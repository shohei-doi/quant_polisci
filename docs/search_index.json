[
["index.html", "Rで計量政治学入門 はじめに 想定する読者 Tidyverseについて ウェブサイトの操作", " Rで計量政治学入門 土井 翔平 2020-04-22 はじめに 本書はRによる計量政治学の入門レベルの講義資料です。 質問や間違いなどがありましたら、ご連絡を下さい。 筆者のプロフィールはこちらをご覧ください。 想定する読者 本書は、データ分析や数学の前提知識やプログラミング経験のない社会科学系学部生を主たる読者として想定しています。 やや高度と思われる箇所には*を付けているので、読み飛ばしても構いません。 なお、RやRStudioのインストールについてはRの分析環境を、基本操作についてはRプログラミング入門をご覧ください。 Tidyverseについて Tidyverseとは様々なデータ操作に関するパッケージ群（あるいはそのプロジェクト）を指します。 本書では、可能な限り、Rの標準関数を用いた表記とTidyverseによる表記を併記するようにします。 しかし、筆者はTidyverseに慣れているので、しばしば標準関数によるコードを省略します。 ウェブサイトの操作 本書はbookdownを用いて作成しています。 ウェブサイトのナビゲーションバーでは、 三本線のボタンで目次の表示・非表示の切り替え 虫眼鏡のマークで単語検索 Aのマークで文字の大きさ、フォント、色のコントロール iのマークでキーボードによる操作方法の表示 が可能です。 "],
["data-import.html", "第1章 データの読み込み 1.1 パッケージ付属のデータ 1.2 主なデータ形式* 1.3 パスと作業ディレクトリ 1.4 .csvファイルの読み込み 1.5 .xls[x]ファイルの読み込み 1.6 .dtaファイルの読み込み 1.7 .rdsファイルの読み込み 1.8 パス入力の省略* 1.9 データの書き出し 1.10 データフレームの作成", " 第1章 データの読み込み 統計分析をする際にはデータを読み込む（インポート）必要があります。 基本的にPCに保存されたデータのパスを入力することでデータを読み込みます。 - URLを入力することでオンラインのデータを読み込むこともできます。 ここでは、まずRやパッケージに付属のデータセットの読み込み方を解説し、統計分析でよく使われるデータ形式を紹介した後に、Rによる読み込み方を説明します。 library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.0 ✓ purrr 0.3.4 ## ✓ tibble 3.0.1 ✓ dplyr 0.8.5 ## ✓ tidyr 1.0.2 ✓ stringr 1.4.0 ## ✓ readr 1.3.1 ✓ forcats 0.5.0 ## ── Conflicts ────────────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() 1.1 パッケージ付属のデータ Rは標準でいくつかのデータセットを持っており、またパッケージを読み込むと付属のデータセットも読み込みます。 data()に何も入力せずに実行すると、データセットの一覧が表示されます。 data() よく、使われるデータセットはフィッシャーのアヤメのデータセットで、irisという名前で保存されています。 head(iris) head()は最初のいくつかの要素だけを表示する関数です（tail()は最後からいくつかを表示します）。 1.2 主なデータ形式* 大雑把に言ってしまうとPCのデータにはテキストデータとバイナリデータに分かれます。 さらにそれぞれ様々な種類の形式がありますが、拡張子によって判断します。 1.2.1 テキストデータ テキストデータとは人間の理解できる文字列のデータのことです。 1.2.1.1 .txtファイル .txtファイルは素のテキストデータになり、データの構造を含みません。 統計分析をする際には使いませんが、テキスト分析をする場合はしばしば遭遇します。 1.2.1.2 .csvファイル 統計分析で遭遇するテキストデータの大半は.csvファイルです。 これは“comma-separated values”の略で、各変数はカンマで区切られています。 各観察は改行で区切られています。 1.2.1.3 .tsvファイル .tsvファイルはカンマの代わりにタブで変数が区切られているテキストデータになります。 1.2.1.4 .htmlファイル .htmlファイルとはウェブサイトの内容を記述してあるファイルです。 ウェブスクレイピング（PCに自動でオンラインの情報を収集させること）をする際に使います。 1.2.2 バイナリデータ バイナリデータとはPCは理解できるけど人間は特定のソフトを使わないと理解できないようなデータになっています。 1.2.2.1 .xls, .xlsxファイル 最も有名なのはExcelで使用される.xlsまたは.xlsxファイルでしょう。 .xlsxの方が.xlsよりも新しくて高圧縮らしいです。 1.2.2.2 .dtaファイル .dtaファイルとはStataと呼ばれる統計分析ソフト専用のデータ形式になります。 Stataは政治学や経済学で人気のツールなのでレプリケーションデータなどはこの形式で配布されていることもあります。 1.2.2.3 .savファイル .savファイルはStataよりも前に人気だった統計ソフト用のデータ形式です。 1.2.2.4 .rdsファイル .rdsファイルとはR戦争のデータ形式になります。 あまり見かけることはありません。 1.2.3 Good bye, Excel! 基本的にはRでデータを読み込めば中身を見ることができるのですが、後述するようにRで読み込む前に生データを見たい場合はしばしばあります。 そのときにMicrosoft OfficeのExcelを使うのはあまりおすすめしません。 なぜなら、 Officeは高い 文字エンコードを指定できない からです。 特に後者の問題は重要だと思います。 例えば日本語を含むデータの場合、Windowsで作成されたものをLinuxやMacで開くと、あるいはその逆をすると文字化けを起こすからです。 そこで、LibreOfficeという無料のオフィスソフトをダウンロードし、その中のCalcを使用することをおすすめします。 LibreOffice Calcであればファイルを開く際にエンコードを選択できるので文字化けすることはありません。 Windowsで文字けする場合、エンコードをUTF-8にする。 Linux, Macで文字化けする場合、エンコードをShift-JISあるいはCP932にする。 もちろん、LibreOfficeでMicrosoft Officeのデータを開くことは可能です。 ただし、LibreOfficをインストールするとMicrosoft Officeが正常に動作しないことがあるかもしれません。 1.3 パスと作業ディレクトリ 一般的に、PCのデータはファイルと呼ばれ、ファイルを入れておく箱のようなものをフォルダ（ディレクトリ）と呼びます。 例えば、Windowsの場合、documentsやpicturesというフォルダがあり、その中にWordファイルや画像データが入っていると思います。 なお、ファイルの名前の末尾には.から始まる拡張子がついています。 例えば、Wordファイルであれば.docx、画像データであれば.pngや.jpgなどです。 これはそのファイルがどのような種類のもので、PCがどのように処理をすればいいのかを示す目印になっています。 - もし、PCで拡張子が表示されていない場合は表示するように設定しましょう。 1.3.1 パス ファイルやフォルダにアクセスする場合、パスと呼ばれるPC上の住所のようなもので指定する必要があります。 例えば、Windowsの場合、documentsフォルダの中のsample.docxというファイルのパスはC:/Users/Shohei/Documents/sample.docxとなります。 正確には、Windowsでは/ではなく円マークになっていると思います。 1.3.1.1 絶対パス このパスの意味はCドライブの中のUserというフォルダの中のShoheiというフォルダの中のDocumentsというフォルダの中にあるsample.docxという意味です。 このように始点（Windowsの場合はCドライブ）から始めるパスを絶対パスと呼びます。 1.3.1.2 相対パス しかし、毎回、絶対パスを書くのは面倒ですし、コードを公開する際にはやや恥ずかしい嫌いもあります。 そこで、途中から書かれるパスを相対パスと呼びます。 例えば、Shoheiというフォルダから見れば、上記のファイルはDocuments/sample.docxとして指定することができます。 1.3.1.3 パスに関する注意点 必ずしも直ちに問題があるわけではないですが、パスに日本語や空白があるとうまく行かないことがあります。 なので、フォルダ名やファイル名はアルファベットで空白を入れない方がいいでしょう。 もしユーザー名が日本語である場合、パス関連でエラーが出る場合はRStudio Cloudを使うか、これを機にOSをクリーンインストールをしてしまうのもありでしょう。 1.3.2 作業ディレクトリ 相対パスでファイルなどを指定する際には出発点となるフォルダを決める必要があります。 これを作業ディレクトリと呼びます。 Rではgetwd()（“get working directory”の略）で現在の作業ディレクトリを確認できます。 また、setwd()に適当なパスを入力することで作業ディレクトリを設定することもできます。 RStudioの場合はFilesパネルの中のMore &gt; Set As Working Directoryで現在開いているフォルダを作業ディレクトリに指定することもできます。 ただし、作業ディレクトリを指定するよりも、Rプロジェクトを作成するのがベターです。 1.4 .csvファイルの読み込み ここでは、例として世界銀行の各国の一人あたりGDPデータを読み込んでみます。 今回は適当に作成したプロジェクト・フォルダの中にdataというフォルダを作成し、その中にwb_gdp_pc.csvというデータを保存してください。 ここでは、tidyverseの中のreadrのread_csv()という関数を使います。 Rの標準関数はread.csv()です（_と.が違います）。 gdp_pc &lt;- read_csv(&quot;data/wb_gdp_pc.csv&quot;) ## Warning: Missing column names filled in: &#39;X3&#39; [3] ## Parsed with column specification: ## cols( ## `Data Source` = col_character(), ## `World Development Indicators` = col_character(), ## X3 = col_character() ## ) ## Warning: 265 parsing failures. ## row col expected actual file ## 2 -- 3 columns 64 columns &#39;data/wb_gdp_pc.csv&#39; ## 3 -- 3 columns 64 columns &#39;data/wb_gdp_pc.csv&#39; ## 4 -- 3 columns 64 columns &#39;data/wb_gdp_pc.csv&#39; ## 5 -- 3 columns 64 columns &#39;data/wb_gdp_pc.csv&#39; ## 6 -- 3 columns 64 columns &#39;data/wb_gdp_pc.csv&#39; ## ... ... ......... .......... .................... ## See problems(...) for more details. データを読み込む際には()の中に読み込みたいデータのパスを入力する必要があります。 したがって、プロジェクト・フォルダから見たデータの相対パスはdata/wb_gdp_pc.csvとなります。 パスをクオーテーションマーク&quot;で囲むことを忘れないでください。 パスの頭に/はいりません。 パスの最後に拡張子を付けることを忘れすに。 読み込んだデータもオブジェクトなので適当な名前をつけて代入する必要があります。 データの名前は 打ち込むのがめんどくさくない程度に短く 他人や数カ月後の自分が見ても分かる程度には意味の分かる ようにするのがコツです。 さて、データを無事読み込めるとEnvironmentパネルにgdp_pcが表示されていると思います。 1.4.1 変数名の適切な読み込み これで一安心と思いきや、Warningという不吉な文字列が見えます。 Environmentパネルをよく見ると変数の数が3つしかないということがわかります。 そこで、データを見てみると、なにかおかしいことが起こっているようです。 WarningとはErrorのように実行できないほどではないけれど、なんか問題があるかもしれない場合に表示されます。 Warningが出たときは問題がないのか確認しましょう。 head(gdp_pc) このような場合はLibreOffice Calcで元データを見てみましょう。 実はread_csv()ではデフォルトでは第1行目を変数名として読み込む設定になっています。 なので、元データのData SourceとWorld Development Indicatorsを変数名として認識してしまったようです。 では、なぜ三番目も変数として認識されているのかはよく分かりません。 変数名は第5行目なので、単純な方法は第1行目から第4行目を削除してしまうことですが、そうすべきではない理由がいくつかあります。 新しい年のデータを使うときに同じ操作をしないといけない。 同じ形式のデータを使うときに同じ操作をしないといけない。 第三者が元データからレプリケートするときに気付かないかもしれない。 ということで、第5行目からデータとして読み込めないか確かめるためにヘルプを見ます。 ?read_csv すると、このような記述が見つかります。 skip Number of lines to skip before reading data. ということで、オプションとしてskip=4を設定して読み込むとうまく行きました gdp_pc &lt;- read_csv(&quot;data/wb_gdp_pc.csv&quot;, skip=4) ## Warning: Missing column names filled in: &#39;X64&#39; [64] ## Parsed with column specification: ## cols( ## .default = col_double(), ## `Country Name` = col_character(), ## `Country Code` = col_character(), ## `Indicator Name` = col_character(), ## `Indicator Code` = col_character(), ## `2018` = col_logical(), ## X64 = col_logical() ## ) ## See spec(...) for full column specifications. head(gdp_pc) ちなみにNAとはRにおける欠損値 (missing value) のことです。 なお、実はこのように時間（この場合は年）が横方向に進んでいくデータをワイド形式と呼び、大抵の場合はこのままでは分析できないのでロング形式にする必要があります。 1.5 .xls[x]ファイルの読み込み 実はtidyverseはいくつかのパッケージをまとめたものになっています。 これまでテキストデータの読み込みに使っていたのは、その中のreadrというパッケージになります。 バイナリデータを読み込むには別途パッケージを使う必要があり、.xls[x]ファイルの場合は以下のものになります。 library(readxl) .xlsか.xslxか分かっている場合はread_xls()もしくはread_xlsx()の適切な方を使い、分からない場合はread_excel()を使います。 ここではFreedom Houseのデータセットを読み込みます。 fh &lt;- read_excel(&quot;data/FH_Country.xls&quot;) 1.5.1 シートの選択 Environmentパネルにfhがあるので一安心と思いきや、変数の数が1つと明らかにおかしいので、Rでデータを見て、LibreOffice Calcで開いてみます。 head(fh) すると、全くデータが異なっていることがわかります。 実はエクセルのデータにはシートという概念があり、異なるデータを一つにまとめることができます。 LibreOffice Calcの左下をよく見ると二番目のシートが選択されていることがわかります。 そしてその左の一番目のシートを選択するとRで読み込まれたものと同じものがあることがわかります。 つまり、先程は自動で一番目のシートを読み込んでしまっていたということで、オプションで二番目のシートを読み込まないといけないわけでした。 そこでヘルプを見るとsheetというオプションがあるので、sheet=2とするとちゃんとほしいデータを読み込んでくれます。 fh &lt;- read_excel(&quot;data/FH_Country.xls&quot;, sheet=2) ## New names: ## * `` -&gt; ...3 ## * `` -&gt; ...4 ## * `` -&gt; ...6 ## * `` -&gt; ...7 ## * `` -&gt; ...9 ## * ... head(fh) 1.5.2 変数名の適切な読み込み (again) これで一安心かと思いきや、そうではありません。 よくみると変数名が適切に選択されていないので、先ほどと同様にskipを設定する必要があります。 fh &lt;- read_excel(&quot;data/FH_Country.xls&quot;, sheet=2, skip=2) ## New names: ## * `` -&gt; ...1 ## * PR -&gt; PR...2 ## * CL -&gt; CL...3 ## * Status -&gt; Status...4 ## * PR -&gt; PR...5 ## * ... head(fh) 1.5.3 欠損値の処理 残念ながら問題はまだ残っています。 head()でデータの冒頭を見たときに変数名の下に&lt;chr&gt;とあるのに注目してください。 これは、当該変数が文字列 (character) であることを意味しています。 国名やステータスが文字列なのは当然として、本来数値データのはずのPR (political rights) やCL (civil liberty) も文字列データになっています。 元データを見てみると、ところどころ-という記号が含まれていることがわかります。 実はこれはFreedom Houseのデータセットにおける欠損値なのですが、Rではデフォルトでは空欄を欠損値として認識します。 そこで、やはりヘルプを見てnaを設定して-も欠損値として読み込むようにします。 fh &lt;- read_excel(&quot;data/FH_Country.xls&quot;, sheet=2, skip=2, na=&quot;-&quot;) ## New names: ## * `` -&gt; ...1 ## * PR -&gt; PR...2 ## * CL -&gt; CL...3 ## * Status -&gt; Status...4 ## * PR -&gt; PR...5 ## * ... head(fh) 実は文字列のままのPRやCLもあるのですが、そこはややこしいので今回は見なかったことにします。 1.6 .dtaファイルの読み込み .xls[x]ファイルと同様.dtaファイルもバイナリデータなので専用のパッケージを読み込みます。 library(haven) ここでは、Bruce Russett and John R. Oneal (2001) “Triangulating Peace” のレプリケーションデータ（とされるもの）を読み込みます。 triangle &lt;- read_dta(&quot;data/TRIANGLE.DTA&quot;) head(triangle) ハッピーなことにStataのデータはそもそも統計分析用に加工されているので、特に面倒くさい手続きをする必要はありません。 1.7 .rdsファイルの読み込み R専用のバイナリデータの形式は.rdsなので、write_rds()で書き出し、read_rds()で読み込むことができます。 1.8 パス入力の省略* データを読み込む際にいちいちパスを打ち込むのは面倒です。 そこで、右下のFilesパネルで読み込みたいデータをクリックするとImport Dataset...というのがあるのでクリックします。 すると次のような画面が出てきますが、右下にデータを読み込むためのパッケージ、関数、パスが表示されるので、関数とパスの部分をコピペしてしまうと楽です。 オブジェクト名の部分は自動的に決まるので、もとのデータの名前が長いとオブジェクト名も長くなり、かっこよくないので自分で設定するようにしたほうがよいでしょう。 また、データのプレビューも可能なのでここでskipなどの設定をすることも可能です。 1.9 データの書き出し データを書き出す際には、基本的に.csvファイルでよいと思うので、write_excel_csv()に保存したいオブジェクト名とパスを入れておきましょう。 ここでは試しにTriangulating Peaceのデータを保存してみます。 write_excel_csv(triangle, &quot;data/triangle.csv&quot;) 指定したパスに新しくファイルができていることを確認してください。 Triangulating Peaceデータの.csvファイルと.dtaファイルの容量を見ると.dtaファイルのほうが小さいことがわかります。 この程度では問題ありませんがデータがあまりにも大きくなる場合はバイナリデータで保存したほうがよいでしょう。 1.10 データフレームの作成 自ら手打ちでデータフレームをdata.frame()によって作成することができます。 data.frame(name = c(&quot;日本&quot;, &quot;アメリカ&quot;, &quot;中国&quot;), code = c(&quot;JPN&quot;, &quot;USA&quot;, &quot;CHN&quot;)) 同様のデータフレームはベクトルからも作れます。 name &lt;- c(&quot;日本&quot;, &quot;アメリカ&quot;, &quot;中国&quot;) code &lt;- c(&quot;JPN&quot;, &quot;USA&quot;, &quot;CHN&quot;) data.frame(name, code) 基本的にデータフレームを作成するときのベクトルは同じ長さでないといけませんが、長さが1の場合はすべての観察に同じ値の変数にになります。 data.frame(name = c(&quot;日本&quot;, &quot;アメリカ&quot;, &quot;中国&quot;), code = c(&quot;JPN&quot;, &quot;USA&quot;, &quot;CHN&quot;), major = 1) すべての観察で大国を表すmajorが1になっています。 tidyverseではdata.frame()の代わりにtibble()を使います。 "],
["select-vars.html", "第2章 変数の選択 2.1 変数名による選択 2.2 番号による選択 2.3 変数名の変更 2.4 高度な変数の選択方法*", " 第2章 変数の選択 ここではTriangulating Peaceのレプリケーションデータを使用します。 library(tidyverse) tri &lt;- read.csv(&quot;data/triangle.csv&quot;) 2.1 変数名による選択 特定の変数をベクトルとして抜き出したい場合はオブジェクト名と変数名の間に$を入れます。 例えば、yearだけを抜き出したい場合は次のようにします。 head(tri$year) ## [1] 1920 1921 1922 1923 1924 1925 データセットとして抜き出す場合は、オブジェクト名の後に[]をつけて、その中に変数名をクオーテーションマーク&quot;で囲んで入れます。 head(tri[&quot;year&quot;]) 複数の変数を指定する場合はc()で変数名のベクトルを作って指定します。 例えば、stateaとstatebとyearを抜き出したい場合は次のようにします。 head(tri[c(&quot;statea&quot;, &quot;stateb&quot;, &quot;year&quot;)]) tidyverseのdplyrというパッケージではselect()によって変数の選択ができます。 例えば、statea, stateb, yearを選択するには次のようにします。 tri %&gt;% select(statea, stateb, year) %&gt;% head() なお、%&gt;%はパイプ演算子と呼ばれるもので、tidyverseの機能の一つです。 その意味についてはこちらを参照して下さい。 変数を除外する場合は-をつけます。 tri %&gt;% select(-year) %&gt;% head() selectでは変数の並び替えもできます。 tri %&gt;% select(year, statea, stateb) %&gt;% head() 変数の選択をせずに並び替えだけしたい場合は、並び替えた後にeverything()を入れます。 tri %&gt;% select(year, statea, stateb, everything()) %&gt;% head() 2.2 番号による選択 列番号を指定することで選択することもできます。 番号がひとつだけの場合はベクトルになります。 head(tri[,3]) ## [1] 1920 1921 1922 1923 1924 1925 複数列を指定するとデータフレームとして抜き出します。 head(tri[,c(1,2,3)]) -を付けるとその列を除外します。 head(tri[,-3]) 2.3 変数名の変更 変数名を確認するにはnames()を使います。 names(tri) ## [1] &quot;statea&quot; &quot;stateb&quot; &quot;year&quot; &quot;dependa&quot; &quot;dependb&quot; &quot;demauta&quot; ## [7] &quot;demautb&quot; &quot;allies&quot; &quot;dispute1&quot; &quot;logdstab&quot; &quot;lcaprat2&quot; &quot;smigoabi&quot; ## [13] &quot;opena&quot; &quot;openb&quot; &quot;minrpwrs&quot; &quot;noncontg&quot; &quot;smldmat&quot; &quot;smldep&quot; ## [19] &quot;dyadid&quot; names()に代入することで変数名を買えることができます。 例えば、stateaをStateAにするには次のようにします。 names(tri)[1] &lt;- &quot;StateA&quot; names(tri) ## [1] &quot;StateA&quot; &quot;stateb&quot; &quot;year&quot; &quot;dependa&quot; &quot;dependb&quot; &quot;demauta&quot; ## [7] &quot;demautb&quot; &quot;allies&quot; &quot;dispute1&quot; &quot;logdstab&quot; &quot;lcaprat2&quot; &quot;smigoabi&quot; ## [13] &quot;opena&quot; &quot;openb&quot; &quot;minrpwrs&quot; &quot;noncontg&quot; &quot;smldmat&quot; &quot;smldep&quot; ## [19] &quot;dyadid&quot; names()ベクトルなので第1要素を参照するには[1]とします。 あるいは、次のようにしてstatebをStateBにすることもできます。 names(tri)[names(tri) == &quot;stateb&quot;] &lt;- &quot;StateB&quot; names(tri) ## [1] &quot;StateA&quot; &quot;StateB&quot; &quot;year&quot; &quot;dependa&quot; &quot;dependb&quot; &quot;demauta&quot; ## [7] &quot;demautb&quot; &quot;allies&quot; &quot;dispute1&quot; &quot;logdstab&quot; &quot;lcaprat2&quot; &quot;smigoabi&quot; ## [13] &quot;opena&quot; &quot;openb&quot; &quot;minrpwrs&quot; &quot;noncontg&quot; &quot;smldmat&quot; &quot;smldep&quot; ## [19] &quot;dyadid&quot; tidyverseで変数名を変える場合はselect()内部で=の左側に新しい変数名、右側にもとの変数名を書きます。 tri %&gt;% select(statea = StateA, stateb = StateB, year) %&gt;% head() 変数名を変えるだけで変数の選択をしない場合はrename()を使います。 tri %&gt;% rename(statea = StateA, stateb = StateB) %&gt;% head() 2.4 高度な変数の選択方法* "],
["create-vars.html", "第3章 変数の作成 3.1 四則演算 3.2 条件に基づく変数 3.3 ラグ変数* 3.4 日付変数*", " 第3章 変数の作成 ここではTriangulating Peaceのレプリケーションデータを使用します。 library(tidyverse) tri &lt;- read_csv(&quot;data/triangle.csv&quot;) ## Parsed with column specification: ## cols( ## statea = col_double(), ## stateb = col_double(), ## year = col_double(), ## dependa = col_double(), ## dependb = col_double(), ## demauta = col_double(), ## demautb = col_double(), ## allies = col_double(), ## dispute1 = col_double(), ## logdstab = col_double(), ## lcaprat2 = col_double(), ## smigoabi = col_double(), ## opena = col_double(), ## openb = col_double(), ## minrpwrs = col_double(), ## noncontg = col_double(), ## smldmat = col_double(), ## smldep = col_double(), ## dyadid = col_double() ## ) 3.1 四則演算 基本的にオブジェクトに$をつけて新しい変数名をつけて代入することで新しい変数を作成します。 例えば、A国とB国の民主主義度であるdemautaとdemautbの平均demautmを作成するには次のようにします。 tri$demautm &lt;- (tri$demauta + tri$demautb)/2 tri %&gt;% select(demauta, demautb, demautm) %&gt;% head() 四則演算は+（足し算）、-（引き算）、*（掛け算）、/（割り算）で行います。 他にも、%%（整数商）や^（累乗）もあります。 tidyverse表記の場合、dplyrのmutate()を使います。 この関数は第1引数にデータフレームを取り、その後ろに新しい変数の定義を書きます。 tri &lt;- tri %&gt;% mutate(demautm = (demauta + demautb)/2) tri %&gt;% select(demauta, demautb, demautm) %&gt;% head() 3.2 条件に基づく変数 ifelse()関数を使うと条件によって値の変わる変数を作成します。 例えば、smldepとはdependaとdependbの小さい方なので、これをmindepとすると次のように作成します。 tri$mindep &lt;- ifelse(tri$dependa &lt; tri$demautb, tri$dependa, tri$dependb) tri %&gt;% select(dependa, dependb, smldep, mindep) %&gt;% head() さて、if_else()は何をしているのでしょうか？ まず、第1引数は条件式となっています。 そして、その条件を満たす場合は第2引数を、満たさない場合は第3引数を出力します。 つまり、dependaがdependbよりも小さければdependaを、大きければdependbを返しています。 tidyverseの場合は、ほとんど同じですが、if_else()という関数を使います。 tri &lt;- tri %&gt;% mutate(if_else(dependa &lt; demautb, dependa, dependb)) tri %&gt;% select(dependa, dependb, smldep, mindep) %&gt;% head() tidyverseのcase_when()を使うと条件に応じて作る変数の値を2種類以上にすることができます。 例えば、1919年までをprewar、1920年から1945年をinterwar、1946年からをcoldwarとするような変数systemを作ります。 tri &lt;- tri %&gt;% mutate(system = case_when(year &lt;= 1919 ~ &quot;prewar&quot;, year &gt; 1919 &amp; year &lt;= 1945 ~ &quot;interwar&quot;, year &gt; 1945 ~ &quot;coldwar&quot;)) 長くなるので、実行しませんが、table()によって、yearとsystemの対応関係をクロス表にできます. table(tri$system, tri$year) ## ## 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 ## coldwar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## interwar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## prewar 104 104 110 110 110 141 118 118 118 118 141 141 141 ## ## 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 ## coldwar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## interwar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## prewar 140 150 198 161 161 160 170 156 179 170 179 179 167 ## ## 1911 1912 1913 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 ## coldwar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## interwar 0 0 0 265 275 235 242 243 401 373 388 457 465 ## prewar 162 171 172 0 0 0 0 0 0 0 0 0 0 ## ## 1930 1931 1932 1933 1934 1935 1936 1937 1938 1946 1947 1948 1949 ## coldwar 0 0 0 0 0 0 0 0 0 15 15 11 11 ## interwar 427 445 454 433 468 478 494 489 479 0 0 0 0 ## prewar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ## 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 ## coldwar 343 336 331 337 338 363 373 393 400 399 540 599 633 ## interwar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## prewar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ## 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 ## coldwar 640 644 703 734 743 748 749 784 819 819 825 796 830 ## interwar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## prewar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ## 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 ## coldwar 850 824 820 800 836 829 850 851 861 849 865 857 855 ## interwar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## prewar 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ## 1989 1990 1991 ## coldwar 802 649 567 ## interwar 0 0 0 ## prewar 0 0 0 ちなみに、mutate()の中では複数の変数を同時に作成することができます。 tri &lt;- tri %&gt;% mutate(demautm = (demauta + demautb)/2, if_else(dependa &lt; demautb, dependa, dependb)) 3.3 ラグ変数* パネルデータの場合、ラグ変数（前の時点の変数）を作成することがあります。 tidyverseのdplyrにあるgroup_by()というグループ化する関数を使うとラグ変数を作成できます。 例えば、smldepのラグ変数をlag_smldepとして作成するとします。 このデータセットでは分析単位はダイアッドなので、cstateaとstatebでグループ化して変数を作ります。 lag()によって変数のラグを取ることができ、order_byでどの変数に関してラグを取るかを決めることができます。 tri &lt;- tri %&gt;% group_by(statea, stateb) %&gt;% mutate(lag_smldep = lag(smldep, order_by = year)) tri %&gt;% select(statea, stateb, year, smldep, lag_smldep) %&gt;% head() lead()によってリードを取ることもできます。 3.4 日付変数* "],
["select-obs.html", "第4章 観察の選択 4.1 数値の大小による選択 4.2 一致・不一致による選択 4.3 「または」 4.4 「かつ」 4.5 部分集合 4.6 番号による選択 4.7 観察の並び替え 4.8 ベクトルの選択*", " 第4章 観察の選択 ここではTriangulating Peaceのレプリケーションデータを使用します。 library(tidyverse) data &lt;- read.csv(&quot;data/triangle.csv&quot;) 4.1 数値の大小による選択 R標準の方法ではdata[条件,]の条件部分に適当な論理値を入力して抜き出します。 例えば、1990年以降のデータだけを取り出す場合は以下のようにします。 head(data[data$year &gt;= 1990,]) なお、&gt;=の代わりに&gt;とすると1990年の観察は除外されます。 head(data[data$year &gt; 1990,]) 未満の場合は&lt;、以下の場合は&lt;=を使います。 tidyverseの中のdplyrというパッケージのfilter()という関数を使うともう少し簡単に書くことができます。 filter()はオブジェクトと条件式を入力すると条件に合致する観察を抜き出します。 data %&gt;% filter(year &gt;= 1990) %&gt;% head() data$変数名のように書かなくていいので楽です。 4.2 一致・不一致による選択 変数が特定の値に一致するときは==を使います。 例えば、1990年「のみ」の観察を抜き出すには次のようにします。 head(data[data$year == 1990,]) =ではない点に注意して下さい。 不一致の場合は!=を使います。 例えばstateaが2（アメリカ）でない観察を抜き出すには次のようにします。 head(data[data$statea != 2,]) 条件式の前に!を付けることで逆を表現することができます。 以下のコードは上記のコードと同じです。 head(data[!data$statea == 2,]) 4.3 「または」 複数の条件のいずれかに合致するものを抜き出すには|を使います。 例えば、stateaもしくはstatebが710（中国）である観察を抜き出す場合は次のようにします。 head(data[data$statea == 710 | data$stateb == 710,]) 4.4 「かつ」 複数の条件の全てに合致するものを抜き出すには&amp;を使います。 例えば、stateaが710でstatebが740（日本）である観察を抜き出す場合は次のようにします。 head(data[data$statea == 710 &amp; data$stateb == 740,]) 4.5 部分集合 yearが1950年から1990年までの10年刻みの観察を抜き出したいとします。 |を使うとこのようになります。 head(data[data$year == 1950 | data$year == 1960 | data$year == 1970 | data$year == 1980 | data$year == 1990,]) これではコードが長くなり面倒ですが、代わりに%in%を使うことができます。 %in%は左のベクトルで要素が右のベクトルの要素のどれかに一致するものを抜き出します head(data[data$year %in% c(1950, 1960, 1970, 1980, 1990),]) なお、等差数列を作る関数seq()を使うともっと簡単に書けます。 head(data[data$year %in% seq(1950, 1990, by = 10),]) tidyverseの場合はfilter()の中に複数の条件式を書いていきます。 4.6 番号による選択 特定の行だけを抜き出したい場合は、条件式の部分に当該番号を入力します。 例えば、最初の観察を抜き出すには次のようにします。 head(data[1,]) c()を使って複数行を選択することもできます。 head(data[c(1,3,5),]) nrow()はデータの行数を返す関数なので、一番下の観察を抜き出すには次のようにします。 head(data[nrow(data),]) -を付けるとその行を除外します。 head(data[-1,]) tidyverseで、行番号で指定する場合はslice()を使います。 head(slice(data, 1)) 4.7 観察の並び替え 変数の大きさによって並び替えをする場合、order()を使います。 例えば、年が古い順に並べる場合は次のようにします。 head(data[order(data$year),]) 逆に新しい順に並べる場合はオプションでdecreasing = TRUEとします。 head(data[order(data$year, decreasing = TRUE),]) tidyverseで観察を並び替える場合はarrange()を使います。 data %&gt;% arrange(year) %&gt;% head() 降順にする場合は変数名をdesc()で囲みます。 data %&gt;% arrange(desc(year)) %&gt;% head() 複数の基準で並び替えることもできます。 data %&gt;% arrange(desc(year), desc(dispute1)) %&gt;% head() 4.8 ベクトルの選択* なお、ベクトルは1行あるいは1列の行列と見ることができますが、Rでは行列とは区別されます。 ベクトルの要素にアクセスする場合は[]の中にアクセスしたい番号（のベクトル）を入れます。 例えば、lettersというアルファベットのベクトルを考えます。 letters ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; &quot;r&quot; &quot;s&quot; ## [20] &quot;t&quot; &quot;u&quot; &quot;v&quot; &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; 第1要素にアクセスする場合はこう書きます。 letters[1] ## [1] &quot;a&quot; 第1から第3要素までアクセスする場合はこう書きます。 letters[1:3] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 1:3は1から3まで1刻みに増えるベクトルを意味します。だ データフレームからベクトルを抜き出す場合は$で変数を指定します。 head(data$year) ## [1] 1920 1921 1922 1923 1924 1925 tidyverseではpull()という関数を使います。 data %&gt;% pull(year) %&gt;% head() ## [1] 1920 1921 1922 1923 1924 1925 "],
["data-combine.html", "第5章 データの結合 5.1 行方向の結合 5.2 列方向の結合", " 第5章 データの結合 観察データを分析する際、大抵の場合は複数のデータを集めて、結合した上で分析をする必要があります。 結合の方法には 行方向の結合：同じ変数を持っているデータ同士を結合させて観察数を増やす。 列方向の結合：同じ種類の観察を持っているデータ同士を結合して変数の数を増やす。 の2種類があります。 library(tidyverse) 5.1 行方向の結合 行方向にデータを結合する必要がある場面としてよくあるのはデータが年や地域ごとに分割されているときです。 例えば、（なぜか）一人あたりGDPのデータが日本と中国で別々のデータになっているとします。 japan &lt;- read_csv(&quot;data/wb_gdp_pc_jp.csv&quot;) ## Parsed with column specification: ## cols( ## name = col_character(), ## year = col_double(), ## gdp_pc = col_double() ## ) japan china &lt;- read_csv(&quot;data/wb_gdp_pc_cn.csv&quot;) ## Parsed with column specification: ## cols( ## name = col_character(), ## year = col_double(), ## gdp_pc = col_double() ## ) china これを結合するにはrbind()（row方向の結合）を使いますが、それぞれ同じ変数名を持っている必要があります。 data &lt;- rbind(japan, china) unique(data$name) ## [1] &quot;Japan&quot; &quot;China&quot; 無事、日本と中国が一つのデータに含まれています。 tidyverseで行方向の結合の場合、bind_rows()という関数を使います。 data &lt;- bind_rows(japan, china) unique(data$name) ## [1] &quot;Japan&quot; &quot;China&quot; 5.2 列方向の結合 変数を増やすためにデータセットを都合するには列方向に結合する必要があります。 例えば、一人あたりGDPのデータにGDP成長率のデータを結合するとします。 gdp_pc &lt;- read_csv(&quot;data/wb_gdp_pc.csv&quot;, skip = 4) %&gt;% select(-&quot;Country Code&quot;, -&quot;Indicator Name&quot;, -&quot;Indicator Code&quot;, -X64)%&gt;% rename(name = &quot;Country Name&quot;) %&gt;% gather(key = year, value = gdp_pc, -name) %&gt;% mutate(year = as.numeric(year)) ## Warning: Missing column names filled in: &#39;X64&#39; [64] ## Parsed with column specification: ## cols( ## .default = col_double(), ## `Country Name` = col_character(), ## `Country Code` = col_character(), ## `Indicator Name` = col_character(), ## `Indicator Code` = col_character(), ## `2018` = col_logical(), ## X64 = col_logical() ## ) ## See spec(...) for full column specifications. head(gdp_pc) gdp_gr &lt;- read_csv(&quot;data/wb_gdp_growth.csv&quot;, skip = 4) %&gt;% select(-&quot;Country Code&quot;, -&quot;Indicator Name&quot;, -&quot;Indicator Code&quot;, -X64)%&gt;% rename(name = &quot;Country Name&quot;) %&gt;% gather(key = year, value = gdp_gr, -name) %&gt;% mutate(year = as.numeric(year)) ## Warning: Missing column names filled in: &#39;X64&#39; [64] ## Parsed with column specification: ## cols( ## .default = col_double(), ## `Country Name` = col_character(), ## `Country Code` = col_character(), ## `Indicator Name` = col_character(), ## `Indicator Code` = col_character(), ## `1960` = col_logical(), ## `2018` = col_logical(), ## X64 = col_logical() ## ) ## See spec(...) for full column specifications. head(gdp_gr) [ロング・ワイド変換]で紹介するようにワイド形式からロング形式に変換しています。 つまり、モチベーションとしてはこの２つのデータセットを結合して、各国の各年の一人あたりGDPとGDP成長率のデータセットを作成したいとします。 merge()を使うことでそれが可能になりますが、byによって結合するデータに共通するそれぞれの観察を特定する変数を指定します。 この場合、各観察は各国の各年なので、nameとyearを指定します。 data &lt;- merge(gdp_pc, gdp_gr, by = c(&quot;name&quot;, &quot;year&quot;)) head(data) tidyverseで列方向の結合の場合、以下の4つの関数のうちの一つを選びます。 ここでは、xとyというデータセットを結合するとします。 left_join(x, y)：xにマッチする観察のみを残す。 right_join(x, y)：yにマッチする観察のみを残す。 inner_join(x, y)：両者に共通する観察のみを残す。 full_join(x, y)：どちらかに含まれる観察を全て残す。 例えば、次のようなXとYというデータセットがあり、同じidのサンプル同士で結合するとします。 X &lt;- tibble(id = c(1,2,3), x = c(&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;)) Y &lt;- tibble(id = c(1,2,4), y = c(&quot;y1&quot;, &quot;y2&quot;, &quot;y4&quot;)) X Y left_join()の場合はXにあるデータだけ残ります。 left_join(X, Y, by = &quot;id&quot;) right_join()の場合ははYにあるデータだけ残ります。 right_join(X, Y, by = &quot;id&quot;) inner_join()の場合は共通して存在するサンプルに、full_join()の場合は少なくともどちらかに存在するサンプルになるので、後者が一番保守的な結合になります。 inner_join(X, Y, by = &quot;id&quot;) full_join(X, Y, by = &quot;id&quot;) なお、byで指定しなくても自動で結合してくれますが、一般的にはbyで指定したほうがいいでしょう。 5.2.1 観察の選択*＊ semi_join()とanti_join()という関数ではデータの結合ではなく、マッチングに応じた観察の選択が可能です。 semi_join(x, y)：yとマッチしたxだけを返す。 anti_join(x, y)：yとマッチしなかったxだけを返す。 semi_join(X, Y, by = &quot;id&quot;) anti_join(X, Y, by = &quot;id&quot;) 5.2.2 データフレームの作成 tidyverseにおけるデータフレームを作成する関数はtibble()です。 tibble(name = c(&quot;日本&quot;, &quot;アメリカ&quot;, &quot;中国&quot;), code = c(&quot;JPN&quot;, &quot;USA&quot;, &quot;CHN&quot;)) やはりデータフレームはベクトルからも作れます。 name &lt;- c(&quot;日本&quot;, &quot;アメリカ&quot;, &quot;中国&quot;) code &lt;- c(&quot;JPN&quot;, &quot;USA&quot;, &quot;CHN&quot;) tibble(name, code) "],
["missing-values.html", "第6章 欠損値の処理* 6.1 欠損値を読み込む 6.2 欠損値を含む観察を除外する 6.3 欠損値を置き換える 6.4 欠損値がある場合の分析* 6.5 欠損値のクラス*", " 第6章 欠損値の処理* 欠損値 (missing value) とは観測ができなかった、あるいはその時点において観察対象が存在していなかった、などの理由から変数が欠損していることを示しています。 Rでは主にNAとして表示されます。 ここでは、Rにおける欠損値の扱い方について説明します。 ここでは欠損値の対処法（例、多重代入法）は触れません。 library(tidyverse) library(readxl) 6.1 欠損値を読み込む Rでは読み込むデータにおいて空欄である場合に欠損値として認識し、データセット内ではNAと表示されます。 例えば、dyplyrに含まれているstarwarsというデータセットを見てみると、身長や重量、誕生年にNAがいくつかあるのが分かります。 starwars &lt;- starwars %&gt;% select(1:10) summary(starwars) ## name height mass hair_color ## Length:87 Min. : 66.0 Min. : 15.00 Length:87 ## Class :character 1st Qu.:167.0 1st Qu.: 55.60 Class :character ## Mode :character Median :180.0 Median : 79.00 Mode :character ## Mean :174.4 Mean : 97.31 ## 3rd Qu.:191.0 3rd Qu.: 84.50 ## Max. :264.0 Max. :1358.00 ## NA&#39;s :6 NA&#39;s :28 ## skin_color eye_color birth_year gender ## Length:87 Length:87 Min. : 8.00 Length:87 ## Class :character Class :character 1st Qu.: 35.00 Class :character ## Mode :character Mode :character Median : 52.00 Mode :character ## Mean : 87.57 ## 3rd Qu.: 72.00 ## Max. :896.00 ## NA&#39;s :44 ## homeworld species ## Length:87 Length:87 ## Class :character Class :character ## Mode :character Mode :character ## ## ## ## 問題は、もとのデータセットにおいて欠損値が空欄になっているとは限らないという点です。 例えば、Polity IVというデータセットを開いてみます。 polity &lt;- read_excel(&quot;data/p4v2017.xls&quot;) %&gt;% select(ccode, country, year, democ, autoc) summary(polity) ## ccode country year democ ## Min. : 2.0 Length:17395 Min. :1800 Min. :-88.00000 ## 1st Qu.:200.0 Class :character 1st Qu.:1894 1st Qu.: 0.00000 ## Median :366.0 Mode :character Median :1959 Median : 1.00000 ## Mean :404.2 Mean :1940 Mean : -0.08928 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.00000 ## Max. :950.0 Max. :2017 Max. : 10.00000 ## autoc ## Min. :-88.0000 ## 1st Qu.: 0.0000 ## Median : 4.0000 ## Mean : 0.3837 ## 3rd Qu.: 7.0000 ## Max. : 10.0000 一見すると欠損値はないように見えますが、よく見るとdemocとautocの最小値が-88となっています。 コードブックをよく見ると分かるのですが、実は-66、-77、-88はそれぞれ被介入、無政府、移行期を意味しています。 それらの違いを無視することは問題があるものの、これらを欠損値に置き換えることがしばしばあります。 polity$democ[polity$democ %in% c(-66, -77, -88)] &lt;- NA polity$autoc[polity$autoc %in% c(-66, -77, -88)] &lt;- NA summary(polity) ## ccode country year democ ## Min. : 2.0 Length:17395 Min. :1800 Min. : 0.000 ## 1st Qu.:200.0 Class :character 1st Qu.:1894 1st Qu.: 0.000 ## Median :366.0 Mode :character Median :1959 Median : 1.000 ## Mean :404.2 Mean :1940 Mean : 3.564 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.000 ## Max. :950.0 Max. :2017 Max. :10.000 ## NA&#39;s :776 ## autoc ## Min. : 0.000 ## 1st Qu.: 0.000 ## Median : 4.000 ## Mean : 4.059 ## 3rd Qu.: 7.000 ## Max. :10.000 ## NA&#39;s :776 無事、欠損値が正しく認識されて、最小値が0になりました。 なお、欠損値が-や.のような文字列になっている場合、欠損値に入れ替えた後にas.numeric()などで数値データに変換するのを忘れないようにしましょう。 tidyverseのdplyrで欠損値を扱うときの方法を説明します。 まず。元データにおける欠損値が空欄ではない場合は、データを読み込む際にオプションnaで指定します。 polity &lt;- read_excel(&quot;data/p4v2017.xls&quot;, na = c(&quot;-66&quot;, &quot;-77&quot;, &quot;-88&quot;)) %&gt;% select(ccode, country, year, democ, autoc) summary(polity) ## ccode country year democ ## Min. : 2.0 Length:17395 Min. :1800 Min. : 0.000 ## 1st Qu.:200.0 Class :character 1st Qu.:1894 1st Qu.: 0.000 ## Median :366.0 Mode :character Median :1959 Median : 1.000 ## Mean :404.2 Mean :1940 Mean : 3.564 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.000 ## Max. :950.0 Max. :2017 Max. :10.000 ## NA&#39;s :776 ## autoc ## Min. : 0.000 ## 1st Qu.: 0.000 ## Median : 4.000 ## Mean : 4.059 ## 3rd Qu.: 7.000 ## Max. :10.000 ## NA&#39;s :776 文字列として指定する点に注意してください。 あるいは、面倒くさいですがna_if()という関数を使うことも可能です。 polity &lt;- read_excel(&quot;data/p4v2017.xls&quot;, na = c(&quot;-66&quot;, &quot;-77&quot;, &quot;-88&quot;)) %&gt;% select(ccode, country, year, democ, autoc) %&gt;% mutate(democ = na_if(democ, -66), democ = na_if(democ, -77), democ = na_if(democ, -88), autoc = na_if(autoc, -66), autoc = na_if(autoc, -77), autoc = na_if(autoc, -88)) summary(polity) ## ccode country year democ ## Min. : 2.0 Length:17395 Min. :1800 Min. : 0.000 ## 1st Qu.:200.0 Class :character 1st Qu.:1894 1st Qu.: 0.000 ## Median :366.0 Mode :character Median :1959 Median : 1.000 ## Mean :404.2 Mean :1940 Mean : 3.564 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.000 ## Max. :950.0 Max. :2017 Max. :10.000 ## NA&#39;s :776 ## autoc ## Min. : 0.000 ## 1st Qu.: 0.000 ## Median : 4.000 ## Mean : 4.059 ## 3rd Qu.: 7.000 ## Max. :10.000 ## NA&#39;s :776 6.2 欠損値を含む観察を除外する 後述するように基本的には欠損値がデータセットに含まれていても問題ないのですが、しばしば欠損値を含む観察を取り除く必要があります。 特定のベクトルのどの要素が欠損しているかを判定する関数はis.na()です。 これは名前の通り、欠損している場合にTRUEが返ってくるので、次のようにすることでdemocとautocが欠損しているサンプルを除外できます。 no_na &lt;- polity[!(is.na(polity$democ) | is.na(polity$autoc)),] summary(no_na) ## ccode country year democ ## Min. : 2.0 Length:16619 Min. :1800 Min. : 0.000 ## 1st Qu.:200.0 Class :character 1st Qu.:1892 1st Qu.: 0.000 ## Median :365.0 Mode :character Median :1959 Median : 1.000 ## Mean :403.2 Mean :1940 Mean : 3.564 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.000 ## Max. :950.0 Max. :2017 Max. :10.000 ## autoc ## Min. : 0.000 ## 1st Qu.: 0.000 ## Median : 4.000 ## Mean : 4.059 ## 3rd Qu.: 7.000 ## Max. :10.000 同様のことは次のようにもできます。 no_na &lt;- polity[!is.na(polity$democ) &amp; !is.na(polity$autoc),] summary(no_na) ## ccode country year democ ## Min. : 2.0 Length:16619 Min. :1800 Min. : 0.000 ## 1st Qu.:200.0 Class :character 1st Qu.:1892 1st Qu.: 0.000 ## Median :365.0 Mode :character Median :1959 Median : 1.000 ## Mean :403.2 Mean :1940 Mean : 3.564 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.000 ## Max. :950.0 Max. :2017 Max. :10.000 ## autoc ## Min. : 0.000 ## 1st Qu.: 0.000 ## Median : 4.000 ## Mean : 4.059 ## 3rd Qu.: 7.000 ## Max. :10.000 tidyverseで欠損値を除く場合はdrop_na()を使います。 polity %&gt;% drop_na() %&gt;% summary() ## ccode country year democ ## Min. : 2.0 Length:16619 Min. :1800 Min. : 0.000 ## 1st Qu.:200.0 Class :character 1st Qu.:1892 1st Qu.: 0.000 ## Median :365.0 Mode :character Median :1959 Median : 1.000 ## Mean :403.2 Mean :1940 Mean : 3.564 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.000 ## Max. :950.0 Max. :2017 Max. :10.000 ## autoc ## Min. : 0.000 ## 1st Qu.: 0.000 ## Median : 4.000 ## Mean : 4.059 ## 3rd Qu.: 7.000 ## Max. :10.000 drop_na()の中で変数を指定することで、その変数が欠損している観察だけを除外することもできます。 polity %&gt;% drop_na(democ) %&gt;% summary() ## ccode country year democ ## Min. : 2.0 Length:16619 Min. :1800 Min. : 0.000 ## 1st Qu.:200.0 Class :character 1st Qu.:1892 1st Qu.: 0.000 ## Median :365.0 Mode :character Median :1959 Median : 1.000 ## Mean :403.2 Mean :1940 Mean : 3.564 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.000 ## Max. :950.0 Max. :2017 Max. :10.000 ## autoc ## Min. : 0.000 ## 1st Qu.: 0.000 ## Median : 4.000 ## Mean : 4.059 ## 3rd Qu.: 7.000 ## Max. :10.000 6.3 欠損値を置き換える is.na()を使うと欠損値を他の数値に書き換えることも可能です。 例えば、欠損値を全て-1に置き換えるには次のようにします。 polity[is.na(polity$democ),]$democ &lt;- -1 polity[is.na(polity$autoc),]$autoc &lt;- -1 summary(polity) ## ccode country year democ ## Min. : 2.0 Length:17395 Min. :1800 Min. :-1.000 ## 1st Qu.:200.0 Class :character 1st Qu.:1894 1st Qu.: 0.000 ## Median :366.0 Mode :character Median :1959 Median : 1.000 ## Mean :404.2 Mean :1940 Mean : 3.361 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.000 ## Max. :950.0 Max. :2017 Max. :10.000 ## autoc ## Min. :-1.000 ## 1st Qu.: 0.000 ## Median : 4.000 ## Mean : 3.834 ## 3rd Qu.: 7.000 ## Max. :10.000 tidyverseで欠損値を他の値に置き換えるときはreplace_na()を使います。 polity &lt;- polity %&gt;% replace_na(list(democ = -1, autoc = -1)) summary(polity) ## ccode country year democ ## Min. : 2.0 Length:17395 Min. :1800 Min. :-1.000 ## 1st Qu.:200.0 Class :character 1st Qu.:1894 1st Qu.: 0.000 ## Median :366.0 Mode :character Median :1959 Median : 1.000 ## Mean :404.2 Mean :1940 Mean : 3.361 ## 3rd Qu.:630.0 3rd Qu.:1991 3rd Qu.: 7.000 ## Max. :950.0 Max. :2017 Max. :10.000 ## autoc ## Min. :-1.000 ## 1st Qu.: 0.000 ## Median : 4.000 ## Mean : 3.834 ## 3rd Qu.: 7.000 ## Max. :10.000 複数の変数を一括で変更する場合はlist()で選択します。 6.4 欠損値がある場合の分析* 基本的に、欠損値がある場合でも分析をする上で問題はありません。 polity &lt;- read_excel(&quot;data/p4v2017.xls&quot;) %&gt;% select(ccode, country, year, democ, autoc) polity$democ[polity$democ %in% c(-66, -77, -88)] &lt;- NA polity$autoc[polity$autoc %in% c(-66, -77, -88)] &lt;- NA 6.4.1 一変数の記述統計 例えば、平均値などの記述統計を求める際にはna.rm = TRUEというオプションをつけます。 mean(polity$democ) ## [1] NA mean(polity$democ, na.rm = TRUE) ## [1] 3.564174 6.4.2 二変数の記述統計 相関係数や共分散など二変数以上の場合は若干ややこしくなります。 useオプションで以下の対処法のうち一つを決定します。 everything：欠損値を含む場合はNAを返す（デフォぱルト）。 all.obs：欠損値を含む場合はエラーとなる。 complete.obs：全ての変数が欠損していないものだけを使って計算する。 pairwise.complete.obs：二変数が欠損していないサンプルを使って計算する。 いまいちよくわからないのでデモデータを作って確認してみます。 irisの上から10のサンプルで品種以外のデータを使います。 demo &lt;- iris[1:10,1:4] demo[1,1] &lt;- NA demo[2,2] &lt;- NA demo[3,2] &lt;- NA demo 6.4.2.1 everythingの場合 欠損値を含まない変数Petal.LengthとPetal.WIdthのみ計算されています。 cor(demo, use = &quot;everything&quot;) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1 NA NA NA ## Sepal.Width NA 1 NA NA ## Petal.Length NA NA 1.0000000 0.5216405 ## Petal.Width NA NA 0.5216405 1.0000000 6.4.2.2 all.obsの場合 欠損値が含まれているのでエラーが起こります。 cor(demo, use = &quot;all.obs&quot;) ## Error in cor(demo, use = &quot;all.obs&quot;): missing observations in cov/cor 6.4.2.3 complete.obsの場合 これはどの変数も欠損していないサンプル（つまり、4番目から10番目のサンプル）の相関係数になります。 cor(demo, use = &quot;complete.obs&quot;) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1.0000000 0.8545604 0.7624091 0.4247114 ## Sepal.Width 0.8545604 1.0000000 0.5684454 0.7269985 ## Petal.Length 0.7624091 0.5684454 1.0000000 0.5385368 ## Petal.Width 0.4247114 0.7269985 0.5385368 1.0000000 cor(demo[4:10,]) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1.0000000 0.8545604 0.7624091 0.4247114 ## Sepal.Width 0.8545604 1.0000000 0.5684454 0.7269985 ## Petal.Length 0.7624091 0.5684454 1.0000000 0.5385368 ## Petal.Width 0.4247114 0.7269985 0.5385368 1.0000000 6.4.2.4 pairwise.completeの場合 先ほどと一致しているところと一致していないところがあります。 cor(demo, use = &quot;pairwise.complete&quot;) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1.0000000 0.8545604 0.6853616 0.4225771 ## Sepal.Width 0.8545604 1.0000000 0.4845437 0.6915641 ## Petal.Length 0.6853616 0.4845437 1.0000000 0.5216405 ## Petal.Width 0.4225771 0.6915641 0.5216405 1.0000000 例えば、Sepal.LengthとSepal.Widthの場合、どちらも欠損していないのは4番目から10番目のサンプルになります。 なので、complete.obsのときと同じ結果になります。 cor(demo[4:10,]$Sepal.Length, demo[4:10,]$Sepal.Width) ## [1] 0.8545604 しかし、Petal.LengthとPetal.Widthの場合、欠損しているサンプルはないので、1番目から10番目のサンプル全てを使った値になります。 cor(demo$Petal.Length, demo$Petal.Width) ## [1] 0.5216405 everythingのときと同じであることも分かります。 6.4.3 回帰分析 回帰分析の際には欠損値を含むサンプルを除外した上で計算します。 summary(lm(democ ~ autoc, data = polity)) ## ## Call: ## lm(formula = democ ~ autoc, data = polity) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.5316 -1.5316 0.2009 2.1118 2.5576 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.442414 0.023232 320.4 &lt;2e-16 *** ## autoc -0.955418 0.004321 -221.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.964 on 16617 degrees of freedom ## (776 observations deleted due to missingness) ## Multiple R-squared: 0.7463, Adjusted R-squared: 0.7463 ## F-statistic: 4.888e+04 on 1 and 16617 DF, p-value: &lt; 2.2e-16 776 observations deleted due to missingnessと表示されています。 6.5 欠損値のクラス* "],
["reshape.html", "第7章 ロング・ワイドの変換* 7.1 パネルデータ 7.2 ループによる方法 7.3 tidyverseな方法", " 第7章 ロング・ワイドの変換* データの読み込みで世界銀行の一人あたりGDPのデータを読み込んだ際に、ワイド形式なのでロング形式にしないといけないと書きました。 ここではワイド形式からロング形式にする方法について、 ループ処理を使う方法 tidyverseの中のtidyrの関数を使う方法 を説明しますが、その前になぜそうしなければいけないのかについて簡単に説明します。 library(tidyverse) 7.1 パネルデータ ある一時点のいくつかのユニットのデータをクロスセクションあるいは横断データと呼びます。 例えば、2019年の各国の一人あたりGDPデータはクロスセクションデータと言えます。 逆にあるユニットの複数時点のデータを時系列データと呼びます。 例えば、日本の1950年から2019年までの一人あたりGDPデータは時系列データと言えます。 パネルデータ、縦断データあるいはTSCS (Time-Series Cross-Section) データと呼ばれるものは複数のユニットの複数時点のデータになります。 今回扱うデータはパネルデータになります。 7.1.1 ワイド形式 再び、世界銀行のデータを読み込みます。 data &lt;- read_csv(&quot;data/wb_gdp_pc.csv&quot;, skip = 4) ## Warning: Missing column names filled in: &#39;X64&#39; [64] ## Parsed with column specification: ## cols( ## .default = col_double(), ## `Country Name` = col_character(), ## `Country Code` = col_character(), ## `Indicator Name` = col_character(), ## `Indicator Code` = col_character(), ## `2018` = col_logical(), ## X64 = col_logical() ## ) ## See spec(...) for full column specifications. head(data) 中身を見てみると各行はユニット（この場合は国家）で各列がそれぞれの年の一人あたりGDPになっていることがわかります。 このように時間が進むに連れて横に増えていくデータをワイド形式と呼びます。 7.1.2 ロング形式 結論を先取りしていうと、パネルデータ分析をする際にはデータはロング形式である必要があります。 ロング形式では各行はユニットかつ時点となっており、それぞれのユニットの特定の時点の変数の値（今回の場合はgdp_pc）が格納されています。 整然 (tidy) データについてはこちらを参照。 7.1.3 前処理 以下ではワイド形式からロング形式に変換する方法を説明しますが、その準備としてデータをきれいな形に変換します。 まず、変数名を確認すると次の点に気づきます。 Coutnry Code, Indicator Name、Indicator Codeという変数が不要でありそう。 Country Nameという変数名に空白があると面倒なので名前を変えた方がいい。 X64という謎の変数がある。 names(data) ## [1] &quot;Country Name&quot; &quot;Country Code&quot; &quot;Indicator Name&quot; &quot;Indicator Code&quot; ## [5] &quot;1960&quot; &quot;1961&quot; &quot;1962&quot; &quot;1963&quot; ## [9] &quot;1964&quot; &quot;1965&quot; &quot;1966&quot; &quot;1967&quot; ## [13] &quot;1968&quot; &quot;1969&quot; &quot;1970&quot; &quot;1971&quot; ## [17] &quot;1972&quot; &quot;1973&quot; &quot;1974&quot; &quot;1975&quot; ## [21] &quot;1976&quot; &quot;1977&quot; &quot;1978&quot; &quot;1979&quot; ## [25] &quot;1980&quot; &quot;1981&quot; &quot;1982&quot; &quot;1983&quot; ## [29] &quot;1984&quot; &quot;1985&quot; &quot;1986&quot; &quot;1987&quot; ## [33] &quot;1988&quot; &quot;1989&quot; &quot;1990&quot; &quot;1991&quot; ## [37] &quot;1992&quot; &quot;1993&quot; &quot;1994&quot; &quot;1995&quot; ## [41] &quot;1996&quot; &quot;1997&quot; &quot;1998&quot; &quot;1999&quot; ## [45] &quot;2000&quot; &quot;2001&quot; &quot;2002&quot; &quot;2003&quot; ## [49] &quot;2004&quot; &quot;2005&quot; &quot;2006&quot; &quot;2007&quot; ## [53] &quot;2008&quot; &quot;2009&quot; &quot;2010&quot; &quot;2011&quot; ## [57] &quot;2012&quot; &quot;2013&quot; &quot;2014&quot; &quot;2015&quot; ## [61] &quot;2016&quot; &quot;2017&quot; &quot;2018&quot; &quot;X64&quot; そこで、X64の中身を確認します。 data$X64 ## [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [51] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [76] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [101] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [126] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [151] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [176] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [201] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [226] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [251] NA NA NA NA NA NA NA NA NA NA NA NA NA NA どうやら取り除いていい変数のようなので以下の処理を行います。 data &lt;- select(data, -&quot;Country Code&quot;, -&quot;Indicator Name&quot;, -&quot;Indicator Code&quot;, -X64) data &lt;- rename(data, name = &quot;Country Name&quot;) names(data) ## [1] &quot;name&quot; &quot;1960&quot; &quot;1961&quot; &quot;1962&quot; &quot;1963&quot; &quot;1964&quot; &quot;1965&quot; &quot;1966&quot; &quot;1967&quot; &quot;1968&quot; ## [11] &quot;1969&quot; &quot;1970&quot; &quot;1971&quot; &quot;1972&quot; &quot;1973&quot; &quot;1974&quot; &quot;1975&quot; &quot;1976&quot; &quot;1977&quot; &quot;1978&quot; ## [21] &quot;1979&quot; &quot;1980&quot; &quot;1981&quot; &quot;1982&quot; &quot;1983&quot; &quot;1984&quot; &quot;1985&quot; &quot;1986&quot; &quot;1987&quot; &quot;1988&quot; ## [31] &quot;1989&quot; &quot;1990&quot; &quot;1991&quot; &quot;1992&quot; &quot;1993&quot; &quot;1994&quot; &quot;1995&quot; &quot;1996&quot; &quot;1997&quot; &quot;1998&quot; ## [41] &quot;1999&quot; &quot;2000&quot; &quot;2001&quot; &quot;2002&quot; &quot;2003&quot; &quot;2004&quot; &quot;2005&quot; &quot;2006&quot; &quot;2007&quot; &quot;2008&quot; ## [51] &quot;2009&quot; &quot;2010&quot; &quot;2011&quot; &quot;2012&quot; &quot;2013&quot; &quot;2014&quot; &quot;2015&quot; &quot;2016&quot; &quot;2017&quot; &quot;2018&quot; いい感じになりました。 7.2 ループによる方法 7.2.1 for文 ループ処理とは似たような操作を何度も繰り返すことです。 例えば、1から10までの数字を表示させるループ処理は次のようなコードでできます。 for (i in 1:10) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 具体的に何を行っているのでしょうか？ まず、1:10は1から10まで1刻みに増加するベクトルを作成しています。 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 そして、i in 1:10は1:10の要素を順番にiに代入し、後ろの{}内の処理を行うということを意味しています。 まず、iに1が代入され、print(i)によってiの中身の1が表示されます。 処理が終わるとiに2が代入され、print(i)によってiの中身の2が表示されます。 以上の処理がiに10が代入され、その処理が終わるまで続きます。 なお、inの左側はiである必要はなく、右側も数値である必要はありません。 letters[1:10] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; for (j in letters[1:10]) { print(j) } ## [1] &quot;a&quot; ## [1] &quot;b&quot; ## [1] &quot;c&quot; ## [1] &quot;d&quot; ## [1] &quot;e&quot; ## [1] &quot;f&quot; ## [1] &quot;g&quot; ## [1] &quot;h&quot; ## [1] &quot;i&quot; ## [1] &quot;j&quot; 7.2.2 時点の選択による方法 ループで変換する場合、2つの戦略があると思われます。 つまり、 時点を順番に選択してくっつけていく方法 ユニットを順番に選択してくっつけていく方法 です。 まずは前者の方法を行います。 データの変数名の内、最初のものを除いたものが時点になっているので、yearとしてベクトルを作成します。 year &lt;- names(data)[-1] year ## [1] &quot;1960&quot; &quot;1961&quot; &quot;1962&quot; &quot;1963&quot; &quot;1964&quot; &quot;1965&quot; &quot;1966&quot; &quot;1967&quot; &quot;1968&quot; &quot;1969&quot; ## [11] &quot;1970&quot; &quot;1971&quot; &quot;1972&quot; &quot;1973&quot; &quot;1974&quot; &quot;1975&quot; &quot;1976&quot; &quot;1977&quot; &quot;1978&quot; &quot;1979&quot; ## [21] &quot;1980&quot; &quot;1981&quot; &quot;1982&quot; &quot;1983&quot; &quot;1984&quot; &quot;1985&quot; &quot;1986&quot; &quot;1987&quot; &quot;1988&quot; &quot;1989&quot; ## [31] &quot;1990&quot; &quot;1991&quot; &quot;1992&quot; &quot;1993&quot; &quot;1994&quot; &quot;1995&quot; &quot;1996&quot; &quot;1997&quot; &quot;1998&quot; &quot;1999&quot; ## [41] &quot;2000&quot; &quot;2001&quot; &quot;2002&quot; &quot;2003&quot; &quot;2004&quot; &quot;2005&quot; &quot;2006&quot; &quot;2007&quot; &quot;2008&quot; &quot;2009&quot; ## [51] &quot;2010&quot; &quot;2011&quot; &quot;2012&quot; &quot;2013&quot; &quot;2014&quot; &quot;2015&quot; &quot;2016&quot; &quot;2017&quot; &quot;2018&quot; いきなりループを書くのは大変なので、まずはiに具体的な数値を入れてちゃんとうまく行くかを確かめます。 例えば、1960年のデータを抜き出したい場合は、そのデータを一時的に保存するものとしてtemp（temporaryの気持ち）とすると i &lt;- &quot;1960&quot; temp &lt;- data[c(&quot;name&quot;, i)] head(temp) とすればいいことがわかります。 また、ロング形式では時点の変数も必要なので、新たにyear変数を作成する必要もあります。 temp$year &lt;- i head(temp) ただし、このままではyearが文字列となっているので、as.numeric()で数値データに変換します。 temp$year &lt;- as.numeric(i) head(temp) さて、これを縦方向に繋げていけばいいのですが、一人あたりGDPの変数名が年（この場合は1960）のままなので、他の年のデータと繋げるときに面倒なことになります。 なので、変数の名前を各データで共通のものgdp_pcにしておく必要があります。 names(temp)[names(temp) == i] &lt;- &quot;gdp_pc&quot; head(temp) 最後にデータを結合する方法ですが、縦方向に結合する場合はbind_rows()を使います。 ここで、ややプログラミング特有の方法があります。 それは、まずからのデータを作成し、それにどんどん繋げていく方法です。 つまり、まずは変換後のデータを入れる空のオブジェクトとしてdata_longを作っておきます。 data_long &lt;- NULL そして、前述の処理をfor文として書きます。 ただし、例として1960としていた部分はループ処理の中で変化していくので除外しておきます。 for (i in year) { temp &lt;- data[c(&quot;name&quot;, i)] temp$year &lt;- as.numeric(i) names(temp)[names(temp) == i] &lt;- &quot;gdp_pc&quot; data_long &lt;- bind_rows(data_long, temp) } 新たに加わった処理はdata_long &lt;- bind_rows(data_long, temp)です。 ここではdata_longに各年のロング形式のデータをくっつけて、それをdata_longとして上書きしています。 まず、空のdata_longが存在します。 yearの第1要素は1960なので、1960年のデータがワイド形式になってtempに保存されます。 最後に空のdata_longと1960年のtempが結合され、新しいdata_longとして保存されます。 次にyearの第2要素は1961年なので1961年のデータがtempに保存されます。 最後に1960年のデータが入ったdata_longと1961年のデータであるtempが結合され、1960年と1961年のデータが入ったdata_longとして上書きされます。 以上の処理がyearの全ての要素について行われます。 実際にロング形式に変換されているのがわかります。 head(data_long) この方法で注意すべきなのはfor文を実行する前に新しいデータの保存先（今回の場合はdata_long）を初期化することです。 初期化を忘れて再びfor文を実行すると同じデータが重複して結合されてしまいます。 7.2.3 ユニットの選択による方法 次はユニットを選択して同様にループ処理を行います。 まず、1行目のデータを抜き出すと次のようになっています。 i &lt;- 1 data[i,] よって、国名はdata[1,1]にあり、一人あたりGDPデータは`data[1,-1]’にあることがわかります。 data[i,1] data[i,-1] ところで、新たにデータセットを作る場合にはdata.frame()（tidyverse版はtibble()）を使います。 ()に中で変数名を指定し、=の後ろで変数を定義します。 また、=の後ろはデータフレームではいけないので国名はas.character()で、一人あたりGDPと年はas.numeric()でベクトルにしておきます。 したがって、Arubaのデータをロング形式にしたものをtempとすると、 temp &lt;- tibble(name = as.character(data[i,1]), year = as.numeric(year), gdp_pc = as.numeric(data[i,-1])) head(temp) で変換できます。 あとは、先ほどと同様にfor文でくっつけていきます。 行の数だけfor文を回すのでnrow()で回数を決めます。 data_long &lt;- NULL for (i in 1:nrow(data)) { temp &lt;- tibble(name = as.character(data[i,1]), year = as.numeric(year), gdp_pc = as.numeric(data[i,-1])) data_long &lt;- bind_rows(data_long, temp) } head(data_long) 7.3 tidyverseな方法 7.3.1 ワイドからロングへ tidyversrのtidyrのpivot_longer()という関数を使うとワイド形式からロング形式に変換することができます。 慣れると簡単ですが、最初はとっつきにくいかもしれません。 結論から言うと、次のたった一行のコードで変換することができます。 data &lt;- data %&gt;% pivot_longer(-name, names_to = &quot;year&quot;, values_to = &quot;gdp_pc&quot;) data %&gt;% drop_na() %&gt;% head() さて、pivot_longer()の引数は最初のデータフレームを除いて3つあります。 最後の2つは必須の入力引数です。 まず、-nameですが、これはロング形式にする際にkey変数として使わない変数を-で指定しています。 パネルデータの場合、年に漢検なく値が不変の変数を除外する必要があります。 今回は国名を除外しました。 続いて、names_toですが、これはワイド形式における変数名（この場合は年）を新しい変数として作成する際の変数名です。 なので、ここではyearとしました。 最後に、values_toはワイド形式における変数の値（この場合は各年の一人あたりGDP）を新しい変数として作成する際の変数名です。 なので、ここではgdp_pcとしました。 ところで、実は処理はまだ終わっていません。 よく見るとyearが文字列になっているのが分かります。 なぜなら、もともと変数名だったからです。 なので、as.numeric()で数値データに変換する必要があります。 data &lt;- data %&gt;% mutate(year = as.numeric(year)) data %&gt;% drop_na() %&gt;% head() 7.3.2 パイプ ところで、tidyverseの中のmagritrには%&gt;%という代入演算子（パイプ）があります。 これは、左のオブジェクトを右の関数の第1引数にする役割を果たします。 %&gt;%はRStudioではShift + Ctrl + mで入力できます。 パイプによって、以上の処理は次のようにまとめて書くこともできます。 data &lt;- read_csv(&quot;data/wb_gdp_pc.csv&quot;, skip = 4) ## Warning: Missing column names filled in: &#39;X64&#39; [64] ## Parsed with column specification: ## cols( ## .default = col_double(), ## `Country Name` = col_character(), ## `Country Code` = col_character(), ## `Indicator Name` = col_character(), ## `Indicator Code` = col_character(), ## `2018` = col_logical(), ## X64 = col_logical() ## ) ## See spec(...) for full column specifications. data &lt;- select(data, -&quot;Country Code&quot;, -&quot;Indicator Name&quot;, -&quot;Indicator Code&quot;, -X64) data &lt;- rename(data, name = &quot;Country Name&quot;) data &lt;- data %&gt;% pivot_longer(-name, names_to = &quot;year&quot;, values_to = &quot;gdp_pc&quot;) %&gt;% mutate(year = as.numeric(year)) data %&gt;% drop_na() %&gt;% head() もっと欲張れば、これも全てパイプで繋ぐことができます。 data &lt;- read_csv(&quot;data/wb_gdp_pc.csv&quot;, skip = 4) %&gt;% select(-&quot;Country Code&quot;, -&quot;Indicator Name&quot;, -&quot;Indicator Code&quot;, -X64)%&gt;% rename(name = &quot;Country Name&quot;) %&gt;% pivot_longer(-name, names_to = &quot;year&quot;, values_to = &quot;gdp_pc&quot;) %&gt;% mutate(year = as.numeric(year)) ## Warning: Missing column names filled in: &#39;X64&#39; [64] ## Parsed with column specification: ## cols( ## .default = col_double(), ## `Country Name` = col_character(), ## `Country Code` = col_character(), ## `Indicator Name` = col_character(), ## `Indicator Code` = col_character(), ## `2018` = col_logical(), ## X64 = col_logical() ## ) ## See spec(...) for full column specifications. data %&gt;% drop_na() %&gt;% head() 7.3.3 tidyverseの利点 tidyverseは今、Rで非常に人気のあるパッケージで少なくない人がtidyverseの関数を使い、パイプでコードを書いています。 もちろん、tidyverseを使わない人もいますし、使わないといけないわけでもありません。 必要以上に特定のパッケージに依存するのは危険だと思います。 ここではtidyverseを使うことの利点をまとめておきます。 コードが短くなる。 ループでは必要だったdata_longのような保存先を作る必要がない。 パイプを使うと処理の順番にコードが書かれているので分かりやすい。 7.3.4 ロングからワイドへ ちなみに、tidyrのpivot_wider()を使うとロング形式からワイド形式に変換できます。 data &lt;- data %&gt;% pivot_wider(names_from = &quot;year&quot;, values_from = &quot;gdp_pc&quot;) data names(data) ## [1] &quot;name&quot; &quot;1960&quot; &quot;1961&quot; &quot;1962&quot; &quot;1963&quot; &quot;1964&quot; &quot;1965&quot; &quot;1966&quot; &quot;1967&quot; &quot;1968&quot; ## [11] &quot;1969&quot; &quot;1970&quot; &quot;1971&quot; &quot;1972&quot; &quot;1973&quot; &quot;1974&quot; &quot;1975&quot; &quot;1976&quot; &quot;1977&quot; &quot;1978&quot; ## [21] &quot;1979&quot; &quot;1980&quot; &quot;1981&quot; &quot;1982&quot; &quot;1983&quot; &quot;1984&quot; &quot;1985&quot; &quot;1986&quot; &quot;1987&quot; &quot;1988&quot; ## [31] &quot;1989&quot; &quot;1990&quot; &quot;1991&quot; &quot;1992&quot; &quot;1993&quot; &quot;1994&quot; &quot;1995&quot; &quot;1996&quot; &quot;1997&quot; &quot;1998&quot; ## [41] &quot;1999&quot; &quot;2000&quot; &quot;2001&quot; &quot;2002&quot; &quot;2003&quot; &quot;2004&quot; &quot;2005&quot; &quot;2006&quot; &quot;2007&quot; &quot;2008&quot; ## [51] &quot;2009&quot; &quot;2010&quot; &quot;2011&quot; &quot;2012&quot; &quot;2013&quot; &quot;2014&quot; &quot;2015&quot; &quot;2016&quot; &quot;2017&quot; &quot;2018&quot; "],
["qualtrics.html", "第8章 Qualtricsデータの処理* 8.1 Qualtricsのデータ 8.2 気合による方法 8.3 ループによる方法 8.4 tidyverseな方法 8.5 おまけ", " 第8章 Qualtricsデータの処理* Qualtricsはオンラインサーベイを便利に行うツールですが、政治学では特にサーベイ実験で使われていると思います。 サーベイ実験では被験者ごとに処理をランダムに与える必要があり、Qualtricsでは簡単にそれを行うことができるのですが、得られたデータを統計分析する際には一手間かかります。 ここでは、[ロング・ワイドの変換]で紹介したワイド形式からロング形式に変換する方法を応用してQualtricsのデータを統計分析用に整形する方法を説明します。 library(tidyverse) 8.1 Qualtricsのデータ ここではQualtricsから得られる架空のデータを使いたいと思います。 Qualtricsでは行は各被験者でユニークな識別番号の他に設問への回答が記載されています。 サーベイ実験ではグループごとに異なる設問がなされるため、例えば、グループが2つでグループ固有の設問が2種類、共通の設問が2種類の場合、以下のような形になっています。 data &lt;- tibble(id = c(1,2,3,4), y1_1 = c(2,3,NA,NA), y2_1 = c(1,4,NA,NA), y1_2 = c(NA,NA,5,3), y2_2 = c(NA,NA,6,4), x1 = c(2,3,3,6), x2 = c(6,4,1,1)) data 1, 2番目の被験者がグループ1で、3, 4番目の被験者がグループ2である。 便宜上、グループ1を統制群、グループ2を処置群とする。 グループ1の固有の設問の1つ目の回答がy1_1で2つ目の回答がy2_1である。 よってグループ1の被験者のy1_2とy2_2への回答は欠損値扱いになっている。 グループ2についても同様である。 全員共通の設問への回答はx1とx2である。 5件法の場合、「回答しない」は6番目の回答であることが多いため、被験者1はx2への、被験者3はy2_2への、被験者4はx1への回答を拒否したものとする。 このデータを統計的に分析するには以下のような形式になっていることが望ましいです。 tは処置群であれば1、統制群であれば0となるような変数である。 8.2 気合による方法 変数やグループの数が少ない場合は気合で書いてしまうという手もあります。 つまり、 統制群の応答変数y1_1とy2_1および共変量x1とx2を選択する。 応答変数の名前をy1とy2に共通化する。 応答変数が欠損しているサンプルは処置群なので除外する。 という方法です。 control &lt;- data[c(&quot;id&quot;, &quot;y1_1&quot;, &quot;y2_1&quot;, &quot;x1&quot;, &quot;x2&quot;)] names(control) &lt;- c(&quot;id&quot;, &quot;y1&quot;, &quot;y2&quot;, &quot;x1&quot;, &quot;x2&quot;) control &lt;- control[!is.na(control$y1) &amp; !is.na(control$y2),] control$t &lt;- 0 control control[!is.na(control$y1) &amp; !is.na(control$y2),]は「第1の応答変数が欠損していない」かつ「第2の応答変数が欠損していない」サンプルを指定しています。 同様の処理を処置群についても行います。 treatment &lt;- data[c(&quot;id&quot;, &quot;y1_2&quot;, &quot;y2_2&quot;, &quot;x1&quot;, &quot;x2&quot;)] names(treatment) &lt;- c(&quot;id&quot;, &quot;y1&quot;, &quot;y2&quot;, &quot;x1&quot;, &quot;x2&quot;) treatment &lt;- treatment[!is.na(treatment$y1) &amp; !is.na(treatment$y2),] treatment$t &lt;- 1 treatment 最後に、両者を結合し、6を欠損値に入れ替えます。 data_reshaped &lt;- bind_rows(control, treatment) data_reshaped[data_reshaped$y2 == 6,]$y2 &lt;- NA data_reshaped[data_reshaped$x1 == 6,]$x1 &lt;- NA data_reshaped[data_reshaped$x2 == 6,]$x2 &lt;- NA data_reshaped 8.3 ループによる方法 この方法はグループの数は多くなるとめんどくさくなるという欠点があります。 各グループについては同様の処理を行うので、forループによって簡略化することができます。 アイデアとしてはi回目の処理においてid共変量とy1_iとy2_iを抜き出します。 文字列はpaste0()という関数で結合することができます。 paste0(&quot;y1_&quot;, 1) ## [1] &quot;y1_1&quot; ちなみに、paste()は文字列の間に特定の記号を含める関数です。 paste(&quot;a&quot;, &quot;b&quot;, sep = &quot;/&quot;) ## [1] &quot;a/b&quot; つまり、paste0()はpaste(..., sep = &quot;)のラッパー関数です。 さて、ここではiを1として選択する変数の名前をsel_varsというベクトルとして作成します。 i &lt;- 1 sel_vars &lt;- c(&quot;id&quot;, paste0(c(&quot;y1_&quot;, &quot;y2_&quot;), i), &quot;x1&quot;, &quot;x2&quot;) sel_vars ## [1] &quot;id&quot; &quot;y1_1&quot; &quot;y2_1&quot; &quot;x1&quot; &quot;x2&quot; 無事、必要な変数名を抜き出せています。 temp &lt;- data[sel_vars] temp その他の処理は先ほどと変わらないので、まとめると次のようになります。 data_reshaped &lt;- NULL for (i in 1:2) { sel_vars &lt;- c(&quot;id&quot;, paste0(c(&quot;y1_&quot;, &quot;y2_&quot;), i), &quot;x1&quot;, &quot;x2&quot;) temp &lt;- data[sel_vars] names(temp) &lt;- c(&quot;id&quot;, &quot;y1&quot;, &quot;y2&quot;, &quot;x1&quot;, &quot;x2&quot;) temp &lt;- temp[!is.na(temp$y1) &amp; !is.na(temp$y2),] temp$t &lt;- i - 1 data_reshaped &lt;- bind_rows(data_reshaped, temp) } data_reshaped[data_reshaped$y2 == 6,]$y2 &lt;- NA data_reshaped[data_reshaped$x1 == 6,]$x1 &lt;- NA data_reshaped[data_reshaped$x2 == 6,]$x2 &lt;- NA data_reshaped 処置変数はグループ番号から1を引いていますが本質的な問題ではありません。 8.4 tidyverseな方法 実はtidyverseのtidyrを応用するとこのような処理をすることができます。 まずは、応答変数に関してgather()でロングにします。 data_reshaped &lt;- data %&gt;% pivot_longer(-c(id, x1, x2), names_to = &quot;t&quot;, values_to = &quot;y&quot;) data_reshaped ポイントはこの段階で応答変数yが欠損値になっているのは、グループが異なる回答ということです。 グループ1の被験者にとってのy1_2とy2_2 グループ2の被験者にとってのy1_1とy2_1 なので、指定した変数が欠損値であるサンプルを除外する関数drop_na()でyが欠損しているサンプルを除外します。 data_reshaped &lt;- data_reshaped %&gt;% drop_na(y) data_reshaped 続いて、適当に名付けておいたtからグループの情報と応答変数の種類の情報を抜き出します。 str_extraxt()という関数は文字列からパターンに合致したものを抜き出します。 str_extract(&quot;y1_1&quot;, &quot;y[0-9]&quot;) ## [1] &quot;y1&quot; パターンのマッチングには正規表現というやや難しい表記が必要になります。 y[0-9]というのはyという文字と数字が1文字続く文字列という意味です。 str_extract(&quot;y1_1&quot;, &quot;_[0-9]&quot;) ## [1] &quot;_1&quot; 同様にしてグループの情報も抜き出せますが、_が邪魔です。 文字列から数値を抜き出す関数はparse_naumber()になります。 str_extract(&quot;y1_1&quot;, &quot;_[0-9]&quot;) %&gt;% parse_number() ## [1] 1 これでグループと応答変数の種類の情報を抜き出す準備が整いました。 以下ではtにグループ番号をkに応答変数の種類を入れる操作をします data_reshaped &lt;- data_reshaped %&gt;% mutate(k = str_extract(t, &quot;y[0-9]&quot;), t = str_extract(t, &quot;_[0-9]&quot;) %&gt;% parse_number()) data_reshaped 続いて、kの中身y1とy2を変数名に戻すためにspread()を使います。 data_reshaped &lt;- data_reshaped %&gt;% pivot_wider(names_from = &quot;k&quot;, values_from = &quot;y&quot;) data_reshaped 最後に欠損値をna_if()で代入しておきます。 data_reshaped &lt;- data_reshaped %&gt;% mutate(y2 = na_if(y2, 6), x1 = na_if(x1, 6), x2 = na_if(x2, 6)) data_reshaped 以上をパイプでまとめると次のようになります。 data_reshaped &lt;- data %&gt;% pivot_longer(-c(id, x1, x2), names_to = &quot;t&quot;, values_to = &quot;y&quot;) %&gt;% drop_na(y) %&gt;% mutate(k = str_extract(t, &quot;y[0-9]&quot;), t = str_extract(t, &quot;_[0-9]&quot;) %&gt;% parse_number()) %&gt;% pivot_wider(names_from = &quot;k&quot;, values_from = &quot;y&quot;) %&gt;% mutate(y2 = na_if(y2, 6), x1 = na_if(x1, 6), x2 = na_if(x2, 6)) data_reshaped ループを用いるか、tidyverseを用いるかにかかわらず重要なのは変数名の設定です。 応答変数と共変量をグループごとに定型的な変数名としておくことで処理が楽になります。 8.5 おまけ 5件法の場合、回答上では 賛成 やや賛成 どちらとも言えない やや反対 反対 となっていることが多いですが、分析上では 反対 やや反対 どちらとも言えない やや賛成 賛成 としたいのが人情です。 こういうときは、6（ないし5）から引いてあげればよいです。 data_reshaped %&gt;% mutate(y1 = 5 - y1, y2 = 5 - y2) "],
["desc-stats.html", "第9章 データの要約 9.1 データを見る 9.2 記述統計 9.3 データのカウント 9.4 グループごとの要約 9.5 ユニークなデータ*", " 第9章 データの要約 データを読み込んで最初にすることは、データの概形を掴むことだと思います。 分析に入る前に、データがどのような特徴を持っているのか、データを作成した場合はミスをしていないかを確認するべきでしょう。 データから代表的な値を計算することでデータを要約することができます。 このような方法を記述統計 (descriptive statistics) と呼びます。 もう一つのアプローチはグラフなどを描いて視覚的に把握することですが、これは後述します。 library(tidyverse) library(summarytools) ## Registered S3 method overwritten by &#39;pryr&#39;: ## method from ## print.bytes Rcpp ## For best results, restart R session and update pander using devtools:: or remotes::install_github(&#39;rapporter/pander&#39;) ## ## Attaching package: &#39;summarytools&#39; ## The following object is masked from &#39;package:tibble&#39;: ## ## view 9.1 データを見る データを把握する最もナイーブな方法は生のデータを見ることです。 例えば、.csvや.xlsファイルであれば適当な表計算ソフトで開くことで見ることができます。 また、View()という関数でRに取り込んだデータを見ることもできます。 tri &lt;- read_csv(&quot;data/triangle.csv&quot;) ## Parsed with column specification: ## cols( ## statea = col_double(), ## stateb = col_double(), ## year = col_double(), ## dependa = col_double(), ## dependb = col_double(), ## demauta = col_double(), ## demautb = col_double(), ## allies = col_double(), ## dispute1 = col_double(), ## logdstab = col_double(), ## lcaprat2 = col_double(), ## smigoabi = col_double(), ## opena = col_double(), ## openb = col_double(), ## minrpwrs = col_double(), ## noncontg = col_double(), ## smldmat = col_double(), ## smldep = col_double(), ## dyadid = col_double() ## ) View(tri) しかし、大抵の場合、観察数が多すぎてデータをそのまま見てもなんだかよく分からないことが多いです。 データが大きすぎると開くのに時間がかかることもあります。 まずは、head()によって、データの冒頭だけ見るのがよいでしょう。 これによって、データの形式が想定通りか暫定的にチェックできます。 head(tri) tail()を使うとデータの最後を見ることがきでます。 9.2 記述統計 記述統計とは変数をいくつかの指標によって表現することを言います。 9.2.1 平均 平均 (mean) は次のように定義されます。 \\[ \\bar{x}_i = \\sum_{i=1}^n \\frac{x_i}{n} \\] Rでは、まずデータフレームから変数を抜き出し、mean()に入れます。 mean(tri$smldep) ## [1] 0.002328343 ちなみに、欠損値がある場合はNAとなるので、na.rm = TRUEというオプションを付けます。 smldepは二国間の相互依存度を示しています。 tidyverse風に書くなら、次のようになります。 tri %&gt;% pull(smldep) %&gt;% mean() ## [1] 0.002328343 pull()でベクトルを抜き出すことができます。 9.2.2 分散と標準偏差 分散 (variance) は次のように定義され、変数の散らばりを意味します。 \\[ \\sigma^2 = \\sum_{i=1}^n \\frac{(x - \\bar{x})^2}{n} \\] Rではvar()によって求めます。 厳密に言えば、不偏分散と呼ばれるもので、\\(n\\)の代わりに\\(n-1\\)で割られています。 var(tri$smldep) ## [1] 5.220904e-05 分散の平方根\\(\\sigma\\)を標準偏差 (standard error) と呼びsd()で計算します。 sd(tri$smldep) ## [1] 0.007225582 実際に二乗すると分散と同じ値になります。 sd(tri$smldep)^2 ## [1] 5.220904e-05 9.2.3 分位点 \\(q\\)%分位点 (quantile) とは、下から数えて\\(q\\)％に当たる点を意味します。 例えば、50%分位点は、中央値 (median) とも呼ばれ、上から見ても下から見てもちょうど真ん中に位置します。 中央値はmedian()で求めることができ、一般的に分位点はquantile()で求めることができます。 median(tri$smldep) ## [1] 0.0002466768 quantile(tri$smldep, 0.5) ## 50% ## 0.0002466768 どっちも同じであることが分かります。 quantile()は一度に複数の分位点を求めることができます。 quantile(tri$smldep, c(0.25, 0.5, 0.75)) ## 25% 50% 75% ## 9.789278e-06 2.466768e-04 1.486773e-03 25%と75%分位点は第1四分位点、第3四分位点とも呼ばれ、中央値と共に報告されることが多いです。 9.2.4 記述統計表 通常は、特定の変数だけの記述統計を報告するということはなく、分析で使用する変数全てについて報告します。 summary()にデータフレームを入れると、全体の記述統計を出してくれます。 summary(tri) ## statea stateb year dependa ## Min. : 2 Min. : 20.0 Min. :1885 Min. :0.0000000 ## 1st Qu.:100 1st Qu.:300.0 1st Qu.:1935 1st Qu.:0.0000233 ## Median :212 Median :438.0 Median :1967 Median :0.0006987 ## Mean :248 Mean :473.5 Mean :1957 Mean :0.0068491 ## 3rd Qu.:365 3rd Qu.:710.0 3rd Qu.:1979 3rd Qu.:0.0038495 ## Max. :900 Max. :950.0 Max. :1991 Max. :0.8484982 ## ## dependb demauta demautb allies ## Min. :0.0000000 Min. :-10.000 Min. :-10.000 Min. :0.0000 ## 1st Qu.:0.0000317 1st Qu.: -7.000 1st Qu.: -7.000 1st Qu.:0.0000 ## Median :0.0019763 Median : 6.000 Median : -5.000 Median :0.0000 ## Mean :0.0175759 Mean : 2.538 Mean : -1.165 Mean :0.2155 ## 3rd Qu.:0.0153196 3rd Qu.: 10.000 3rd Qu.: 8.000 3rd Qu.:0.0000 ## Max. :0.6529297 Max. : 10.000 Max. : 10.000 Max. :1.0000 ## ## dispute1 logdstab lcaprat2 smigoabi ## Min. :0.000 Min. :1.872 Min. :0.000103 Min. : 0.00 ## 1st Qu.:0.000 1st Qu.:6.740 1st Qu.:1.486062 1st Qu.: 13.00 ## Median :0.000 Median :8.042 Median :2.830705 Median : 22.00 ## Mean :0.047 Mean :7.626 Mean :2.978976 Mean : 25.33 ## 3rd Qu.:0.000 3rd Qu.:8.630 3rd Qu.:4.246247 3rd Qu.: 34.00 ## Max. :1.000 Max. :9.407 Max. :9.494078 Max. :130.00 ## ## opena openb minrpwrs noncontg ## Min. :0.0008 Min. :0.0008 Min. :0.0000 Min. :0.0000 ## 1st Qu.:0.1261 1st Qu.:0.1149 1st Qu.:0.0000 1st Qu.:0.0000 ## Median :0.2346 Median :0.2439 Median :0.0000 Median :1.0000 ## Mean :0.3083 Mean :0.3237 Mean :0.2356 Mean :0.6307 ## 3rd Qu.:0.4263 3rd Qu.:0.4550 3rd Qu.:0.0000 3rd Qu.:1.0000 ## Max. :1.9985 Max. :1.9985 Max. :1.0000 Max. :1.0000 ## NA&#39;s :1204 NA&#39;s :2731 ## smldmat smldep dyadid ## Min. :-10.000 Min. :0.000e+00 Min. : 2020 ## 1st Qu.: -8.000 1st Qu.:9.790e-06 1st Qu.:100365 ## Median : -7.000 Median :2.467e-04 Median :212220 ## Mean : -3.311 Mean :2.328e-03 Mean :248516 ## 3rd Qu.: 1.000 3rd Qu.:1.487e-03 3rd Qu.:365439 ## Max. : 10.000 Max. :1.719e-01 Max. :900910 ## ただし、これをそのまま論文などに載せるのはカッコよくありません。 そこで、summarytoolsというパッケージを使います。 データフレームにすることにこだわらないのであれば、stargazerというパッケージでもいいと思います。 descr()という関数でmarkdownのテーブル形式で表示します。 descr(tri, transpose = TRUE) その結果をさらにtb()に入れることで、データフレームにできるので、.csvファイルなどとして書き出すこともできます。 tri %&gt;% descr() %&gt;% tb() また、dfSummary()とview()でファンシーに表示してくれます。 tri %&gt;% dfSummary() %&gt;% summarytools::view() summarytools::view()としているのは、tidyrにもview()という関数があるので、summarytoolsのもであることを明示するためです。 9.3 データのカウント 例えば、戦争が起こった・起こらなかった、のようにカテゴリカル変数の場合、上記の記述統計を用いるより、数えてしまう方が良いことがあります。 table()で数えることができます。 table(tri$dispute1) ## ## 0 1 ## 38116 1880 table()に複数の便数を入れることで、クロス表を作ることもできます。 table(tri$dispute1, tri$noncontg) ## ## 0 1 ## 0 13492 24624 ## 1 1279 601 tidyverseにはcount()という関数があり、数えることができます。 tri %&gt;% count(dispute1) tri %&gt;% count(dispute1, noncontg) count()の結果をクロス表にするにはpivot_wider()を使います。 summarytools()であれば、freq()やctable()を使います。 freq(tri$dispute1) ## Frequencies ## tri$dispute1 ## Type: Numeric ## ## Freq % Valid % Valid Cum. % Total % Total Cum. ## ----------- ------- --------- -------------- --------- -------------- ## 0 38116 95.30 95.30 95.30 95.30 ## 1 1880 4.70 100.00 4.70 100.00 ## &lt;NA&gt; 0 0.00 100.00 ## Total 39996 100.00 100.00 100.00 100.00 ctable(tri$dispute1, tri$noncontg) ## Cross-Tabulation, Row Proportions ## dispute1 * noncontg ## Data Frame: tri ## ## ---------- ---------- --------------- --------------- ---------------- ## noncontg 0 1 Total ## dispute1 ## 0 13492 (35.4%) 24624 (64.6%) 38116 (100.0%) ## 1 1279 (68.0%) 601 (32.0%) 1880 (100.0%) ## Total 14771 (36.9%) 25225 (63.1%) 39996 (100.0%) ## ---------- ---------- --------------- --------------- ---------------- 9.4 グループごとの要約 特定のグループごとに記述統計を求めたい場合があるとします。 このような場合、tidyverseのgroup_by()とsummarise()を組み合わせます。 例えば、次のようにして各年のsmldepの平均値を求めることができます。 tri %&gt;% group_by(year) %&gt;% summarise(mean_smldep = mean(smldep)) group_by()はsummarytoolsでも使えます。 紛争が起こっているかどうかでグループ分けをします。 tri %&gt;% group_by(dispute1) %&gt;% descr() %&gt;% tb() 9.5 ユニークなデータ* "],
["r-envir.html", "第10章 Rの分析環境 10.1 Rのインストール 10.2 RStudioのインストール 10.3 再現可能な分析のために", " 第10章 Rの分析環境 Rは統計用のプログラミング言語です。 他に、特に機械学習の分野ではPythonやJuliaも人気です。 政治学や経済学ではStataという統計ソフトも人気ですが有料という難点があります。 また、RStudioはRを便利に使うための統合開発環境 (IDE) です。 RStudio以外にもあるもののデファクトスタンダードになっている感はあります。 RStudioはあくまでRを使いやすくするためのもので、R本体ではありません。 なので、まずはRをインストールしてからRStudioをインストールします。 10.1 Rのインストール 10.1.1 ダウンロード まずはRの公式サイトへ行き（右クリックで新しいタブで開くことができます）、download Rをクリックします。 次にダウンロードする際のミラーサイトを選びます。 好きな国のものを選んでいいですが、ここでは日本の統計数理研究所のものを選んでおきます。 自分のPCのOSに応じたものを選択します。 10.1.1.1 Windowsの場合 install R for the first timeを選択します。 Downlosd R X.X.X for YYYを選択してダウンロードします。 分かりやすいようにダウンロードフォルダにダウンロードしておきます。 Windowsの場合、Rtoolsをインストールもインストールしておきましょう。 10.1.1.2 Macintoshの場合 10.1.2 インストール Rをダウンロードしたフォルダを開き、ファイルをクリックします。 ファイル名はOSによって異なります。 その後は表示されるままに進めていけばよいです。 Rは基本的にOSの言語で表示されますが、英語で使いたい場合はMessage Translationsのインストールにチェックが入っている場合は外しておきましょう。 英語のエラーメッセージで検索したほうが解決策が見つけやすくなります。 10.2 RStudioのインストール 10.2.1 ダウンロード RStudioの公式サイトからRStudioのダウンロードサイトへ行きます。 下の方にインストーラーをダウンロードするリンクがあるのでOSに応じたものを選択します。 安定版ではないけれど最新のRStudioを使いたい人はRStudio Previewをインストールしてください。 また、RやRStudioをインストールせずにオンラインで使用できるRStudio Cloudというものもあります。 10.2.2 インストール あとはダウンロードしたフォルダに移り、インストーラーを起動して表示されるがままに進めていきます。 10.2.3 RStudioの起動 RStudioのショートカットをクリックしたり、メニューでRStudioと入力してクリックすると起動するはずです。 RStudioを初めて起動すると次のような表示になるとはずです。 左側の大きなパネルでRが表示されていればインストールの成功です。 ちなみに、Tools &gt; Global Options &gt; Appearanceではフォントや背景・ハイライトの色を変えることができます。 ダークな背景を選択するとRStudio全体もダークテーマになります。 10.2.4 RStudio Cloud* RStudio CLoudにより、RStudioをブラウザを使ってオンラインで使用することができます。 複数のユーザーで共同作業を行うことも可能です。 LinuxユーザーはRStudio Serverを使って自らサーバを立てることもできます。 10.3 再現可能な分析のために 再現可能性 (replicability) とは、狭義では、誰がどんな環境で分析しても。オリジナルの分析結果と（ほぼ）同じものを得られることだと思っています。 以下では、再現可能性を担保できるようなR/RStudioの使い方を解説します。 10.3.1 Rスクリプト まず、分析の手順を記録に残し、公開する必要があります。 RではRスクリプトと呼ばれるファイル（拡張子は.R）を作成し、そこにコードを残して起きます。 もちろん、使用したデータも公開する必要があるのは言うまでもありません。 10.3.1.1 Rスクリプトの作成 RStudioでは左上のFile &gt; New File &gt; RScriptもしくは白い紙に緑色のプラスマークのボタンを押してR Scriptを選択します。 すると、デフォルトでは左上のパネルにRスクリプトのエディタが表示されます。 10.3.1.2 Rスクリプトの展開 RスクリプトをRStudioで開くには左上のFile &gt; Open Fileで選択します。 10.3.1.3 Rスクリプトの実行 Rスクリプトに書かれたコードはCtrl + Enterを押すと、カーソルのある行がコンソールに流れ、実行されます。 10.3.2 Rプロジェクト データの読み込みで解説したように、データの読み込みや保存の際には起点となる作業ディレクトリ (working directory) を決める必要があります。 一般的に、作業ディレクトリはPCによって変わってしまうので、Rプロジェクトを立てることでその問題を回避します。 簡単に言えば、Rプロジェクトをクリックすることで自動的に作業ディレクトリが設定された状態でRStudioを起動することができます。 また、プロジェクトごとにRStudioを起動できるので、異なるプロジェクト間でデータやRスクリプトが混在することも回避できます。 ひとまず、新しい分析を行う際は必ずRプロジェクトを作成するようにしましょう。 10.3.2.1 Rプロジェクトの作成 まずは、プロジェクトの作り方ですが、RStudioの左上の青いボタンをクリックします。 続いて、新たにプロジェクト用のフォルダを作るのであればNew Directoryを、既存のフォルダをプロジェクト用にするのであればExisting Directoryを選択します。 基本的にはNew Projectを選択します。 最後に、プロジェクト用のフォルダの名前とそのフォルダを置くフォルダのパスを指定してCreate Projectをクリックします。 フォルダ名は必ず英数字と-や_で書き、日本語は避けましょう。 既存のフォルダを使う場合はパスを指定するだけです。 例えば今回はDocumentsフォルダの中にtestという名前のプロジェクトを作成しました。 一度、RStudioを終了し、先程指定したパス通りの場所にフォルダができていることを確認してください。 そのフォルダの中に、プロジェクト名と同じ名前の.Rprojファイルができているはずです。 10.3.2.2 プロジェクトの起動 それをダブルクリックしてみるとRStudioが起動されます。 このとき、すでに作業ディレクトリはプロジェクト用フォルダに指定されているのです。 getwd()で作業ディレクトリを確認してみて下さい。 10.3.2.3 ワークスペースの保存と再開* どうしても一度分析を中断して、再開したい場合はワークスペースを保存しておきましょう。 上記画面でSave workflow to .RData on exitがAskになっている場合、RStudioを終了する際にワークスペースを保存するのか聞かれるはずなので、保存します。 ちなみに、.RDataファイルはRのワークスペース（の一部）を保存するデータ形式です。 すると、フォルダ内に.RDataファイルができるので、再開するときにload()に当該ファイルのパスを入力して実行するとワークスペースが復元されます。 10.3.3 RStudioの設定* 10.3.3.1 RStudio起動時の挙動 Tools &gt; Global Optionsを開き、Genralの中で以下のチェックを外します。 平たく言うとRStudioを起動したときに前回の続きが残っていない真っさらな状態にしておきます。 10.3.3.2 文字コード 日本語がしばしば文字化けすることがあります。 なぜならWindowsではShift-JIS、LinuxとMacではUTF-8と呼ばれるエンコーディング（平たく言うとPCが文字を表示する方法）形式だからです。 詳しくはRにおける文字コードを参照して下さい。 UTF-8が世界的に使われているので、Code &gt; Saving &gt; Default text encodingをUTF-8にしておきます。 もし、日本語を含むファイルをRStudioで開いたときに文字化けしている場合、Windowsを使っている人はUTF-8のファイルをShift-JISで開いたということなので、File &gt; Reopen with EncodingでUTF-8を選択します。 逆にMacの場合はShift-JISのファイルをUTF-8で開いているので同様にShift-JISで開きます。 Windowsの人はUTF-8をデフォルトのエンコーディングにしてしまうといいでしょう。 "],
["intro-r.html", "第11章 Rプログラミング入門 11.1 関数 11.2 オブジェクト 11.3 パッケージ", " 第11章 Rプログラミング入門 Rによるプログラミングの基本として、 オブジェクト 関数 パッケージ について解説します。 大雑把に言えば、Rではオブジェクトとしてデータを読み込み、関数によってオブジェクト（＝データ）の処理や分析を行います。 パッケージによって様々な関数を追加することで、処理や分析の幅を広げます。 RStudioでは左（下）にコンソールが表示され、&gt;の右側にコマンドを打ち込み、Enterを押すことで実行されます。 本格的に分析する場合はRスクリプトを作成します。 11.1 関数 関数 (function) とは何かを入力すると、何かを出力するものです。 例えば、 print(&quot;Hello, World.&quot;) ## [1] &quot;Hello, World.&quot; というコードは、&quot;Hello, World.&quot;という文字列をprint()という関数に入力し、その文字列を出力しています。 Rでは、関数は関数名()という形を取ります。 入力するものを入力引数 (input argument) 、出力するものを出力引数 (output argument) と呼んだりします。 次のように、入力引数も出力引数も1つとは限りません。 rnorm(n = 10, mean = 0, sd = 1) ## [1] 0.54469082 0.05750223 -0.41409653 -2.33305301 -0.73235764 -0.17190804 ## [7] 0.15130006 0.26668146 1.40493837 -0.18509483 さて、この関数は何をしているのでしょうか。 Rでは、関数名の前に?をつけて実行することで、その関数のヘルプを見ることができます。 ?rnorm 英語で関数の使い方が解説されていますが、rnorm(n = 10, mean = 0, sd = 1)は平均0、標準偏差1の（標準）正規分布に従う乱数を10個だけ生じさせています。 入力引数は=で明示的に指定する場合、どのような順番でも構いません。 rnorm(mean = 0, sd = 1, n = 10) 入力引数を明示的に指定しない場合、ヘルプにある順番で入力します。 以下の例は上述のものと同じです。 rnorm(10, 0, 1) また、ヘルプでmean = 0, sd = 1のように書かれている場合、デフォルトが定められています。 実行者が入力引数を指定しない限り、デフォルト値が使用されます。 したがって、以下の例もこれまでと同じコードです。 rnorm(10) 11.1.1 総称関数* 総称関数 (generic function) とは、Rにおいて入力引数の種類に応じて挙動が変わる関数のことを指します。 例えば、summary()という関数はデータフレームが入力引数の場合には記述統計を表示しますが、回帰分析の結果の場合は回帰表を出力します。 総称関数のヘルプを見る場合は、以下のように、関数名に.をつけて入力引数の種類を書きます。 ?summary.data.frame ?summary.lm 11.2 オブジェクト Rでは&lt;-でオブジェクトを作成することができます。 例えば、20個の正規分布に従う乱数をxという名前のオブジェクトとして作成します。 x &lt;- rnorm(20) RStudioでは&lt;-はショートカットAlt + -で入力できます。 実際に、乱数がxに格納されていることが分かります。 x ## [1] 0.887128727 1.382090710 0.564927748 -1.857431260 0.698096799 ## [6] -2.381830884 2.695714386 -0.725434802 0.193875116 -0.441517470 ## [11] 1.273162715 0.006180365 -2.163209009 -0.187561751 -0.348745175 ## [16] -1.481590144 2.345780861 -0.323815016 -1.823892922 0.078873992 RStudioの場合、右上のEnvironmentパネルに生成されたオブジェクトが表示されます。 オブジェクトを入力引数とすることも可能です。 xの平均と標準偏差を求めてみます。 mean(x) ## [1] -0.08045985 sd(x) ## [1] 1.416365 もちろん、出力引数を新しいオブジェクトにすることもできます。 x.mean &lt;- mean(x) x.mean ## [1] -0.08045985 オブジェクトの名前にはアルファベットと数字、.と_が使えます。 ただし、数字は最初の文字としては使えません。 オブジェクトは上書きすることもできます。 x.mean &lt;- mean(rnorm(20)) x.mean ## [1] -0.0566962 先ほどとは違う値に上書きされていることが分かります。 11.3 パッケージ 大雑把に言って、Rによるデータ分析はデータをオブジェクトとして読み込み、いろいろな関数で処理を行うことで実行します。 つまり、関数が重要なのですが、Rで標準に備わっている関数には限界があります。 そこで、様々な研究者が関数を作成し、それをまとめたものをパッケージとして公開しています。 基本的に、CRANでパッケージは公開されます。 ライブラリやモジュールと呼んだりすることもあります。 11.3.1 CRANからのインストール パッケージをインストールするには、install.packages()という関数にパッケージ名を入れて実行します。 試しに、Tidyverseという幅広く使われているパッケージをインストールしてみます。 install.packages(&quot;tidyverse&quot;) &quot;でパッケージ名を囲まないとエラーになります。 install.packages(tidyverse) ## Error in install.packages(tidyverse): object &#39;tidyverse&#39; not found RStudioの場合、Packagesパネル（デフォルトの場合は右下）の中にInstallというボタンがあり、 そこにパッケージ名を入力してインストールすることも可能です。 インストールしたパッケージに対して再びinstall.packages()を行うと、最新版にアップデートされます。 RStudioの場合、PackagesパネルにUpdateというボタンがあり、アップデートできるパッケージを自動検索してくれます。 11.3.2 GitHubからのインストール* パッケージの開発版や一部のパッケージはGitHub上で公開されています。 GitHub上のパッケージをインストールする場合はdevtoolsというパッケージを使うので、まずはインストールと読み込みを行います。 install.packages(&quot;devtools&quot;) library(devtools) インストールにはinstall_github()を使いますが、入力はパッケージ名ではなくユーザー名/レポジトリ名となる点に注意してください。 11.3.3 パッケージの読み込み パッケージはインストールしただけでは使用することはできず、library()で読み込む必要があります。 library(tidyverse) この場合は&quot;で囲む必要はありません。 インストールは一回で十分です。 RStudioであればPackagesパネルにインストール済みのパッケージ一覧があるので、パッケージ名をクリックすると含まれる関数一覧を見ることができます。 同様のものはCRANでもpdf形式で見ることができます。 一部のソフトウェアはJournal of Statistical Softwareなどで論文が公開されています。 11.3.4 tidyverseとは* Tidyverseとは広義にはRにおけるデータ処理を行うためのパッケージを開発するプロジェクトであり、狭義にはそこで開発されたパッケージの一部を指します。 具体的には、 ggplot2 dplyr tidyr readr purrr tibble stringr forcats になります。 パッケージとしてのtidyverseを読み込むことで、上記のパッケージを読み込んでいます。 なお、プロジェクト全体としては、上記のもの以外にも多くのパッケージが開発されています。 "],
["inter-r.html", "第12章 Rプログラミング応用* 12.1 オブジェクトのクラス 12.2 関数の作成 12.3 ループ 12.4 条件分岐 12.5 練習問題", " 第12章 Rプログラミング応用* Rによる、より高度な作業のために 代表的なオブジェクトのクラス オリジナルの関数の作成 ループや条件分岐 などを学びます。 12.1 オブジェクトのクラス オブジェクトの種類をクラスと呼びます。 class()にオブジェクトを入力するとクラスが分かります。 最も使われるのは数値 ()numeric, real) です。 class(1) ## [1] &quot;numeric&quot; 厳密には数値と整数 (integer) は異なりますが、気にしないといけない局面は少ないと思います。 class(2L) ## [1] &quot;integer&quot; 他には、文字列 (character) や class(&quot;Hello, World.&quot;) ## [1] &quot;character&quot; 論理値 (logical) などもあります。 class(TRUE) ## [1] &quot;logical&quot; 論理値は主に条件式が満たされるかどうかを示します。 1 == 1 ## [1] TRUE 0 &gt; 2 ## [1] FALSE ちなみに、TRUEは数値としての1、FALSEは0にもなります。 TRUE + 1 ## [1] 2 FALSE * 2 ## [1] 0 また、因子型 (factor) と呼ばれるクラスもあります。 カテゴリカル変数と言ったほうが分かりやすいかもしれません。 x &lt;- factor(1) x ## [1] 1 ## Levels: 1 class(x) ## [1] &quot;factor&quot; Xの中身は1ですが、数値ではなくカテゴリーになっているので、数値として操作することはできません。 x + 1 ## Warning in Ops.factor(x, 1): &#39;+&#39; not meaningful for factors ## [1] NA Rではベクトルには特別なクラスは付与されていません。 ベクトルはc()に中身を入力して作成します。 x &lt;- c(1,3,5) x ## [1] 1 3 5 行列 (matrix) はクラスとして存在します。 x &lt;- matrix(c(1,3,5,7), 2, 2) x ## [,1] [,2] ## [1,] 1 5 ## [2,] 3 7 class(x) ## [1] &quot;matrix&quot; 他に、データフレーム (data.frame) やリスト (list) などもあります。 クラスを確認するときは、is.*()の形をとる関数を使います。 is.numeric(1) ## [1] TRUE is.character(1) ## [1] FALSE クラスを変更するときは、as.*()のような関数を使います。 as.factor(1) ## [1] 1 ## Levels: 1 as.character(1) ## [1] &quot;1&quot; 必ずしも全てのクラスが任意のクラスに変換できるわけではありません（例えば、文字列から数値など）。 12.2 関数の作成 Rで関数を自作する際はfunction(){}という関数を使います。 ()の中に入力引数を記述します。 {}の中に処理内容を記述し、最後にreturn()で出力引数を指定します。 例えば、数値ベクトルを入力引数として、平均と標準偏差を出力引数とする関数を作成します。 mean_sd &lt;- function(x) { # 入力引数の名前をxとしておきます。 mean.x &lt;- mean(x) # 平均を計算します。 sd.x &lt;- sd(x) # 標準偏差を計算します。 return(c(mean.x, sd.x)) # 出力引数を指定します。 } 実際に実行してみます。 x &lt;- rnorm(100) mean_sd(x) ## [1] -0.1201579 0.9796026 12.3 ループ ループとは同一の処理を複数回実行することを指します。 例えば、100個の標準正規分布に従う乱数の平均を5回求める処理は次のようになります。 for (i in 1:5) { print(mean(rnorm(100))) } ## [1] -0.1071121 ## [1] 0.05739356 ## [1] 0.02812875 ## [1] 0.01851493 ## [1] -0.04155935 forループとは()の中のinのあとのベクトルの第1要素から順番にiに代入して繰り返しています。 そのことは、次の例から解ると思います。 head(letters) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; lettersとはアルファベットのベクトルです。 for (i in head(letters)) { print(i) } ## [1] &quot;a&quot; ## [1] &quot;b&quot; ## [1] &quot;c&quot; ## [1] &quot;d&quot; ## [1] &quot;e&quot; ## [1] &quot;f&quot; forループとは別に、特定の条件が満たされるまで繰り返されるwhileループもあります。 ループ処理の結果を格納するには少しテクニックが必要です。 100個の乱数の平均を5回取ったものをxとして保存したいとします。 まず、xをNULLオブジェクトとして作成します。 x &lt;- NULL x ## NULL NULLとは空っぽのオブジェクト（0という数値や空白という文字ではない）です。 先程のループ処理の中で、計算した平均をc()でxにくっつけていきます。 for (i in 1:5) { x &lt;- c(x, mean(rnorm(100))) } x ## [1] 0.002829741 0.190244752 -0.086676396 -0.145271872 -0.025504924 無事、5個の平均値がxに保存されていることがわかります。 実際にforループの中で何が起こっているかは、次のコードで解ると思います。 x &lt;- NULL for (i in 1:5) { x &lt;- c(x, mean(rnorm(100))) print(x) } ## [1] 0.1718086 ## [1] 0.171808648 0.001146305 ## [1] 0.171808648 0.001146305 0.118222109 ## [1] 0.171808648 0.001146305 0.118222109 0.053654075 ## [1] 0.171808648 0.001146305 0.118222109 0.053654075 -0.061643063 ループが一周するたびに、前回のxに新しい要素が付け加わり、新しいxとして保存されています。 NULLオブジェクトを使ったループ結果の保存でよくあるミスは、やり直す際にNULLでリセットするのを忘れることです。 例えば、同じコードをもう一度実行しましょう。 for (i in 1:5) { x &lt;- c(x, mean(rnorm(100))) } x ## [1] 0.1718086479 0.0011463051 0.1182221090 0.0536540751 -0.0616430635 ## [6] -0.1609762623 -0.0008344367 0.0710724183 -0.0280604494 0.0759796897 xに10個の平均値が入っています。 このようなミスを避ける方法の一つは、全体を関数として作成することです。 multi_mean &lt;- function() { x &lt;- NULL for (i in 1:5) { x &lt;- c(x, mean(rnorm(100))) } return(x) } x &lt;- multi_mean() x ## [1] 0.06567381 0.09813713 -0.05572884 -0.02336270 -0.04081045 12.4 条件分岐 条件分岐とは、特定の条件の場合に特定の動作を行うようにすることです。 例えば、正の場合positive、負の場合negativeと出力するコマンドは次のようになります。 x &lt;- rnorm(1) if (x &gt; 0) { print(&quot;positive&quot;) } else { print(&quot;negative&quot;) } ## [1] &quot;positive&quot; print(x) ## [1] 0.2722273 if(){}の()の中に条件式を書き、{}の中に処理内容を書きます。 それ以外の条件はelseで示します。 条件式は3つ以上でも構いません。 x &lt;- rnorm(1) if (x &gt; -0.5) { print(&quot;x is less than -0.5.&quot;) } else if (x &gt;= -0.5 &amp; x &lt;= 0.5) { print(&quot;x is between -0.5 and 0.5.&quot;) } else { print(&quot;x is more than 0.5.ー&quot;) } ## [1] &quot;x is more than 0.5.ー&quot; print(x) ## [1] -1.463745 &amp;は「かつ」を意味します。 「または」は|を使います。 &gt;=は \\(\\geq\\) を意味します。 「同じ値である」は==を使います（=ではない点に注意）。 12.5 練習問題 12.5.1 フィボナッチ数列 フィボナッチ数列とは以下の条件を満たす数列です。 \\[ \\begin{aligned} F_0 &amp;= 0 \\\\ F_1 &amp;= 1 \\\\ F_{n} &amp;= F_{n-1} + F_{n-2} \\quad n \\geq 2 \\end{aligned} \\] 例えば、 \\[ \\begin{aligned} F_2 = 1, F_3 = 2, F_4 = 3, F_5 = 5, F_6 = 8,\\ldots \\end{aligned} \\] となります。 フィボナッチ数列の第\\(n\\)項を（解析解を使わずに）求める関数を作成してみて下さい。 また、\\(F_n \\geq m\\)となるような\\(n\\)を求める関数を作成してみて下さい。 12.5.2 モンテカルロ・シミュレーション モンテカルロ・シミュレーション（モンテカルロ法）とは乱数を用いて近似解を求める手法です。 例えば、円周率\\(\\pi\\)の近似解は以下のように求めることができます。 0以上1未満の一様分布から\\(n\\)個の乱数\\(x_i\\)と\\(n\\)個の乱数\\(y_i\\)を発生させます (\\(i = 1,2,\\ldots,n\\)) 。 原点と\\((x_i,y_i)\\)の距離が1以下である回数を計算し\\(n_1\\)とします。 円周率の近似解として\\(\\hat{\\pi} = 4 \\times n_1/n\\)を得ます。 モンテカルロ・シミュレーションによる円周率の近似解を求める関数を作成してみて下さい。 また、モンテカルロ・シミュレーションによる円周率の近似解を\\(m\\)回求めて、その平均値や標準偏差が\\(n\\)によってどのように変化するか検討してみて下さい。 "],
["r-makdown-html.html", "第13章 R Markdown: HTML 13.1 R Markdownファイルの作成 13.2 Markdown記法 13.3 Rチャンク 13.4 yamlヘッダー 13.5 その他のテンプレート", " 第13章 R Markdown: HTML データ分析の再現可能性の必要性は論を俟たないですが、再現可能性を担保するにはレプリケーションデータやコードを公開するだけでなく、それらが理解可能である必要があります。 恐ろしいことに自分が書いたコードでさえ数カ月後に読み返すと意味がわからないことはまれによくあります。 Rスクリプトに#でコメントするのが単純な方法ですが、データ分析においてはしばしば文章とコード、アウトプットを混在させたノートブックを使用することがあります。 詳しくはないですが文芸的プラグラミングと呼ばれるものの一種のような気がします。 更にノートブックからより見やすいファイルを作成することができ、そのファイルおよびシステムをR Markdownと呼びます。 実は、と言うほどではないですが、このブログもR Markdownで書かれています。 13.1 R Markdownファイルの作成 百聞は一見に如かずなので、一まずはR Markdownを使ってみます。 まず、左上のファイルを作成するボタンを押し、R Markdown...を選択します。 初めてR Markdownを使う場合は必要なパッケージをインストールするか聞かれるのでインストールを選択します。 続いて、どのような種類のR Markdownファイルを作成するかを選択するので、（デフォルトのままですが）DocumentのHTMLを選択します。 すると、エディタに以下のようなサンプルのRmdファイルが表示されます。 適当なフォルダに保存し、エディタ上部のKnitをクリックするかShift + Ctrl + kを押すとR Markdownファイルがタイプセットされます。 無事、タイプセットに成功すると以下のような.htmlファイルのプレビューが表示されます。 .Rmdファイルを保存したフォルダに.htmlファイルが生成されているはずです。 .htmlファイルとはウェブサイトを作成するためのファイルで、ウェブブラウザ（例、FirefoxやGoogle Chrome）で開くことできれいに見れます。 13.1.1 参考になるサイト R Markdownの公式サイト R Markdown: The Definitive Guide R Markdownのチートシート (pdf) 比治山大学の前田和寛先生のR Markdown入門 13.2 Markdown記法 13.2.1 Markdownとは* R MarkdownとはMarkdownとRスクリプトを合体させたようなものです。 ここではMarkdownについて説明しますが、読み飛ばしても構いません。 Markdownとは計量マークアップ言語と呼ばれているようにマークアップ言語の一種です。 マークアップ言語とは文章の中身と役割・外見を区別して記述する言語です。 逆に、世間で普及しているWordのように文章の中身と役割・外見が混在しているエディターはWYSIWYGと呼びます。 例えば、Wordではセクションの名前などは指定することができますが、見た目はフォントのサイズが大きくなったり、太字になったりします。 一方で、マークアップ言語の一種である.htmlファイルでは &lt;h1&gt;セクションタイトル&lt;/h1&gt; のように明示的にh1というタグをつけ、h1タグのついている文章に対して.cssファイルで見た目を決定します。 同様に、LaTeXでは\\section{セクションタイトル}のようにタグをつけます。 基本的にはWYSIWYGなソフトのほうが直観的な操作が可能で作業が楽ではあるものの、マークアップ言語はテキストで役割や外見も決めるので再現可能性が高いと言えるでしょう。 そこで、より簡便なマークアップ言語として登場したのがMarkdown記法です。 なので、HTML記法を使うこともできます。 13.2.2 セクション Markdownでは#を使ってセクションのタイトルを記述します。 #が多くなればなるほどより小さな見出しになります。 # レベル1 ## レベル2 ### レベル3 #### レベル4 13.2.3 パラグラフ 空行を入れると新しいパラグラフになります。 同じパラグラフです。 同じパラグラフです。 同じパラグラフです。 同じパラグラフです。 違うパラグラフです。 違うパラグラフです。 違うパラグラフです。 違うパラグラフです。 なので、パラグラフ内でも一文ごとに改行したほうが見やすいと思います。 13.2.4 箇条書き 番号なしの箇条書きの場合は=を、番号付きの箇条書きの場合は1.を入れます。 - 番号なし箇条書き - 番号なし箇条書き - 番号なし箇条書き 番号なし箇条書き 番号なし箇条書き 番号なし箇条書き 1. 番号付き箇条書き 1. 番号付き箇条書き 1. 番号付き箇条書き 番号付き箇条書き 番号付き箇条書き 番号付き箇条書き タブ（半角スペース4つ分）を入れると階層構造をつけることができます。 - レベル1 - レベル2 - レベル１ レベル1 レベル2 レベル１ 13.2.5 文字の強調 *もしくは_で囲むと斜体になり、**もしくは__で囲むと太字になります。 *斜体*と**太字** 斜体と太字 ｀で囲むとコードになり、~~で囲むと打ち消されます。 `code`と~~打ち消し~~ codeと打ち消し 日本語のLaTeXでは打ち消しに対応していないので、表示させていません。 13.2.6 引用 &gt;から始めると引用になります。 &gt; 引用文です。 引用文です。 13.2.7 リンク リンクを貼る場合は[リンク名](リンク先のURL)あるいは&lt;リンク先のURL&gt;とします。 - [RStudio](https://www.rstudio.com/) - &lt;https://www.rstudio.com/&gt; RStudio https://www.rstudio.com/ 13.2.8 画像、表 画像を埋め込む場合は![画像名](画像のパス)とします。 ![Rlogo](figures/Rlogo.png) Rlogo 表を埋め込む際には次のように書きます。 | 項目1 | 項目2 | 項目3 | |-------|-------|-------| | りんご| 100 | 赤 | | みかん| 80 | オレンジ | 項目1 項目2 項目3 りんご 100 赤 みかん 80 オレンジ 13.2.9 数式 LaTeX記法による数式を記述できます。 インラインの場合は$で囲み、ディスプレイの場合は$$で囲みます。 .htmlの場合、mathjaxによって数式を表示するのでオフラインでは表示できません。 確率変数$X_i$は平均$\\mu$、分散$\\sigma^2$の正規分布に従う。 確率変数\\(X_i\\)は平均\\(\\mu\\)、分散\\(\\sigma^2\\)の正規分布に従う。 $$ X_i \\sim \\mathcal{N}(\\mu,\\sigma^2) $$ \\[ X_i \\sim \\mathcal{N}(\\mu,\\sigma^2) \\] 13.3 Rチャンク R Markdown内でRコードを記述する際にはRチャンクと呼ばれるものの中で行います。 Rチャンクは次のような形をしています。 Ctrl + Alt + IでRチャンクを挿入することができます。 まず、この部分は後述するチャンクオプションを指定する場所になります。 ここではRコードであること、チャンク名をcarsと指定しています。 R MrkdownにおいてもRスクリプトと同様にCtrl + Enterでコードを実行することができます。 あるいはRチャンクの右上のボタンをクリックしても実行できます。 実行されたコードはチャンクの直下に表示されます。 右上から二番目のボタンはこのRチャンクの直前のRチャンクまでのコードを全て実行するボタンになります。 13.3.1 チャンクオプション チャンクオプションを指定することでコードとそのアウトプットをどのように出力するかを制御することができます。 主なものをまとめておきます。 eval=FALSEとするとコードは表示されるが実行されない。 echo=FALSEとするとコードは実行されるが表示されない。 include=FALSEとするとコードは実行されるがコードも実行結果も表示されない。 warning=FALSEやerror=FALSE、message=FALSEとすると警告やエラー、メッセージが表示されない。 例えば、{r, echo=FALSE}のように書きます。 デフォルトを変更したい場合は冒頭でknitr::opts_chunk$set(echo=TRUE)のように設定します。 13.4 yamlヘッダー yamlヘッダーとは.Rmdファイルの冒頭で---によって囲まれた箇所で、ページ全体の設定を行います。 初期状態では --- title: &quot;Untitled&quot; author: &quot;Shohei Doi&quot; date: &quot;4/9/2019&quot; output: html_document --- となっていますが、titleやauthor、dateでタイトル、著者、日付を設定できます。 13.4.1 output outputによって出力形式を決定します。 これによってyamlヘッダーにおいてどのような項目を設定できるのかも決まります。 どのような出力形式が利用可能であるかは後述するとして、以下ではhtml_documentにおける主なyamlヘッダーの設定を紹介します。 前田先生のページが参考になります。 13.4.2 目次 目次を出力するには次のように書きます。 output: html_document: toc: TRUE 目次の設定には次のようなものがあります。 output: html_document: toc: TRUE toc_depth: 2 toc_gloat: TRUE number_sections: TRUE toc_depthによってどの階層の見出しまで表示するかを決めます。 toc_floatをTRUEにすると目次がスクロールしてもついてきます。 number_sectionsをTRUEにすると見出しに通し番号がつきます。 13.4.3 テーマ テーマを決める場合はthemeで指定します。 テーマ一覧はこちらになります。 output: html_document: theme: &quot;paper&quot; 13.4.4 htmlとcss cssによってカスタム.cssファイルを指定できます。 includeによって.htmlファイルの挿入ができます。 デフォルトでは.cssファイルは画像データなどは全て.htmlファイルに含まれてスタンドアロンな形で見ることができます。 しかし、self_containedをFALSEとすると付属ファイルは別フォルダに作成され、.htmlファイル自体が見やすくなります。 13.5 その他のテンプレート outputを変更することで、いくつかのテンプレートを使用することができます。 ここでは.htmlファイルが出力されるいくつかのテンプレートを紹介しておきます。 公式サイトのGalleryやFormatsをご覧ください。 13.5.1 Distill Distillはウェブで公開することを念頭に置いた専門的な記事を書くためのテンプレートになっています。 インストールは以下のように行います。 devtools::install_github(&quot;rstudio/distill&quot;) RStudioのバージョンは1.2以上であることが求められています。 インストールに成功するとR Markdown...の中のFrom TemplateにDistill Articleが追加されているはずです。 13.5.2 Tufte Handout Tufte Handoutというテンプレートもあります。 Tufte Handout tufteというパッケージをインストールするとテンプレートに追加されます。 13.5.3 rmdformats rmdformatsというテンプレートもあります。 同様に、rmdformatsというパッケージをインストールします。 material readthedown html_clean html_docco 13.5.4 スライド R Markdownから作成できる.htmlファイルのスライドにはioslidesとslidyというものがあります。 ioslides ioslides slidy slidy これらはデフォルトで入っています。 また、reveal.jsという.htmlスライドを作ることもできます。 revealjsというパッケージをインストールするとテンプレートが追加されます。 Presentationの方ではない点に注意。 reveal.js reveal.js 同様にしてxaringanというNARUTOという忍者マンガにインスパイアされたテンプレートを使用することもできます。 xaringan xaringan 13.5.5 ダッシュボード flexdashboardというパッケージを使うとダッシュボードを作ることができます。 パッケージをインストールするとFlex Dashboardというテンプレートが追加されます。 flexdashboard 13.5.6 Microsoft Office R MarkdownからMicrosoft OfficeのWordやPowerPointの形式のファイルを作成することも可能です。 "],
["r-markdown-pdf.html", "第14章 R Markdown: pdf 14.1 LaTeXの導入 14.2 日本語環境の構築 14.3 スライドの作成 14.4 LaTeX記法 14.5 参考文献と引用", " 第14章 R Markdown: pdf R Markdownから.pdfファイルを作成するにはLaTeXと呼ばれる組版システムを導入する必要があります。 一手間かかりますが、逆にR Markdownによって簡単にLaTeXを使えるとも言えます。 R Markdown: The Definitive Guide ここではLaTeXの導入から.pdf形式による論文とスライドの作成、そしていくつかのLaTeX記法の紹介を行います。 14.1 LaTeXの導入 LaTeXのディストリビューションはいろいろあるのですが、今回はTinyTeXを使って環境構築を行います。 TinyTeXはメジャーなディストリビューションであるTeX Liveのうち必要最小限の要素だけを含んでいます。 TeX Live以外にもMikTeX、WindowsであればW32TeX、MacではMacTeXも有名です。 TeX Liveは全てのパッケージを一度にダウンロードするので非常に時間がかかります。 本格的にLaTeXを使わないのであればTinyTeXで十分だと思います。 また、OverleafというオンラインLaTeXエディタもあります。 14.1.1 tinytexのインストール tinytexというRパッケージがありますので、それをインストールします。 install.packages(&quot;tinytex&quot;) 続いて、TinyTeX本体を以下のコマンドでインストールします。 tinytex::install_tinytex() エラーメッセージが出てくるかもしれませんがダイアログにあるように無視して進めて問題ありません。 そこそこ時間がかかりますが、TeX Liveを使ったことがある人はあまりの速さにびっくりするかもしれません。 14.1.2 タイプセット R Markdownファイルを作成する際にDocumentのPDFを選択します。 やはりサンプルファイルができるので、適当なフォルダに保存してKnitもしくはShift + Ctrl + Kでタイプセットすると.pdfファイルが作成されるはずです。 .texからタイプセットする場合はpdflatex()、lualatex()、xelatex()でパスを指定して使います。 タイプセット時にいろいろとインストールを行い、時間がかかるかもしれません。 これはTiny TeXが最低限のパッケージだけを持っていて、必要なパッケージは適宜インストールするからです。 一度、パッケージをインストールすると再度インストールはしないので時間は掛かりません。 14.2 日本語環境の構築 残念ながら、デフォルトの状態では日本語を含むファイルをタイプセットすることはできません。 実際に、サンプルファイルに適当な日本語を入れてタイプセットしてみるとエラーが出るはずです。 今回はXeLaTeXによる日本語ファイルのタイプセットを目指します。 Windowsでしか確認していないのでMacではうまくいかないかもしれません。 その時は教えてください。 14.2.1 LaTeXエンジンのあれこれ* なぜXeLaTeXを使うのかについて説明しますが読み飛ばしても構いません。 僕も詳しくはないですが、LaTeXエンジンにはいろいろな種類があります。 モダンなエンジンはpdfLaTeX、LuaLaTeX、XeLaTeXと呼ばれています。 例えば、こちらを参照。 実際にR MarkdownやTinyTeXで対応しているのはこの3つになります。 Overleafでもこの3つにpLaTeXを加えたものに対応しています。 一方で、日本語ファイルをタイプセットする際にこれまで用いられてきたのは[u]pLaTeXと呼ばれるエンジンです。 しかし、今後は徐々にモダンなエンジンが主流になると思われます。 このうち、pdfLaTeXでは日本語を扱えないので選択肢はLuaLaTeXとXeLaTeXのどちらかになります。 どうやら、LuaLaTeXが主流となりつつあるらしく、またLuaと呼ばれる言語を使えるという利点もありそうです。 しかし、僕はLuaが何なのか分かりませんし（したがって、どんなご利益があるのかも知りません）、XeLaTeXの方がタイプセットの速度が早いらしいので、現時点ではこちらを使用しています。 14.2.2 yamlヘッダー XeLaTeXによってR Markdownから.。pdfファイルを生成するにはyamlヘッダーのoutput以下を次のようにします。 output: pdf_document: latex_engine: xelatex number_sections: true documentclass: bxjsarticle header-includes: - \\usepackage{zxjatype} - \\usepackage[ipa]{zxjafont} geometry: no 目次を出力する際は.htmlの時と同様に設定します。 フォントの大きさはfontsize: 10ptのように指定します。 14.2.3 フォントのインストール もしIPAexフォントがPCに入っていない場合は以下のコマンドでインストールします。 tinytex::tlmgr_install(&quot;ipaex&quot;) あるいはこちらからダウンロード&amp;インストールします。 この状態でタイプセットすると日本語も表示されるはずです。 14.2.4 その他のテンプレート .htmlの時と同様に.pdfのときもいくつかのrtcilesにテンプレートが用意されています。 rticlesというパッケージをインストールするとテンプレートが追加されます。 14.2.5 Sumatra PDF おそらく、Adobe AcrobatがPDFリーダーとしては人気だとは思いますが、Acrobatで開いている.pdfファイルを編集することはできないという欠点があります。 そこで、Sumatra PDFなどのPDFリーダーを使用することがおすすめです。 14.3 スライドの作成 LaTeXでスライドを作成する際によく用いられているのがBeamerと呼ばれるドキュメントクラスです。 R MarkdownからBeamerスライドを作成することも可能です。 京都府立大学の秦先生がPowerPointでBeamer風のスライドを作るためテンプレートを公開しています。 こんな感じの。 まず、Presentationの中のPDF (Beamer)を選択します。 そして、yamlヘッダーのoutput以下を次のように書き換えます。 output: beamer_presentation: latex_engine: xelatex header-includes: - \\usepackage{zxjatype} - \\usepackage[ipa]{zxjafont} スライドでは#がセクションタイトル、##が各スライドのタイトルになります。 classoption: &quot;aspectratio=169&quot;とするとアスペクト比が16:9になります。 14.3.1 テーマ Beamerにはデフォルトで多くのテーマとカラーがあります。 以下のようにして設定することができます。 output: beamer_presentation: theme: &quot;AnnArbor&quot; colortheme: &quot;dolphin&quot; fonttheme: &quot;structurebold&quot; 14.4 LaTeX記法 もちろん、Markdown記法はそのまま使うことができます。 LaTeXもhtmlと同様にマークアップ言語であり、専用の記法があります。 Markdown記法ではできないことはLaTeX記法で直接書き込むことで可能になります。 14.4.1 定理環境 定理や仮説を書くときには、まずyamlヘッダーに以下を付け加えます。 header-includes: - \\usepackage{amsthm} - \\newtheorem{hypo}{仮説} そして仮説を書くときには次のように書きます。 \\begin{hypo} Xが大きくなるとYも大きくなりやすくなる。 \\end{hypo} 14.4.2 数式 数式はインラインであれば$で、ディスプレイであれば$$で囲みます。 14.4.2.1 添字 上付きの添字は~で、下付きの添字は_で書きます。 複数の文字列をまとめるときは{}で囲みます。 $x^n, y_{it}$ \\(x^n, y_{it}\\) 14.4.2.2 太字 数式内で太字にする場合は\\mathbf{}を使います。 $\\mathbf{x}$ \\(\\mathbf{x}\\) 14.4.2.3 条件 条件に応じて値が変わる場合は次のように書きます。 $$ T_i = \\begin{cases} 1 &amp; もしiさんが処置群にいた場合 \\\\ 0 &amp; そうでない場合 \\\\ \\end{cases} $$ \\[ T_i = \\begin{cases} 1 &amp; もしiさんが処置群にいた場合 \\\\ 0 &amp; そうでない場合 \\\\ \\end{cases} \\] 14.5 参考文献と引用 R Markdownでは文献ファイルから引用と参考文献を作成することができます。 いろいろな形式に対応しているようですが、ここではLaTeXでよく使われている.bibファイルを使います。 14.5.1 .bibファイル .bibファイルは文献情報を保存する形式の一つです。 まず、RStudioでも他のテキストエディタでもいいので、.Rmdファイルがあるディレクトリに.bibファイルを作成します。 ここではreference.bibという名前で作成したとします。 Google Scholarに登録されている文献であれば次のようにbib形式の情報を取得することができます。 ただし、Google Scholarの文献情報はいい加減であることも多いので気をつけてください。 まず、引用したい文献を検索します。 続いて、引用したい文献の引用ボタンをクリックします。 そして、BibTeXボタンをクリックすると.bib形式の書誌情報が表示されます。 @article{fearon1995rationalist, title={Rationalist explanations for war}, author={Fearon, James D}, journal={International organization}, volume={49}, number={3}, pages={379--414}, year={1995}, publisher={Cambridge University Press} } これを先ほど作成したreference.bibにコピペして保存します。 直接.bibファイルを編集したい場合はJabRefなどのソフトを使うといいでしょう。 Mendeleyを使うと/pdfファイルを取り込んで自動で.bibファイルを作成してくれます。 14.5.2 文献の引用 引用する際には[@citation_key]という形で記述します。 citation_keyとは書誌情報の最初の要素（この場合はfearon1995rationalist）になります。 したがって、[@fearon1995rationalist]と記述すると引用ができます。 Google Scholarの場合は自動で引用キーが生成されますが長いので適当なものに書き直したほうが楽です。 14.5.3 日本語文献の引用 日本語文献の場合も概ね同様の方法で行います。 ただし、Google Scholarに収録されていないことも多いので次のようなサービスも利用できます。 Lead2AmazonでAmazonの検索結果からBibTeX情報を取り出す。 CiNiiには標準でBibTeXをエクスポートする機能があります。 例えば、Lead2Amazonで取り出した高坂正堯の「国際政治」の書誌情報は以下のようになります。 ただし、このまま引用すると、名前と名字が入れ替わって表示されてしまうので、名字の後ろに,をつける必要があります。 @BOOK{高坂201710, title={国際政治 - 恐怖と希望 (中公新書)}, author={高坂 正堯}, publisher={中央公論新社}, year={2017}, month={10}, edition={改}, isbn={9784121801081}, url={http://amazon.co.jp/o/ASIN/4121801083/}, totalpages={233}, timestamp={2019.04.10}, } 本格的に日本語文献を適切な形で表示するにはjecon.bstのようなBibTeXスタイルファイルを使う必要があります。 "],
["encoding-r.html", "第15章 Rにおける文字コード* 15.1 なぜ文字化けが起こるのか 15.2 Rスクリプトの文字化け 15.3 データの文字化け 15.4 その他の問題", " 第15章 Rにおける文字コード* Rに限らず文字化けはPCにおいてしばしば起こる問題です。 平たく言ってしまうと、PCでは文字にコードが付与されており、機械がコードを読み取って文字を表示します。 そのコードと文字の対応関係をエンコーディングと呼び、異なるエンコーディングでデータを読み込むと文字化けが起こります。 15.1 なぜ文字化けが起こるのか 15.1.1 エンコーディング 実用上、日本語で文字化けが起こる問題の大半は WindowsではShift-JISあるいはCP932で、 LinuxやMacなどのUNIX系ではUTF-8で エンコーディングしていることに起因しています。 UTF-8のUはunicodeであることからも分かるように、世界で共通の規格として作られているエンコーディング方式になります。 なので、RおよびRStudioでは日本語独自のShift-JISではなくUTF-8を使うようにしたほうがよいでしょう。 15.1.2 RとRStudioにおける問題 RとRStudioで文字化けが起こる問題は大きく2つに分けられます。 RStudioで日本語を含むRスクリプトを開いたとき Rで日本語を含むデータを読み込んだとき 以下では、それぞれの問題の対処法を紹介します。 15.2 Rスクリプトの文字化け Rスクリプトが文字化けしている場合はRStudiで対処します。 例としてUTF-8でエンコードしたRスクリプトとShift-JISでエンコードしたRスクリプトをRStudioで開いてみてください。 （設定を変更していなければ）Windowsの場合は前者が、Linux/Macの人は後者が文字化けしているはずです。 15.2.1 ファイルを開く まず、デフォルトをUTF-8に変更しましょう。 メニューの中のFileにReopen with Encoding...というのがあるので、UTF-8を選択します。 さらにSet as default encoding for source filesにチェックを入れることで今後はUTF-8で表示されます。 UTF-8でエンコードされた方は正常に表示され、Shift-JISでエンコードされた方は文字化けしていることを確認してください。 今後、RStudioで文字化けが起こる場合はデフォルトがUTF-8になっているので、Rスクリプトが他のエンコードのために起こっていることになります。 そのような場合にはReopen with Encoding...で適当なエンコーディングを選択します。 例えば、Shift-JISを選択すると正しく表示されるはずです。 15.2.2 ファイルを保存する 自分で作成したRスクリプトを保存する際にはメニューのFileの中のSave with Encoding...でUTF-8を選択してください。 ここでもUTF-8がデフォルトになるようにチェックを入れておきましょう。 15.3 データの文字化け データが文字化けしているときはRで対処します。 UTF-8でエンコーディングしたデータとShift-JISでエンコーディングしたデータをそれぞれ読み込んでみてください。 やはりWindowsでは前者が、Linux/Macでは後者が文字化けをしているはずです。 read.csv(&quot;data/data_utf8.csv&quot;) read.csv(&quot;data/data_sjis.csv&quot;) ## Error in type.convert.default(data[[i]], as.is = as.is[i], dec = dec, : invalid multibyte string at &#39;&lt;83&gt;C&lt;83&gt;k&#39; 僕はLinuxを使っているので後者が文字化けを起こしてエラーが出ています。 15.3.1 標準関数の場合 標準関数の場合、fileEncodingというオプションでエンコーディングを指定します。 read.csv(&quot;data/data_utf8.csv&quot;, fileEncoding = &quot;utf8&quot;) read.csv(&quot;data/data_sjis.csv&quot;, fileEncoding = &quot;shift-jis&quot;) 15.3.2 tidyverseの場合 tidyverseのreadrの場合はlocaleで指定します。 readrはtidyverseに含まれているので、tidyverseを読み込んだ場合は、別途読み込む必要はありません。 library(tidyverse) read_csv(&quot;data/data_utf8.csv&quot;, locale = locale(encoding = &quot;utf8&quot;)) ## Parsed with column specification: ## cols( ## member = col_character() ## ) read_csv(&quot;data/data_sjis.csv&quot;, locale = locale(encoding = &quot;shift-jis&quot;)) ## Parsed with column specification: ## cols( ## member = col_character() ## ) 15.3.3 エンコーディングを確認する方法 readrのguess_encoding()という関数を使うと、どのようなエンコーディングがされているかを推測します。 guess_encoding(&quot;data/data_utf8.csv&quot;) guess_encoding(&quot;data/data_sjis.csv&quot;) windows-1215というのはCP1215とも呼ばれるエンコーディングで、Shift-JISの親戚のようなものです（きっと）。 15.3.4 もとのデータを見たい場合 しばしばRではなく直接データを見たいときがあります。 そのような場合は、LibreOfficeのCalcというソフトで開くとエンコーディングを指定することができます。 15.3.5 データを保存する場合 データを書き出す場合、UTF-8で行うのが望ましいですが、そうするとWindowsからExcelなどで開いた場合に文字化けしてしまいます。 それを回避するために、readrのwrite_excel_csv()を使うとエクセルで開いても文字化けしません。 15.4 その他の問題 15.4.1 アカウント名が日本語の場合 Windowsでアカウント名が日本語の場合、パスを通すときにエラーが出てくる場合があります。 そのような場合は、 新しいアカウントを作成する。 新しいアカウントを作成し、現在のアカウントの内容を全てコピーして、現在のアカウントを削除する。 OSをクリーンインストールする。 Linux（Ubuntuなど）を使う。 仮想マシン（VMwareやVirtualBox）を使う。 デュアルブートをする。 といった選択肢が考えられます（下に行くほど難易度が高い）。 15.4.2 画像で日本語が文字化けする場合 Macで画像を出力する際に日本語が文字化けすることがあります。 plot()の場合は、 par(family = &quot;HiraKakuProN-W3&quot;) ggplot2の場合は、 theme(base_family = &quot;HiraKakuProN-W3&quot;) とするらしいです（Macは使ったことがないので分かりません）。 quantedaでプロットする際、うまくフォントが指定できない場合があるので、こちらを参考に、extrafont::fonts()でフォント一覧を確認して、適当なものを指定して下さい。 "],
["pipe.html", "第16章 パイプ演算子%&gt;%について* 16.1 基本的な使い方 16.2 データの代入 16.3 左辺の参照 16.4 複数の出力", " 第16章 パイプ演算子%&gt;%について* こいつはtidyverse内のmagrittrというパッケージの機能で、パイプ演算子あるいは単にパイプと呼ばれたりします。 以下のサイトが参考になりました。 R for Data ScienceのPipes magrittrのvignetteの訳 library(tidyverse) library(magrittr) ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## set_names ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract 16.1 基本的な使い方 基本的に%&gt;%は左辺の出力を右辺の関数の第1引数にします。 つまり、f %&gt;% gはg(f)と同値です。 ちなみに、RStudioではShift + Ctrl + Mで入力します。 summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## iris %&gt;% summary() ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## これだけだとパイプ演算子のご利益は分かりにくいですが、コードが長くなるにつれてその力を発揮します。 例えば、irisの各品種について各変数の平均と中央値を求めてみます。 パイプ演算子を使うと次のように一行のコードで書くことができます。 iris %&gt;% pivot_longer(-Species, names_to = &quot;var&quot;, values_to = &quot;val&quot;) %&gt;% group_by(var, Species) %&gt;% summarise(mean = mean(val), median = median(val)) iris %&gt;% pivot_longer(-Species, names_to = &quot;var&quot;, values_to = &quot;val&quot;) %&gt;% group_by(var, Species) %&gt;% summarise(mean = mean(val), median = median(val)) %&gt;% knitr::kable() var Species mean median Petal.Length setosa 1.462 1.50 Petal.Length versicolor 4.260 4.35 Petal.Length virginica 5.552 5.55 Petal.Width setosa 0.246 0.20 Petal.Width versicolor 1.326 1.30 Petal.Width virginica 2.026 2.00 Sepal.Length setosa 5.006 5.00 Sepal.Length versicolor 5.936 5.90 Sepal.Length virginica 6.588 6.50 Sepal.Width setosa 3.428 3.40 Sepal.Width versicolor 2.770 2.80 Sepal.Width virginica 2.974 3.00 これをパイプ演算子を使わないと、次のようになります。 summarise(group_by(pivot_longer(iris, -Species, names_to = &quot;var&quot;, values_to = &quot;val&quot;), var, Species), mean = mean(val), median = median(val)) summarise(group_by(pivot_longer(iris, -Species, names_to = &quot;var&quot;, values_to = &quot;val&quot;), var, Species), mean = mean(val), median = median(val)) %&gt;% knitr::kable() var Species mean median Petal.Length setosa 1.462 1.50 Petal.Length versicolor 4.260 4.35 Petal.Length virginica 5.552 5.55 Petal.Width setosa 0.246 0.20 Petal.Width versicolor 1.326 1.30 Petal.Width virginica 2.026 2.00 Sepal.Length setosa 5.006 5.00 Sepal.Length versicolor 5.936 5.90 Sepal.Length virginica 6.588 6.50 Sepal.Width setosa 3.428 3.40 Sepal.Width versicolor 2.770 2.80 Sepal.Width virginica 2.974 3.00 あるいは適当なオブジェクトを作成して次のようにします。 temp &lt;- pivot_longer(iris, -Species, names_to = &quot;var&quot;, values_to = &quot;val&quot;) temp &lt;- group_by(temp, var, Species) temp &lt;- summarise(temp, mean = mean(val), median = median(val)) temp temp &lt;- pivot_longer(iris, -Species, names_to = &quot;var&quot;, values_to = &quot;val&quot;) temp &lt;- group_by(temp, var, Species) temp &lt;- summarise(temp, mean = mean(val), median = median(val)) knitr::kable(temp) var Species mean median Petal.Length setosa 1.462 1.50 Petal.Length versicolor 4.260 4.35 Petal.Length virginica 5.552 5.55 Petal.Width setosa 0.246 0.20 Petal.Width versicolor 1.326 1.30 Petal.Width virginica 2.026 2.00 Sepal.Length setosa 5.006 5.00 Sepal.Length versicolor 5.936 5.90 Sepal.Length virginica 6.588 6.50 Sepal.Width setosa 3.428 3.40 Sepal.Width versicolor 2.770 2.80 Sepal.Width virginica 2.974 3.00 このように考えるとパイプ演算子のご利益は次のようにまとめられます。 処理をする順番に関数が登場するので可読性を高めることができる。 一行でコードを書くことができるので無駄なオブジェクトを作らなくてよい。 16.2 データの代入 データを加工する際、パイプを使うと基本的にはこのようになります。 iris &lt;- iris %&gt;% mutate(species = case_when(Species == &quot;setosa&quot; ~ 0, Species == &quot;versicolor&quot; ~ 1, Species == &quot;virginica&quot; ~ 2)) summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species species ## setosa :50 Min. :0 ## versicolor:50 1st Qu.:0 ## virginica :50 Median :1 ## Mean :1 ## 3rd Qu.:2 ## Max. :2 しかし、左から右に流れるべきと思う場合は次のように書くこともできます。 iris %&gt;% mutate(species = case_when(Species == &quot;setosa&quot; ~ 0, Species == &quot;versicolor&quot; ~ 1, Species == &quot;virginica&quot; ~ 2)) -&gt; iris summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species species ## setosa :50 Min. :0 ## versicolor:50 1st Qu.:0 ## virginica :50 Median :1 ## Mean :1 ## 3rd Qu.:2 ## Max. :2 あるいは%&lt;&gt;%という演算子を使うこともできます。 iris %&lt;&gt;% mutate(species = case_when(Species == &quot;setosa&quot; ~ 0, Species == &quot;versicolor&quot; ~ 1, Species == &quot;virginica&quot; ~ 2)) summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species species ## setosa :50 Min. :0 ## versicolor:50 1st Qu.:0 ## virginica :50 Median :1 ## Mean :1 ## 3rd Qu.:2 ## Max. :2 16.3 左辺の参照 基本的にはパイプ演算子の左辺を右辺の第1引数にしますが、.を使うことで任意の引数にすることができます。 例えば、irisでsetosaを除外して回帰分析をしたい場合、第1引数はformulaなので普通はパイプで繋げることはできないが、以下のように書くことができます。 iris %&gt;% filter(Species != &quot;setosa&quot;) %&gt;% lm(Sepal.Length ~ Sepal.Width, data = .) %&gt;% summary() ## ## Call: ## lm(formula = Sepal.Length ~ Sepal.Width, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.0032 -0.3877 -0.0774 0.3200 1.7381 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.0934 0.4844 6.387 5.70e-09 *** ## Sepal.Width 1.1033 0.1675 6.585 2.27e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5547 on 98 degrees of freedom ## Multiple R-squared: 0.3068, Adjusted R-squared: 0.2997 ## F-statistic: 43.36 on 1 and 98 DF, p-value: 2.27e-09 また、%$%という演算子は右辺において左辺のデータを参照せずに変数名を指定することができます。 したがって、次のように書くこともできます。 iris %&gt;% filter(Species != &quot;setosa&quot;) %$% lm(Sepal.Length ~ Sepal.Width) %&gt;% summary() ## ## Call: ## lm(formula = Sepal.Length ~ Sepal.Width) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.0032 -0.3877 -0.0774 0.3200 1.7381 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.0934 0.4844 6.387 5.70e-09 *** ## Sepal.Width 1.1033 0.1675 6.585 2.27e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5547 on 98 degrees of freedom ## Multiple R-squared: 0.3068, Adjusted R-squared: 0.2997 ## F-statistic: 43.36 on 1 and 98 DF, p-value: 2.27e-09 これは、次のコードと同値です。 iris %&gt;% filter(Species != &quot;setosa&quot;) %&gt;% { lm(.$Sepal.Length ~ .$Sepal.Width) } %&gt;% summary() ## ## Call: ## lm(formula = .$Sepal.Length ~ .$Sepal.Width) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.0032 -0.3877 -0.0774 0.3200 1.7381 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.0934 0.4844 6.387 5.70e-09 *** ## .$Sepal.Width 1.1033 0.1675 6.585 2.27e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5547 on 98 degrees of freedom ## Multiple R-squared: 0.3068, Adjusted R-squared: 0.2997 ## F-statistic: 43.36 on 1 and 98 DF, p-value: 2.27e-09 16.4 複数の出力 .を使うことで複数の出力を行うことも可能です。 iris$Sepal.Length %&gt;% { mean(.) %&gt;% print() median(.) %&gt;% print() var(.) %&gt;% print() } ## [1] 5.843333 ## [1] 5.8 ## [1] 0.6856935 $T&gt;$という演算子を使うと右辺は評価されるが、返り値は左辺のままになります。 例えば、plot()に流すことで図を出力しつつ、irisをsummary()にも流すことができます。 iris %T&gt;% plot() %&gt;% summary() ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species species ## setosa :50 Min. :0 ## versicolor:50 1st Qu.:0 ## virginica :50 Median :1 ## Mean :1 ## 3rd Qu.:2 ## Max. :2 これは、以下のコードと同値です。 iris %&gt;% { plot(.) summary(.) } ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species species ## setosa :50 Min. :0 ## versicolor:50 1st Qu.:0 ## virginica :50 Median :1 ## Mean :1 ## 3rd Qu.:2 ## Max. :2 "],
["environment.html", "動作環境", " 動作環境 sessionInfo() ## R version 3.6.3 (2020-02-29) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 18.04.4 LTS ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] magrittr_1.5 summarytools_0.9.6 haven_2.2.0 readxl_1.3.1 ## [5] knitr_1.28 forcats_0.5.0 stringr_1.4.0 dplyr_0.8.5 ## [9] purrr_0.3.4 readr_1.3.1 tidyr_1.0.2 tibble_3.0.1 ## [13] ggplot2_3.3.0 tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.4.6 lubridate_1.7.8 lattice_0.20-41 assertthat_0.2.1 ## [5] digest_0.6.25 R6_2.4.1 cellranger_1.1.0 plyr_1.8.6 ## [9] backports_1.1.6 reprex_0.3.0 evaluate_0.14 highr_0.8 ## [13] httr_1.4.1 pillar_1.4.3 rlang_0.4.5 rstudioapi_0.11 ## [17] magick_2.3 checkmate_2.0.0 rmarkdown_2.1 pander_0.6.3 ## [21] munsell_0.5.0 broom_0.5.6 compiler_3.6.3 modelr_0.1.6 ## [25] xfun_0.13 pkgconfig_2.0.3 base64enc_0.1-3 htmltools_0.4.0 ## [29] tcltk_3.6.3 tidyselect_1.0.0 bookdown_0.18 codetools_0.2-16 ## [33] matrixStats_0.56.0 fansi_0.4.1 crayon_1.3.4 dbplyr_1.4.3 ## [37] withr_2.1.2 grid_3.6.3 nlme_3.1-144 jsonlite_1.6.1 ## [41] gtable_0.3.0 lifecycle_0.2.0 DBI_1.1.0 scales_1.1.0 ## [45] cli_2.0.2 stringi_1.4.6 pryr_0.1.4 fs_1.4.1 ## [49] xml2_1.3.1 ellipsis_0.3.0 rapportools_1.0 generics_0.0.2 ## [53] vctrs_0.2.4 tools_3.6.3 glue_1.4.0 hms_0.5.3 ## [57] yaml_2.2.1 colorspace_1.4-1 rvest_0.3.5 "],
["references.html", "参考文献", " 参考文献 "]
]
