[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R/Pythonで計量政治学入門",
    "section": "",
    "text": "はじめに\nRやPythonを用いて、（主として政治に関する）データ分析を行うために必要な基本的知識や技術を学びます。\n\n正直なところ、ChatGPTやOpen Interpreterを使えばいいような気はしますし、もっとよいサイトはたくさんあります。\n\n執筆者の土井翔平は北海道大学公共政策大学院および法学部・大学院法学研究科で国際関係論の研究と教育に従事しています。データ分析やプログラミングの専門家ではありません。\n\n計量「政治学」とありますが、執筆者の専門の都合で政治に関する題材が多いという意味でしかありません。政治以外の社会科学を専門とする方にも役に立つ内容のはずです。\n一橋大学で担当していた「国際政治の計量分析I」がベースとなっています（講義スライド\n\n本当は昔のバージョンの内容が古くなったために消したかったのですが、ありがたいことに何人かの方にご覧になっていると言われたので、改稿しました。昔のバージョンは暫定的にこちらにあります。\n\n\n\n\n\n\nRかPythonか？\n\n\n\n\n\nRとPythonのどちらを使えばいいのかは初学者が最初に直面する問題かもしれません。結論から言えば「どちらでもよい」と言っていいと思います。\nデータ分析の基本的な部分はどちらの言語でも実行可能です。より高度な分析を行う場合はそれぞれ得手不得手がありますが、そこに至るまでにR/Pythonを学習していれば、もう一方も簡単に学ぶことができると思います。\nしたがって、最初は自身の直感に従ったり、それぞれ触ってみて使いやすいと思った方を選んだりすればよいかと思います。RとPythonの（実用上の）違いを強いて言うならば、政治学などではRが比較的使われており、機械学習（人工知能）ではPythonが使われているという違いはあります。\n\n\n\n\n\n参考にすべきサイト\nインターネット上では多くの参考にすべきサイト・資料があります。\n\n私たちのR：ベストプラクティスの探求",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "quick_start.html",
    "href": "quick_start.html",
    "title": "1  R/Pythonの基本操作",
    "section": "",
    "text": "1.1 環境構築\nRにせよ、Pythonにせよ、使用するためには環境構築をする必要があります。大きく分けて、クラウド環境とローカル環境のに種類の方法があります。\n初めてR/Pythonを学習する人はPCの操作に不慣れな人はクラウド環境で十分だと思います。RであればPosit Cloud（旧名RStudio Cloud）、PythonであればGoogle Colaboratoryなどがあります。\nローカル環境を構築する場合はウェブサイトや書籍などに情報が載っているので、それらを参考にしてください。例えば、Rの環境構築であれば高知工科大学の矢内先生の解説などがあります。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R/Pythonの基本操作</span>"
    ]
  },
  {
    "objectID": "quick_start.html#環境構築",
    "href": "quick_start.html#環境構築",
    "title": "1  R/Pythonの基本操作",
    "section": "",
    "text": "クラウド環境：ウェブブラウザを通じて既に準備がされているサーバ上のR/Pythonを用いる。\n\n準備はアカウントを作成するだけ簡単／インターネットに接続していないと利用できない、マシンのスペックに制限がある。\n\nローカル環境：自身のPCにR/Pythonをインストールする。\n\nオフライン環境でも利用できる、自分のPCのスペックに比例した性能を得られる／インストールが大変\n\n\n\n\nGoogle Colabの無料版は12時間の制限がある点に注意。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R/Pythonの基本操作</span>"
    ]
  },
  {
    "objectID": "quick_start.html#r",
    "href": "quick_start.html#r",
    "title": "1  R/Pythonの基本操作",
    "section": "1.2 R",
    "text": "1.2 R\nPosit Cloudを開いて、右上のNew Projectというボタンをクリックし、New RStudio Projectを選択します。すると、次のような画面になるはずです。\n\n\n\nこの画面の左側にR version...と始まるパネルがありますが、これをコンソールと呼びます。この中の&gt;の横にコードを入力し、EnterEnterを押すことで実行することができます。\n実際にやってみましょう。以下のコードを&gt;の横に入力し、Enterを押してください。\n\n\n\nR\n\nprint(\"Hello, world!\")\n\n\n[1] \"Hello, world!\"\n\n\n実際に、Hello, world!という表示がされるはずです。もし、表示されない場合は上記コードをコピペして再度実行してみてください。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R/Pythonの基本操作</span>"
    ]
  },
  {
    "objectID": "quick_start.html#python",
    "href": "quick_start.html#python",
    "title": "1  R/Pythonの基本操作",
    "section": "1.3 Python",
    "text": "1.3 Python\nGoogle Colaboratoryにアクセスし、ノートブックを新規作成してください。すると、次のような画面になるはずです。\n\n\n\nこの再生ボタンの（黒い丸に三角のマーク）あるところをセルと呼びます。その中にコードを記入して、Shift-EnterShift-Enterをクリックすると実行されます。\n以下のコードを入力・実行してみてください。\n\n\n\nPython\n\nprint(\"Hello, world!\")\n\n\nHello, world!\n\n\nHello, world!という表示がされれば、うまくいっています。もし、表示されない場合は上記コードをコピペして再度実行してみてください。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R/Pythonの基本操作</span>"
    ]
  },
  {
    "objectID": "quick_start.html#オブジェクトと関数",
    "href": "quick_start.html#オブジェクトと関数",
    "title": "1  R/Pythonの基本操作",
    "section": "1.4 オブジェクトと関数",
    "text": "1.4 オブジェクトと関数\nprint(\"Hello, world!\")という極めてシンプルなコードですが、ここにR/Pythonのプログラミングの基本的要素が含まれています。\nまず、\"Hello, world!\"というのは、見ての通りHello, world!という文字列を意味しています。\"で囲むことによって、これらは文字列だよとR/Pythonに伝えています。そして、print(...)というのはその中身を表示させる機能を果たしています。\nこのように、R/Pythonでは「なにか」をR/Pythonに渡して「処理」を行います。この「なにか」をオブジェクト、「処理」をするものを関数と呼びます。今回の例で言えば、“Hello, world!”という文字列オブジェクトをprint(...)という関数に渡して表示という処理を行ったということです。\n卑近な例えで言えば、オブジェクトが食材で関数が調理といったところでしょうか。様々な食材を様々な調理することで料理を完成させるように、データ分析も様々なオブジェクトと様々な関数で行っていきます。\nこの時点でオブジェクトと関数について正確に把握するのは難しいと思います。「習うより慣れろ」ということで次章以降のプログラミングの中で体感してもらえればよいと思います。今後、一見難解そうに見えるプログラミングが現れたとしてもオブジェクトと関数という視点から整理すると見通しがよくなるだろうということを伝えておきます。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R/Pythonの基本操作</span>"
    ]
  },
  {
    "objectID": "data_frame.html",
    "href": "data_frame.html",
    "title": "2  データフレーム",
    "section": "",
    "text": "2.1 パッケージのインストール\nスマホのアプリと同様にパッケージは最初に（そして一回だけ）インストールする必要があります。今回はgapminderという名前のパッケージをインストールします。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "data_frame.html#パッケージのインストール",
    "href": "data_frame.html#パッケージのインストール",
    "title": "2  データフレーム",
    "section": "",
    "text": "2.1.1 R\nRではinstall.packages(\"...\")という関数を実行するとパッケージをインストールできます。ただ、RStudio (posit Studio) を使っている場合は、（初期設定では）画面右下のPackagesタブのInstallボタンをクリックしてインストールするのが楽でしょう。\n\n\n\nR\n\ninstall.packages(\"gapminder\")\n\n\n\n\n2.1.2 Python\nPythonの場合は用いているパッケージマネジャーによって方法が異なります。例えば、Google Colaboratoryの場合はpipを使って管理をしています。pip install ...コマンドでインストールできます。\n\n\n\npython\n\n!pip install gapminder\n\n\n\n文頭に!をつけることを忘れないでください。これは、Pythonコードではなくbashコマンドとして実行する目印です。\nAnacondaなどを利用している場合はcondaを使います。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "data_frame.html#パッケージの読み込み",
    "href": "data_frame.html#パッケージの読み込み",
    "title": "2  データフレーム",
    "section": "2.2 パッケージの読み込み",
    "text": "2.2 パッケージの読み込み\nパッケージのインストールは最初の一度で十分ですが、利用する度に読み込む必要があります。もし読み込みができない場合はパッケージのインストールに失敗している可能性が高いです。\nRではlibrary(...)関数を用いて、パッケージを読み込みます。\n\n\n\nR\n\nlibrary(gapminder)\n\n\nPythonではimport ...コマンドを用いて、パッケージを読み込みます。\n\n\n\nPython\n\nimport gapminder",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "data_frame.html#パッケージの使用",
    "href": "data_frame.html#パッケージの使用",
    "title": "2  データフレーム",
    "section": "2.3 パッケージの使用",
    "text": "2.3 パッケージの使用\nさて、これでGapminderのデータを読み込むことができました。データの中身を確認してみましょう。\nRではパッケージgapminderを読み込んだ際に、オブジェクトgapminderを呼び出しています。\n\n\n\nR\n\ngapminder\n\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\nPythonではパッケージgapminderの中にオブジェクトgapminderが入っています。\n\n\n\nPython\n\ngapminder.gapminder\n\n\n          country continent  year  lifeExp       pop   gdpPercap\n0     Afghanistan      Asia  1952   28.801   8425333  779.445314\n1     Afghanistan      Asia  1957   30.332   9240934  820.853030\n2     Afghanistan      Asia  1962   31.997  10267083  853.100710\n3     Afghanistan      Asia  1967   34.020  11537966  836.197138\n4     Afghanistan      Asia  1972   36.088  13079460  739.981106\n...           ...       ...   ...      ...       ...         ...\n1699     Zimbabwe    Africa  1987   62.351   9216418  706.157306\n1700     Zimbabwe    Africa  1992   60.377  10704340  693.420786\n1701     Zimbabwe    Africa  1997   46.809  11404948  792.449960\n1702     Zimbabwe    Africa  2002   39.989  11926563  672.038623\n1703     Zimbabwe    Africa  2007   43.487  12311143  469.709298\n\n[1704 rows x 6 columns]\n\n\n\nPythonではパッケージ名のあとに.をつけて、パッケージ内のデータや関数にアクセスします。分かりにくいですが、gapminder.gapminderというのは「gapminderというパッケージの中のgapminderというデータ」という意味です。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "data_frame.html#データフレーム",
    "href": "data_frame.html#データフレーム",
    "title": "2  データフレーム",
    "section": "2.4 データフレーム",
    "text": "2.4 データフレーム\nこれらのオブジェクトをデータフレームと呼びます。データフレームは横（行）が観察 (observation) で、縦（列）が変数 (variable) になります。\n\n\n\nデータフレームのイメージ\n\n\n\nしばしば、表形式 (tabular) データ、構造化データ、関係データなどとも呼びます。\n\nGapminderのデータで言えば、観察はある年のある国で、変数は国名、大陸名、年、平均寿命、人口、一人あたりGDPとなっています。このような形式のデータは社会科学のデータ分析で標準的なものであり、当面の間はデータフレームの分析を扱います。\nなお、データフレームの全体を表示するのは冗長なので、冒頭だけを表示させることができます。\n\n\n\nR\n\nhead(gapminder)\n\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\n\n\n\n\nPython\n\ngapminder.gapminder.head()\n\n\n       country continent  year  lifeExp       pop   gdpPercap\n0  Afghanistan      Asia  1952   28.801   8425333  779.445314\n1  Afghanistan      Asia  1957   30.332   9240934  820.853030\n2  Afghanistan      Asia  1962   31.997  10267083  853.100710\n3  Afghanistan      Asia  1967   34.020  11537966  836.197138\n4  Afghanistan      Asia  1972   36.088  13079460  739.981106",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "data_frame.html#それで",
    "href": "data_frame.html#それで",
    "title": "2  データフレーム",
    "section": "2.5 それで？",
    "text": "2.5 それで？\n残念ながらデータそれ自体からなにかしらの知見を得ることは難しいです。というか、データを眺めただけで何かが分かるのであれば、わざわざデータ分析をする必要はないように思えます。\nここからは、データを数値で表現したり（要約）、グラフを作ったり（可視化）することで特徴を把握する作業を学びたいと思います。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "desc_distribution.html",
    "href": "desc_distribution.html",
    "title": "3  一変数の要約",
    "section": "",
    "text": "3.1 オブジェクトへの代入\n既にGapminderのデータは読み込まれていますが、いちいちgapminderやgapminder.gapminderと書くのはしんどいと思います。ここでは、別名のオブジェクトとして保存します。名前はなんでもいいのですが、とりあえずdf_gapとしてみましょう。\nR\n\nlibrary(gapminder)\n\ndf_gap &lt;- gapminder\nPython\n\nimport gapminder\n\ndf_gap = gapminder.gapminder\nこのように、オブジェクトを別の名前のオブジェクトとして保存することを代入と呼びます。Rでは&lt;-で、Pythonでは=で代入をします。\n作成されたオブジェクトはRStudioのEnvironmentパネル、Google Colaboratoryの{}ボタンをクリックしたところに表示されます。",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>一変数の要約</span>"
    ]
  },
  {
    "objectID": "desc_distribution.html#データの大きさ",
    "href": "desc_distribution.html#データの大きさ",
    "title": "3  一変数の要約",
    "section": "3.2 データの大きさ",
    "text": "3.2 データの大きさ\nデータに含まれる観察の数（サンプルサイズ）を求めます。\n\n\n\nR\n\nnrow(df_gap)\n\n\n[1] 1704\n\n\n\n\n\nPython\n\nlen(df_gap)\n\n\n1704\n\n\nデータに含まれる変数の数を求めます。\n\n\n\nR\n\nncol(df_gap)\n\n\n[1] 6\n\n\n\n\n\nPython\n\nlen(df_gap.columns)\n\n\n6\n\n\nこれらを同時に求めることもできます。\n\n\n\nR\n\ndim(df_gap)\n\n\n[1] 1704    6\n\n\n\n\n\nPython\n\ndf_gap.shape\n\n\n(1704, 6)\n\n\n\nPythonではオブジェクトの後ろに.を付けて属性やメソッドを呼び出すことができます。",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>一変数の要約</span>"
    ]
  },
  {
    "objectID": "desc_distribution.html#中心",
    "href": "desc_distribution.html#中心",
    "title": "3  一変数の要約",
    "section": "3.3 中心",
    "text": "3.3 中心\n\n3.3.1 一変数の選択\nある変数の中心、代表するような要約統計量を求めます。その準備として、データフレームから特定の変数（例えば、一人あたりGDP）だけを抜き出す方法を紹介します。RとPythonのそれぞれで2通りの書き方がありますが、どちらでも構いません。\n\n\n\nR\n\ndf_gap$gdpPercap\ndf_gap[\"gdpPercap\"]\n\n\n\n\n\nPython\n\ndf_gap.gdpPercap\ndf_gap['gdpPercap']\n\n\n\nRでは標準でデータフレームが使えますが、Pythonではpandasというパッケージを使うことがデファクト・スタンダードになっています。ここでは明示的にpandasを呼び出していませんが、操作方法はpandasのデータフレームのものになります（次章以降も同様です）。\n\n\n\n3.3.2 平均値\n平均値 (mean) は全ての観察について変数の値を足し合わせ、サンプルサイズで割ったものです。\n\\[\n\\bar{x} = \\frac{\\sum_{i=1}^N x_i}{N}\n\\]\n\n\n\nR\n\nmean(df_gap$gdpPercap)\n\n\n[1] 7215.327\n\n\n\n\n\nPython\n\ndf_gap['gdpPercap'].mean()\n\n\n7215.327081212149\n\n\n\n\n3.3.3 中央値\n中央値 (median) とは、その値よりも小さな観察の数が全体の50%である（したがって、大きな観察も50%である）ような値です。\n\n\n\nR\n\nmedian(df_gap$gdpPercap)\n\n\n[1] 3531.847\n\n\n\n\n\nPython\n\ndf_gap['gdpPercap'].median()\n\n\n3531.8469885",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>一変数の要約</span>"
    ]
  },
  {
    "objectID": "desc_distribution.html#散らばり",
    "href": "desc_distribution.html#散らばり",
    "title": "3  一変数の要約",
    "section": "3.4 散らばり",
    "text": "3.4 散らばり\n平均値や中央値は変数の代表的な値、「中心」を表すものでした。しかし、変数の散らばり具合にも関心があるかもしれません。\n\n3.4.1 最小値・最大値\nまず思いつくのは最小値 (minimum) と最大値 (maximum) ではないでしょうか。\n\n\n\nR\n\nmin(df_gap$gdpPercap)\n\n\n[1] 241.1659\n\nmax(df_gap$gdpPercap)\n\n[1] 113523.1\n\n\n\n\n\nPython\n\ndf_gap['gdpPercap'].min()\n\n\n241.1658765\n\ndf_gap['gdpPercap'].max()\n\n113523.1329\n\n\n\n\n3.4.2 分位点\nしたから数えて\\(q%\\)となるような点を\\(q\\)分位点 (quantile) と呼びます。特に、下から数えて\\(25%\\)と\\(75%\\)を第1四分位点、第3四分位点と呼びます。第2四分位点は中央値になります。試しに第1四分位点を求めます。\n\n\n\nR\n\nquantile(df_gap$gdpPercap, 0.25)\n\n\n    25% \n1202.06 \n\n\n\n\n\nPython\n\ndf_gap['gdpPercap'].quantile(0.25)\n\n\n1202.06030925\n\n\nRの場合はquantile()という関数に変数と求めたい分位点の数値を入れます。関数には複数のオブジェクトを入れることができます。Pythonではquantile()メソッドに数値を入れます。\n\n\n3.4.3 分散・標準偏差\n散らばりを表す要約統計量としてよく用いられるのは分散 (variance) です。分散の二乗根を標準偏差 (standard deviation) と呼びます。\n\\[\n\\sigma^2 = \\frac{\\sum_{i=1}^N (x_i - \\bar{x})^2}{N}\n\\]\n\n\\((x_i - \\bar{x})\\)が平均値からどれだけ離れているかを表しています。これを二乗することで面積に変換し、その平均を求めています。\n\n\n\n\nR\n\nvar(df_gap$gdpPercap)\n\n\n[1] 97169410\n\nsd(df_gap$gdpPercap)\n\n[1] 9857.455\n\n\n\n\n\nPython\n\ndf_gap['gdpPercap'].var()\n\n\n97169410.05827107\n\ndf_gap['gdpPercap'].std()\n\n9857.45454254145",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>一変数の要約</span>"
    ]
  },
  {
    "objectID": "desc_distribution.html#グループに含まれる観察数",
    "href": "desc_distribution.html#グループに含まれる観察数",
    "title": "3  一変数の要約",
    "section": "3.5 グループに含まれる観察数",
    "text": "3.5 グループに含まれる観察数\nこれまで、明示してきませんでしたが、いわゆる連続変数 (continuous variable) の要約について議論してきました。ここではその定義は避けますが、「四則演算できる変数」という意味くらいに捉えておきます。\nデータ分析で扱う変数は（しばしば誤解されますが）連続変数だけではありません。そのような変数の代表は離散変数 (discrete variable) と呼ばれるものです。やはり厳密な定義は避けますが、ここでは「グループを表す変数」ということにしておきます。gapminderのデータでは例えば大陸という変数はグループを表しています。また、国や年もグループを表していると見てもよいでしょう。\n離散変数は四則演算ができないので（例えばアジアとアメリカを足すというのは定義不能です）、平均値や分散などは定義できません。その代わり、グループに含まれる観察の数を求めることで変数の特徴を掴みます。それでは大陸ごとにどれくらいの観察が含まれているかを調べてみたいと思います。\n\n\n\nR\n\ntable(df_gap$continent)\n\n\n\n  Africa Americas     Asia   Europe  Oceania \n     624      300      396      360       24 \n\n\n\n\n\nPython\n\ndf_gap.value_counts(\"continent\")\n\n\ncontinent\nAfrica      624\nAsia        396\nEurope      360\nAmericas    300\nOceania      24\nName: count, dtype: int64\n\n\nアフリカが多く、オセアニアが少ないことなどが分かります。",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>一変数の要約</span>"
    ]
  },
  {
    "objectID": "desc_summary.html",
    "href": "desc_summary.html",
    "title": "4  記述統計表",
    "section": "",
    "text": "4.1 簡易な方法\nR\n\nlibrary(gapminder)\n\ndf_gap &lt;- gapminder\n\nsummary(df_gap)\n\n\n        country        continent        year         lifeExp     \n Afghanistan:  12   Africa  :624   Min.   :1952   Min.   :23.60  \n Albania    :  12   Americas:300   1st Qu.:1966   1st Qu.:48.20  \n Algeria    :  12   Asia    :396   Median :1980   Median :60.71  \n Angola     :  12   Europe  :360   Mean   :1980   Mean   :59.47  \n Argentina  :  12   Oceania : 24   3rd Qu.:1993   3rd Qu.:70.85  \n Australia  :  12                  Max.   :2007   Max.   :82.60  \n (Other)    :1632                                                \n      pop              gdpPercap       \n Min.   :6.001e+04   Min.   :   241.2  \n 1st Qu.:2.794e+06   1st Qu.:  1202.1  \n Median :7.024e+06   Median :  3531.8  \n Mean   :2.960e+07   Mean   :  7215.3  \n 3rd Qu.:1.959e+07   3rd Qu.:  9325.5  \n Max.   :1.319e+09   Max.   :113523.1\nPython\n\nimport gapminder\n\ndf_gap = gapminder.gapminder\n\ndf_gap.describe()\n\n\n             year      lifeExp           pop      gdpPercap\ncount  1704.00000  1704.000000  1.704000e+03    1704.000000\nmean   1979.50000    59.474439  2.960121e+07    7215.327081\nstd      17.26533    12.917107  1.061579e+08    9857.454543\nmin    1952.00000    23.599000  6.001100e+04     241.165876\n25%    1965.75000    48.198000  2.793664e+06    1202.060309\n50%    1979.50000    60.712500  7.023596e+06    3531.846988\n75%    1993.25000    70.845500  1.958522e+07    9325.462346\nmax    2007.00000    82.603000  1.318683e+09  113523.132900\nこのようにして気軽に記述統計表を見ることはできますが、残念ながらこのまま論文に載せることができるクオリティではありません。以下では、よりきれいな記述統計表を作成する方法を紹介します。",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>記述統計表</span>"
    ]
  },
  {
    "objectID": "desc_summary.html#簡易な方法",
    "href": "desc_summary.html#簡易な方法",
    "title": "4  記述統計表",
    "section": "",
    "text": "e+04のような謎の文字が登場しますが、これは文字化けやエラーなどではありません。e+04は\\(10^4 = 10000\\)を意味しています（浮動小数点数）。",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>記述統計表</span>"
    ]
  },
  {
    "objectID": "desc_summary.html#データフレームの作成",
    "href": "desc_summary.html#データフレームの作成",
    "title": "4  記述統計表",
    "section": "4.2 データフレームの作成",
    "text": "4.2 データフレームの作成\nまず、summarytoolsというパッケージのdescr()という関数で記述統計表を作ります。初めて使う場合はパッケージのインストールを忘れないでください。\n\n\n\nR\n\nlibrary(summarytools)\n\ndescr(df_gap)\n\nDescriptive Statistics\ndf_gap\nN: 1704\n\n\n\n\ngdpPercap\nlifeExp\npop\nyear\n\n\n\n\nMean\n7215.33\n59.47\n29601212.32\n1979.50\n\n\nStd.Dev\n9857.45\n12.92\n106157896.74\n17.27\n\n\nMin\n241.17\n23.60\n60011.00\n1952.00\n\n\nQ1\n1201.92\n48.19\n2792776.00\n1964.50\n\n\nMedian\n3531.85\n60.71\n7023595.50\n1979.50\n\n\nQ3\n9325.86\n70.85\n19593660.50\n1994.50\n\n\nMax\n113523.13\n82.60\n1318683096.00\n2007.00\n\n\nMAD\n4007.61\n16.10\n7841473.62\n22.24\n\n\nIQR\n8123.40\n22.65\n16791557.75\n27.50\n\n\nCV\n1.37\n0.22\n3.59\n0.01\n\n\nSkewness\n3.84\n-0.25\n8.33\n0.00\n\n\nSE.Skewness\n0.06\n0.06\n0.06\n0.06\n\n\nKurtosis\n27.40\n-1.13\n77.62\n-1.22\n\n\nN.Valid\n1704.00\n1704.00\n1704.00\n1704.00\n\n\nPct.Valid\n100.00\n100.00\n100.00\n100.00\n\n\n\n\nこのままでは項目が多いので、いくつかに絞ります。\n\n\n\nR\n\nlibrary(summarytools)\n\ndescr(df_gap, stats = c(\"n.valid\", \"mean\", \"sd\", \"min\", \"q1\", \"med\", \"q3\", \"max\"))\n\nDescriptive Statistics\ndf_gap\nN: 1704\n\n\n\n\ngdpPercap\nlifeExp\npop\nyear\n\n\n\n\nN.Valid\n1704.00\n1704.00\n1704.00\n1704.00\n\n\nMean\n7215.33\n59.47\n29601212.32\n1979.50\n\n\nStd.Dev\n9857.45\n12.92\n106157896.74\n17.27\n\n\nMin\n241.17\n23.60\n60011.00\n1952.00\n\n\nQ1\n1201.92\n48.19\n2792776.00\n1964.50\n\n\nMedian\n3531.85\n60.71\n7023595.50\n1979.50\n\n\nQ3\n9325.86\n70.85\n19593660.50\n1994.50\n\n\nMax\n113523.13\n82.60\n1318683096.00\n2007.00\n\n\n\n\n表示されるのではデータフレームではないので、出力結果をtb()関数に入れてデータフレーム化します。\n\n\n\nR\n\ndf_sum &lt;- descr(df_gap, stats = c(\"n.valid\", \"mean\", \"sd\", \"min\", \"q1\", \"med\", \"q3\", \"max\"))\ndf_sum &lt;- tb(df_sum)\n\nprint(df_sum)\n\n\n# A tibble: 4 × 9\n  variable  n.valid       mean          sd     min       q1    med     q3    max\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 gdpPercap    1704     7215.       9857.    241.    1.20e3 3.53e3 9.33e3 1.14e5\n2 lifeExp      1704       59.5        12.9    23.6   4.82e1 6.07e1 7.08e1 8.26e1\n3 pop          1704 29601212.  106157897.  60011     2.79e6 7.02e6 1.96e7 1.32e9\n4 year         1704     1980.         17.3  1952     1.96e3 1.98e3 1.99e3 2.01e3\n\n\nPythonの場合はpandasのdescribe()メソッドがデータフレームを出力します。\n\n\n\nPython\n\ndf_sum = df_gap.describe()\n\nprint(df_sum)\n\n\n             year      lifeExp           pop      gdpPercap\ncount  1704.00000  1704.000000  1.704000e+03    1704.000000\nmean   1979.50000    59.474439  2.960121e+07    7215.327081\nstd      17.26533    12.917107  1.061579e+08    9857.454543\nmin    1952.00000    23.599000  6.001100e+04     241.165876\n25%    1965.75000    48.198000  2.793664e+06    1202.060309\n50%    1979.50000    60.712500  7.023596e+06    3531.846988\n75%    1993.25000    70.845500  1.958522e+07    9325.462346\nmax    2007.00000    82.603000  1.318683e+09  113523.132900\n\n\n\n4.2.1 転置\n変数と要約統計量の位置を入れ替えたい場合は次のようにします（こちらのほうが政治学では一般的な印象を受けます）。\nsummarytoolsではオプションtranspose = TRUEを追加します。\n\n\n\nR\n\ndf_sum &lt;- descr(df_gap, stats = c(\"n.valid\", \"mean\", \"sd\", \"min\", \"q1\", \"med\", \"q3\", \"max\"), transpose = TRUE)\ndf_sum &lt;- tb(df_sum)\n\nprint(df_sum)\n\n\n# A tibble: 4 × 9\n  variable  n.valid       mean          sd     min       q1    med     q3    max\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 gdpPercap    1704     7215.       9857.    241.    1.20e3 3.53e3 9.33e3 1.14e5\n2 lifeExp      1704       59.5        12.9    23.6   4.82e1 6.07e1 7.08e1 8.26e1\n3 pop          1704 29601212.  106157897.  60011     2.79e6 7.02e6 1.96e7 1.32e9\n4 year         1704     1980.         17.3  1952     1.96e3 1.98e3 1.99e3 2.01e3\n\n\nPythonの場合はtranspose()メソッドがデータフレームを転置します。\n\n\n\nPython\n\ndf_sum = df_gap.describe()\ndf_sum = df_sum.transpose()\n\nprint(df_sum)\n\n\n            count          mean  ...           75%           max\nyear       1704.0  1.979500e+03  ...  1.993250e+03  2.007000e+03\nlifeExp    1704.0  5.947444e+01  ...  7.084550e+01  8.260300e+01\npop        1704.0  2.960121e+07  ...  1.958522e+07  1.318683e+09\ngdpPercap  1704.0  7.215327e+03  ...  9.325462e+03  1.135231e+05\n\n[4 rows x 8 columns]",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>記述統計表</span>"
    ]
  },
  {
    "objectID": "desc_summary.html#表の出力",
    "href": "desc_summary.html#表の出力",
    "title": "4  記述統計表",
    "section": "4.3 表の出力",
    "text": "4.3 表の出力\nデータフレームを論文で掲載する表として保存します。R/Pythonの外に保存する場合は、保存先としてパスを指定する必要があります。パスとはPC上の住所のようなものです。\nパスは表の出力だけでなく、画像の保存やデータの読み込みの際にも必要になる重要概念なので、しっかり説明しようと思います。\n\n4.3.1 作業ディレクトリ\nまず、現在RやPythonで作業している場所を作業ディレクトリ (working directory) と言います。\n\nディレクトリとはフォルダのことです。\n\n作業ディレクトリのパスを次のコードで確認します。\n\n\n\nR\n\ngetwd()\n\n\n\n\n\nPython\n\nimport os\n\nos.getcwd()\n\n\nおそらく、AAA/BBB/CCC/DDDのような文字列が表示されるはずです（Windowsの場合は/が¥かもしれません）。これが作業ディレクトリのパスです。\nすなわち、PCのAAAというフォルダの中のBBBの中のCCCの中のDDDで今は作業をしているという意味です。パスと住所と同じ構造をしていることが分かります。\n\n\n4.3.2 保存先フォルダの作成\n次に、表の出力先としてtablesというフォルダを作成します。まず、RStudio Cloudの場合、右下のFilesタブの中のFolderボタンをクリックして、Moreの中のGo To Working Directoryをクリックすると作業ディレクトリが表示されます。その中でNew Folderを選択し、tablesとフォルダ名を入力してOKをします。\nGoogle Colaboratoryの場合、左のフォルダボタンを押すと、作業ディレクトリが開きます。しかし、Google Colaboratoryでは一定時間が経つと作業がリセットされてしまうので、Google Driveにデータを保存する方が便利です。\nGoogle Driveの中にtablesというフォルダを作成します。次に、Colaboratoryのページの左側にフォルダのボタンがあるので、それをクリックし、上の方にあるGoogle Driveのボタンを押して、マウントします。すると、driveというフォルダが表示されます。この中のMyDriveが自身のGoogle Driveになります。先ほど作成したtablesフォルダがあることを確認してください。\n自分のPC上で（ローカルの）R/Pythonを使っている場合は、まず作業ディレクトリを自分で作り、その中にtablesフォルダを作成します。\n\nRStudioを使っている場合は、プロジェクトファイルを作成すると、作業ディレクトリが自動で設定されるので、おすすめします。\nPythonを使っている場合は、Jupyter NotebookやVScodeが自動で作業ディレクトリを設定します。\n\n\n\n4.3.3 データフレームの保存\n一つのやり方はデータフレームを.csvファイルに出力する方法です。\n\n\n\nR\n\nwrite.csv(df_sum, \"tables/summary_gapminder_R.csv\")\n\n\n\n\n\nPython\n\ndf_sum.to_csv(\"tables/summary_gapminder_py.csv\")\n\n\nファイルを保存する場合は、保存先のパスを指定する必要があります。今回は、tablesフォルダの中にsummary_gapminder_R[py].csvというファイル名で保存しようと思います。\n\ntables/は「tablesというフォルダの中の」という意味です。\nsummary_gapminder_R.csvは保存するファイルの名前で、自由に決めることができます。\n\nただし、半角英数字とアンダーバー_やハイフン-のみを使い、空白は入れないことを推奨します。\n\n.csvは拡張子で、今回はcsvファイルとして保存します。\nGoogle Colaboratoryの場合、tables/...の前にdrive/MyDrive/を付け足します。\n\nこのように、作業ディレクトリから見たパスを相対パスと呼びます。パスを全て書く場合を絶対パスと呼びますが、使用はおすすめしません。\n出力されたデータをWordなどに貼り付け、見た目をよしなにします。\n\n\n4.3.4 LaTeX\ntexファイルとして出力する場合は例えば次のようにします。\n\n\n\nR\n\nlibrary(xtable)\n\nprint(xtable(df_sum), file = \"tables/summary_gapminder_R.tex\", booktabs = TRUE)\n\n\n\n\n\nPython\n\ndf_sum.to_latex(\"tables/summary_gapminder_py.tex\")\n\n\n\nパッケージjinja2をインストールしておく必要があります。\n\n論文に載せる際は変数名を適切なものへと変更したり、キャプションなどをつけるといいでしょう。また、LaTeXのパッケージbooktabsを使うように設定しています。",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>記述統計表</span>"
    ]
  },
  {
    "objectID": "desc_summary.html#スクリプト",
    "href": "desc_summary.html#スクリプト",
    "title": "4  記述統計表",
    "section": "4.4 スクリプト",
    "text": "4.4 スクリプト\nRで記述統計表を作成するコードをまとめてみます。\n\n\n\nR\n\nlibrary(gapminder)\nlibrary(summarytools)\n\ndf_gap &lt;- gapminder\n\ndf_sum &lt;- descr(df_gap, stats = c(\"n.valid\", \"mean\", \"sd\", \"min\", \"q1\", \"med\", \"q3\", \"max\"), transpose = TRUE)\ndf_sum &lt;- tb(df_sum)\n\nwrite.csv(df_sum, \"tables/summary_gapminder_R.csv\")\n\n\nデータ分析は試行錯誤なので、同じようなことを何度もすることがあります。例えば、記述統計表を作り直すということはあるでしょう。その都度、上記のようなコードをイチから書いていくのは面倒です。\nそこで、コードをスクリプトに保存をします。RStudioの左上で新しくファイルを作成するボタンをクリックし、R Scriptを選択します。すると、左上にまっさらなスクリプトが登場するので、そこにコードを書き込んでいき、適宜保存をします。\n実は、スクリプト上のコードはCtrl-EnterCtrl-Enterで実行することができます。なので、実際はスクリプト上にコードを書き、実行していくことになります。\nGoogle Colaboratoryはノートブックという形式で、コードと実行結果が一体化しています。ただ、ノートブックを使わない場合は同様にPythonスクリプトを作成します（例えば、Visual Studio Codeなどを用います）。\n\nノートブックではセルごとにコードが実行されるので、適当な内容ごとにセルを区切ってコードを書くようにしましょう。",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>記述統計表</span>"
    ]
  },
  {
    "objectID": "desc_summary.html#パイプ演算子",
    "href": "desc_summary.html#パイプ演算子",
    "title": "4  記述統計表",
    "section": "4.5 パイプ演算子",
    "text": "4.5 パイプ演算子\nPythonで記述統計表を作成するコードをまとめます。\n\n\n\nPython\n\nimport gapminder\n\ndf_gap = gapminder.gapminder\n\ndf_sum = df_gap.describe()\ndf_sum = df_sum.transpose()\n\ndf_sum.to_csv(\"tables/summary_gapminder_py.csv\")\n\n\nところで、Pythonでは特定の種類のオブジェクトに限定した処理はメソッドとして提供されています。そして、メソッドは連結して書くことができます。\n例えば上記のコードは以下のようになります。\n\n\n\nPython\n\nimport gapminder\n\ndf_gap = gapminder.gapminder\n\ndf_gap.describe().transpose().to_csv(\"tables/summary_gapminder_py.csv\")\n\n\nRではパイプ演算子と呼ばれるものを使って、同様に書くことができます。パイプ演算子とは%&gt;%もしくは|&gt;のことで、左側の内容を右側の関数の最初の入力として渡します。\n\n例えば、a |&gt; f(...)というのはf(a, ...)と等価です。\n\nパイプ演算子を使うと、次のようにまとめて書くことができます。\n\n\n\nR\n\nlibrary(gapminder)\nlibrary(summarytools)\n\ndf_gap &lt;- gapminder\n\ndf_gap |&gt; \n    descr(stats = c(\"n.valid\", \"mean\", \"sd\", \"min\", \"q1\", \"med\", \"q3\", \"max\"), transpose = TRUE) |&gt; \n    tb() |&gt; \n    write.csv(\"tables/summary_gapminder_R.csv\")\n\n\nメソッドやパイプ演算子で連結させて書くか、処理を一つずつ行ってオブジェクトに代入して書くかは見やすさや個人の好みに応じて決めればよいと思います。\n\n\n\n\n\n\n2つのパイプ演算子\n\n\n\nRにはパイプ演算子が2つあります。まず、%&gt;%というのはmagrittr（より一般的にはtidyverse）のパイプ演算子で、先に登場しました。その後、Rでも標準のパイプ演算子として|&gt;が導入されました。\n僕が理解する範囲ではどちらも機能は変わらないので、好きな方を使えば良いと思います（使わなくてもいいと思います）。ただ、他の人が書いたコードにこれらが登場しても混乱しないようにしましょう。\n\n\nPythonでは()でくくって、コードを改行することができます。\n\n\n\nPython\n\nimport gapminder\n\ndf_gap = gapminder.gapminder\n\n(\n    df_gap\n    .describe()\n    .transpose()\n    .to_csv(\"tables/summary_gapminder_py.csv\")\n)",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>記述統計表</span>"
    ]
  },
  {
    "objectID": "desc_correlation.html",
    "href": "desc_correlation.html",
    "title": "5  二変数の要約",
    "section": "",
    "text": "5.1 連続変数同士の関係",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>二変数の要約</span>"
    ]
  },
  {
    "objectID": "desc_correlation.html#連続変数同士の関係",
    "href": "desc_correlation.html#連続変数同士の関係",
    "title": "5  二変数の要約",
    "section": "",
    "text": "5.1.1 共分散\n相関係数 (correlation coefficient) 、特に相関、という言葉は聞いたことがあるでしょう。相関係数とは2つの変数間の関係の強さを見る際に、よく使われる指標です。\nこれから相関係数について説明しますが、ややこしいので、興味のない人はコードまで飛ばしてください。\nまずは、相関係数を理解するために、共分散 (covariance) について学びます。一度、分散の定義に戻ります。\n\\[\n\\sigma^2 = \\frac{\\sum_{i=1}^N (x_i - \\bar{x})^2}{N}\n\\]\n\\(\\bar{x}\\)は\\(x\\)の平均でした。したがって、\\((x_i - \\bar{x})\\)は変数の値が平均からどれだけ離れているかを表しており、それを二乗して面積に変換して、その平均を求めることで、変数の散らばり具合を表していました。\n共分散は分散の二変数バージョンであり、次のように定義されます。分散との違いは分母の総和の中身が\\((x_i - \\bar{x})^2\\)から\\((x_i - \\bar{x})(y_i - \\bar{y})\\)に変わっていることです。\n\\[\n\\sigma_{xy}^2 = \\frac{\\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})}{N}\n\\]\nそれでは、\\((x_i - \\bar{x})(y_i - \\bar{y})\\)について考えたいと思います。この前半は既に述べたように\\(x_i\\)と平均値との差です。よって、前半は\\(x_i\\)が平均値よりも大きければ正、小さければ負の値になります。後半については\\(x_i\\)が\\(y_i\\)に置き換わっただけで、意味は同様です。\nしたがって、\\((x_i - \\bar{x})(y_i - \\bar{y})\\)全体としては\\(x_i\\)と\\(y_i\\)が共に平均値より大きいもしくは小さければ正の値を取ります。一方が平均値より大きく、他方が小さければ負の値を取ります。\nより直感的に言えば、\\(\\bar{x}\\)と\\(\\bar{y}\\)を原点とする平面を考えると、\\((x_i,y_i)\\)が第1（右上）もしくは第3象限（左下）にあるときに、\\((x_i - \\bar{x})(y_i - \\bar{y})\\)は正の値を取ります。逆に、第2（左上）もしくは第4象限（右下）にあるときは負の値を取ります。\n\n\n\n\\((x_i - \\bar{x})(y_i - \\bar{y})\\)の符号\n\n\n共分散はそのような\\((x_i - \\bar{x})(y_i - \\bar{y})\\)の平均値なので、正の値を取るということは\\(x\\)と\\(y\\)が正の比例関係にあり、負の値を取るということは負の比例関係にあるということを示唆しています。\n\n\n5.1.2 複数変数の選択\nそれでは、共分散を求めたいと思います。平均値や分散を求めるときは1つの変数をデータフレームから取り出しましたが、共分散の場合は2つ（あるいはそれ以上）の変数を取り出す必要があります。RとPythonではそれぞれ、次のように書きます。\n\n\n\nR\n\ndf_gap[,c(\"lifeExp\", \"gdpPercap\")]\n\n\n# A tibble: 1,704 × 2\n   lifeExp gdpPercap\n     &lt;dbl&gt;     &lt;dbl&gt;\n 1    28.8      779.\n 2    30.3      821.\n 3    32.0      853.\n 4    34.0      836.\n 5    36.1      740.\n 6    38.4      786.\n 7    39.9      978.\n 8    40.8      852.\n 9    41.7      649.\n10    41.8      635.\n# ℹ 1,694 more rows\n\n\n\nまず、データフレームの後ろに”[,]`を付けます。\n,の左側では横（観察）を選択しますが、今回は全ての観察を用いるので何も指定しません。\n,の右側では縦（変数）を選択します。c()の中に変数名オブジェクトを入れることで、複数の変数名のオブジェクトを作成しています。\n\nなお、Rではtidyverseというパッケージ群を使うことで、簡便にデータフレームの処理が可能になります。\n\n\n\n\n\n\ntidyverse\n\n\n\ntidyverseとは狭義には特定のパッケージの集まりです。広義には既存のRを改善するためのプロジェクトや考え方と言ってもいいかもしれません。\ntidyverseは主観的には便利なのですが、Rの標準的な書き方とはやや異なるため、結果的にRを分断しかねない要素もあります。この資料ではtidyverseを使って書こうと思います。\n\n\n具体的にはtidyverseの中のdplyrというパッケージを使いますが、tidyverseを読み込むだけで関連パッケージが全て読み込まれます。\n\n\n\nR\n\nlibrary(tidyverse)\n\ndf_gap |&gt; \n    select(lifeExp, gdpPercap)\n\n\n# A tibble: 1,704 × 2\n   lifeExp gdpPercap\n     &lt;dbl&gt;     &lt;dbl&gt;\n 1    28.8      779.\n 2    30.3      821.\n 3    32.0      853.\n 4    34.0      836.\n 5    36.1      740.\n 6    38.4      786.\n 7    39.9      978.\n 8    40.8      852.\n 9    41.7      649.\n10    41.8      635.\n# ℹ 1,694 more rows\n\n\n\nselect()を使います。\n\npandasでは[.loc[,](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)]メソッドを使います。\n\n\n\nPython\n\ndf_gap.loc[:,[\"lifeExp\", \"gdpPercap\"]]\n\n\n      lifeExp   gdpPercap\n0      28.801  779.445314\n1      30.332  820.853030\n2      31.997  853.100710\n3      34.020  836.197138\n4      36.088  739.981106\n...       ...         ...\n1699   62.351  706.157306\n1700   60.377  693.420786\n1701   46.809  792.449960\n1702   39.989  672.038623\n1703   43.487  469.709298\n\n[1704 rows x 2 columns]\n\n\n\n,の左側では横（観察）を選択しますが、今回は全ての観察を用いるので:を入れます。\n,の右側では縦（変数）を選択します。[]の中に変数名オブジェクトを入れることで、複数の変数名のオブジェクトを作成しています。\n\nなお、次のように省略して書くこともできます。\n\n\n\nPython\n\ndf_gap[[\"lifeExp\", \"gdpPercap\"]]\n\n\n\n\n5.1.3 共分散（再訪）\n共分散を求めます。なお、対角成分（左上や右下など）は分散を示しています。\n\n\n\nR\n\ncov(df_gap[,c(\"lifeExp\", \"gdpPercap\")])\n\n\n             lifeExp  gdpPercap\nlifeExp     166.8517    74323.2\ngdpPercap 74323.1957 97169410.1\n\n\n\n\n\nPython\n\ndf_gap.loc[:,[\"lifeExp\", \"gdpPercap\"]].cov()\n\n\n                lifeExp     gdpPercap\nlifeExp      166.851664  7.432320e+04\ngdpPercap  74323.195748  9.716941e+07\n\n\nところで、7.432320e+04とはなんぞやと思うかもしれません。これは浮動小数点と呼ばれるもので、\\(7.432320...\\times10^4 = 74323.20...\\)を意味しています。\n\n\n5.1.4 相関係数\n共分散は2つの変数の比例関係を示していますが、一つの問題があります。それは、変数の散らばり具合も含んでいるため、その値の解釈が難しいということです。試しに、人口も含めて共分散を求めてみます。\n\n\n\nR\n\ncov(df_gap[,c(\"lifeExp\", \"pop\", \"gdpPercap\")])\n\n\n               lifeExp           pop     gdpPercap\nlifeExp   1.668517e+02  8.907024e+07  7.432320e+04\npop       8.907024e+07  1.126950e+16 -2.678859e+10\ngdpPercap 7.432320e+04 -2.678859e+10  9.716941e+07\n\n\n例えば、平均寿命と人口の共分散は\\(89070240\\)で、平均寿命と一人あたりGDPの共分散は\\(74323\\)です。では、前者の方が大きな値を取っているので、人口のほうが一人あたりGDPよりも平均寿命と強い関係にあると言っていいでしょうか。もしかすると人口のほうが大きな値を取りやすいので、平均値よりも離れやすく、その結果として共分散も大きくなっているのかもしれません。\nそこで、変数の値の大きさに左右されずに関係性を示すものとして相関係数を使いたいと思います。相関係数は共分散を\\(x_i\\)の分散と\\(y_i\\)の分散の積で割ったものになります。\n\\[\n\\rho_{xy} = {\\sigma^2_{xy} \\over \\sigma_x \\sigma_y}\n\\]\n直感的に言えば、\\(x_i\\)の分散と\\(y_i\\)の分散で割ることによって、\\(x_i\\)と\\(y_i\\)の散らばり具合を相殺（調整）しています。結果として、相関係数は\\(-1\\)から\\(1\\)の間に収まります。\nそれでは、相関係数を求めます。人口よりも一人あたりGDPの方が平均寿命と高い相関係数を持っている、すなわち強い関係にあることが分かります。\n\n\n\nR\n\ncor(df_gap[,c(\"lifeExp\", \"pop\", \"gdpPercap\")])\n\n\n             lifeExp         pop   gdpPercap\nlifeExp   1.00000000  0.06495537  0.58370622\npop       0.06495537  1.00000000 -0.02559958\ngdpPercap 0.58370622 -0.02559958  1.00000000\n\n\n\n\n\nPython\n\ndf_gap.loc[:,[\"lifeExp\", \"pop\", \"gdpPercap\"]].corr()\n\n\n            lifeExp       pop  gdpPercap\nlifeExp    1.000000  0.064955   0.583706\npop        0.064955  1.000000  -0.025600\ngdpPercap  0.583706 -0.025600   1.000000",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>二変数の要約</span>"
    ]
  },
  {
    "objectID": "desc_correlation.html#可視化の重要性",
    "href": "desc_correlation.html#可視化の重要性",
    "title": "5  二変数の要約",
    "section": "5.2 可視化の重要性",
    "text": "5.2 可視化の重要性\nところで、これまで「強い関係」という言葉を定義せずに用いていました。重要なことは、相関係数で分かることは「どれくらい2つの変数が直線的な関係にあるか」ということ（だけ）です。\nここで、Wikipediaから画像を拝借して、この点を考えたいと思います。いわゆる散布図 (scatter plot) と呼ばれるもので、横軸が\\(x_i\\)、縦軸が\\(y_i\\)を表していると考えてください。\n\n\n\n相関係数\n\n\n\nまず、1段目を見ると分かるように相関係数は高い（低い）値を取れば取るほど2つの変数は直線に近づいていきます。また、相関係数が正であれば正の比例関係、負であれば負の比例関係にあることも分かります。\n\nなお、「どれくらい相関係数が高ければいいのか」というのは意味のない疑問だと思っています。例えば、\\(0.8\\)でも関係は弱いと思う人もいれば、\\(0.4\\)でも強いと思う人もいるでしょう。\n\n続いて、2段目では全ての図において相関係数は\\(1\\)（もしくは\\(-1\\)）になっています。ここで異なるのはそれぞれの直線の傾きです。「強い関係」と聞くと傾きが大きいと想像するかもしれませんが、相関係数はそこまで意味しません。\n最後に、3段目では全ての図において相関係数は\\(0\\)となっています。それぞれ2つの変数は何かしらの関係性を持っていそうですが、相関係数では直線以外の関係性を捉えることはできません。\n\n以上のことをまとめると、相関係数だけで分かることは少ないということではないでしょうか。そして教訓は相関係数という数値だけでなく、実際にグラフを作るということでしょう。\nこの点をより実感できるものとしてAnscombe”s quartetやDatasaurus Dozenというデータ（およびグラフ）があります。これらのデータは全て同じ平均値や分散、相関係数を持っていますが、それぞれ異なる印象を与えます。\n\n\n\nAnscombe”s quartet\n\n\n\n\n\nDatasaurus Dozen\n\n\nしたがって、相関係数だけでなく平均値や分散についても数値だけを見るのではなく、グラフを作って確認するのがよいでしょう。グラフの作成は次章からのテーマです。",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>二変数の要約</span>"
    ]
  },
  {
    "objectID": "desc_correlation.html#連続変数と離散変数の関係",
    "href": "desc_correlation.html#連続変数と離散変数の関係",
    "title": "5  二変数の要約",
    "section": "5.3 連続変数と離散変数の関係",
    "text": "5.3 連続変数と離散変数の関係\n\n5.3.1 グループごとの平均値\nグループごとに平均値を求めることで、離散変数と連続変数の関係を見ることができます。Rではすでに触れたtidyverseによって簡単に処理できます。\n\n\n\nR\n\ndf_gap |&gt; \n    group_by(continent) |&gt; \n    summarise(mean_lifeExp = mean(lifeExp), \n              mean_pop = mean(pop), \n              mean_gdpPercap = mean(gdpPercap))\n\n\n# A tibble: 5 × 4\n  continent mean_lifeExp  mean_pop mean_gdpPercap\n  &lt;fct&gt;            &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n1 Africa            48.9  9916003.          2194.\n2 Americas          64.7 24504795.          7136.\n3 Asia              60.1 77038722.          7902.\n4 Europe            71.9 17169765.         14469.\n5 Oceania           74.3  8874672.         18622.\n\n\n\nまず、group_by()でどの変数がグループを表しているかを指定します。\n次に、summarise()の中で平均値を計算し、新しい変数として定義します。\n\nここでは&lt;-やないんかいと突っ込みたくなりますが、=なので気をつけてください。\n\n\npandasではこのように書きます。\n\n\n\nPython\n\ndf_gap.groupby(\"continent\")[[\"lifeExp\", \"pop\", \"gdpPercap\"]].mean()\n\n\n             lifeExp           pop     gdpPercap\ncontinent                                       \nAfrica     48.865330  9.916003e+06   2193.754578\nAmericas   64.658737  2.450479e+07   7136.110356\nAsia       60.064903  7.703872e+07   7902.150428\nEurope     71.903686  1.716976e+07  14469.475533\nOceania    74.326208  8.874672e+06  18621.609223\n\n\n\nまず、groupby()でどの変数がグループを表しているかを指定します。\n次に[[...]]で平均値を計算したい変数を指定します。\n最後に、.mean()で平均値を求めます。\n\npandasでの集計には注意が必要です。グループとして使った変数continentは集計後のデータフレームでは変数ではなくindexになっています。\n\nindexとは各観察（行）を表す目印のようなものです。\n\nグループ化に使った変数をindexとせずに、変数のままにする場合は、次のようにas_index=Falseを付けます。\n\n\n\nPython\n\ndf_gap.groupby(\"continent\", as_index=False)[[\"lifeExp\", \"pop\", \"gdpPercap\"]].mean()\n\n\n  continent    lifeExp           pop     gdpPercap\n0    Africa  48.865330  9.916003e+06   2193.754578\n1  Americas  64.658737  2.450479e+07   7136.110356\n2      Asia  60.064903  7.703872e+07   7902.150428\n3    Europe  71.903686  1.716976e+07  14469.475533\n4   Oceania  74.326208  8.874672e+06  18621.609223\n\n\n平均値だけでなく、その他の要約統計量も同様に計算できます。\n\n\n5.3.2 グループのネスト\nグループを表す変数は1つに限る必要はありません。例えば、各年の各大陸の平均値を求めることも可能です。\n\n\n\nR\n\nlibrary(tidyverse)\n\ndf_gap |&gt; \n    group_by(continent, year) |&gt; \n    summarise(mean_lifeExp = mean(lifeExp), \n              mean_pop = mean(pop), \n              mean_gdpPercap = mean(gdpPercap))\n\n\n# A tibble: 60 × 5\n# Groups:   continent [5]\n   continent  year mean_lifeExp  mean_pop mean_gdpPercap\n   &lt;fct&gt;     &lt;int&gt;        &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n 1 Africa     1952         39.1  4570010.          1253.\n 2 Africa     1957         41.3  5093033.          1385.\n 3 Africa     1962         43.3  5702247.          1598.\n 4 Africa     1967         45.3  6447875.          2050.\n 5 Africa     1972         47.5  7305376.          2340.\n 6 Africa     1977         49.6  8328097.          2586.\n 7 Africa     1982         51.6  9602857.          2482.\n 8 Africa     1987         53.3 11054502.          2283.\n 9 Africa     1992         53.6 12674645.          2282.\n10 Africa     1997         53.6 14304480.          2379.\n# ℹ 50 more rows\n\n\n\n\n\nPython\n\ndf_gap.groupby([\"continent\", \"year\"])[[\"lifeExp\", \"pop\", \"gdpPercap\"]].mean()\n\n\n                  lifeExp           pop     gdpPercap\ncontinent year                                       \nAfrica    1952  39.135500  4.570010e+06   1252.572466\n          1957  41.266346  5.093033e+06   1385.236062\n          1962  43.319442  5.702247e+06   1598.078825\n          1967  45.334538  6.447875e+06   2050.363801\n          1972  47.450942  7.305376e+06   2339.615674\n          1977  49.580423  8.328097e+06   2585.938508\n          1982  51.592865  9.602857e+06   2481.592960\n          1987  53.344788  1.105450e+07   2282.668991\n          1992  53.629577  1.267464e+07   2281.810333\n          1997  53.598269  1.430448e+07   2378.759555\n          2002  53.325231  1.603315e+07   2599.385159\n          2007  54.806038  1.787576e+07   3089.032605\nAmericas  1952  53.279840  1.380610e+07   4079.062552\n          1957  55.960280  1.547816e+07   4616.043733\n          1962  58.398760  1.733081e+07   4901.541870\n          1967  60.410920  1.922986e+07   5668.253496\n          1972  62.394920  2.117537e+07   6491.334139\n          1977  64.391560  2.312271e+07   7352.007126\n          1982  66.228840  2.521164e+07   7506.737088\n          1987  68.090720  2.731016e+07   7793.400261\n          1992  69.568360  2.957096e+07   8044.934406\n          1997  71.150480  3.187602e+07   8889.300863\n          2002  72.422040  3.399091e+07   9287.677107\n          2007  73.608120  3.595485e+07  11003.031625\nAsia      1952  46.314394  4.228356e+07   5195.484004\n          1957  49.318544  4.735699e+07   5787.732940\n          1962  51.563223  5.140476e+07   5729.369625\n          1967  54.663640  5.774736e+07   5971.173374\n          1972  57.319269  6.518098e+07   8187.468699\n          1977  59.610556  7.225799e+07   7791.314020\n          1982  62.617939  7.909502e+07   7434.135157\n          1987  64.851182  8.700669e+07   7608.226508\n          1992  66.537212  9.494825e+07   8639.690248\n          1997  68.020515  1.025238e+08   9834.093295\n          2002  69.233879  1.091455e+08  10174.090397\n          2007  70.728485  1.155138e+08  12473.026870\nEurope    1952  64.408500  1.393736e+07   5661.057435\n          1957  66.703067  1.459635e+07   6963.012816\n          1962  68.539233  1.534517e+07   8365.486814\n          1967  69.737600  1.603930e+07  10143.823757\n          1972  70.775033  1.668784e+07  12479.575246\n          1977  71.937767  1.723882e+07  14283.979110\n          1982  72.806400  1.770890e+07  15617.896551\n          1987  73.642167  1.810314e+07  17214.310727\n          1992  74.440100  1.860476e+07  17061.568084\n          1997  75.505167  1.896480e+07  19076.781802\n          2002  76.700600  1.927413e+07  21711.732422\n          2007  77.648600  1.953662e+07  25054.481636\nOceania   1952  69.255000  5.343003e+06  10298.085650\n          1957  70.295000  5.970988e+06  11598.522455\n          1962  71.085000  6.641759e+06  12696.452430\n          1967  71.310000  7.300207e+06  14495.021790\n          1972  71.910000  8.053050e+06  16417.333380\n          1977  72.855000  8.619500e+06  17283.957605\n          1982  74.290000  9.197425e+06  18554.709840\n          1987  75.320000  9.787208e+06  20448.040160\n          1992  76.945000  1.045983e+07  20894.045885\n          1997  78.190000  1.112072e+07  24024.175170\n          2002  79.740000  1.172741e+07  26938.778040\n          2007  80.719500  1.227497e+07  29810.188275\n\n\nしかし、ここまで多いとよく分からないので、やはりグラフにするのが人類には優しいのでしょう。",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>二変数の要約</span>"
    ]
  },
  {
    "objectID": "desc_correlation.html#平均値や分散共分散の性質-optional",
    "href": "desc_correlation.html#平均値や分散共分散の性質-optional",
    "title": "5  二変数の要約",
    "section": "5.4 平均値や分散、共分散の性質 (optional)",
    "text": "5.4 平均値や分散、共分散の性質 (optional)",
    "crumbs": [
      "データの要約",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>二変数の要約</span>"
    ]
  },
  {
    "objectID": "plot_distribution.html",
    "href": "plot_distribution.html",
    "title": "6  分布のグラフ",
    "section": "",
    "text": "6.1 使用するパッケージ",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>分布のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_distribution.html#使用するパッケージ",
    "href": "plot_distribution.html#使用するパッケージ",
    "title": "6  分布のグラフ",
    "section": "",
    "text": "6.1.1 ggplot2\nRでグラフを作る場合、デフォルトの関数を使うこともできますが、ggplot2と呼ばれるパッケージを使うことも多いです。この資料ではggplot2を使う方法を紹介します。なお、ggplot2はtigyverseに含まれています。\n\n\n\nR\n\nlibrary(tidyverse)\n\n\n\n\n6.1.2 matplotlib/seaborn\nPythonの場合、matplotlibというパッケージを使って作図することがデファクト・スタンダードとなっています。また、しばしば、seabornというパッケージを併用して、より柔軟な作図を行うことがあります。\n\n\n\nPython\n\nfrom matplotlib import pyplot as plt\n\n\nこれまでと、やや書き方が異なっています。まず、fromについて説明します。Pythonのパッケージは入れ子構造になっています。つまり、matplotlibというパッケージの中にpyplotというパッケージが含まれています。すなわち、matplotlibの中のpyplotだけを呼び出すという意味です。なお、以下のコードは同じ意味です。\n\n\n\nPython\n\nimport matplotlib.pyplot as plt\n\n\n次にasについて説明します。as以下がない場合、pyplotの中の関数などを使う際にはpyplot.と書く必要がありますが、それは面倒な気もします。asで仮名を与えることで、plt.と短縮して書くことができます。別にpltである必要はないのですが、デファクト・スタンダードとして使われています。\n\n\n\nPython\n\nimport seaborn as sns\n\n\n\n\n6.1.3 お手本を探す\n自分でこのようなグラフを作りたいと頭の中にあったとしても、それを作るためのコードを探すのは一苦労です。まずは、「お手本」を見つけて、そのコードを参考にするのがよいでしょう。例えば、以下のようなサイトは「お手本」を探す際に有用です。\n\nThe R Graph Gallery\nggplot2 extensions - gallery\nmatplotlib - Examples\nseaborn - Example gallery\n\nその上で分からないことがあれば、公式サイトのreferenceを参照したり、ググります。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>分布のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_distribution.html#ヒストグラム",
    "href": "plot_distribution.html#ヒストグラム",
    "title": "6  分布のグラフ",
    "section": "6.2 ヒストグラム",
    "text": "6.2 ヒストグラム\nある1つの変数がどのように散らばっているかを分布 (distribution) と言いますが、これを可視化するものとしてヒストグラム (histogram) があります。\nまず、Rでggplot2を使ってヒストグラムを作ります。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_histogram(aes(x = lifeExp))\n\n\n\n\n\n\n\n\n\n\nまず、ggplot()の中に、作図に使用するデータフレームを入れます。そして、+をつけます。イメージとしてはggplot()でキャンバスを作り、そこに絵を+で重ねていきます。\ngeom_histogram()でヒストグラムを作図します（geomはgeometoryの略です）。その中でaes()によってどの変数を作図に使うかを示します（aesはaestheticsの略です）。今回はヒストグラムの横軸（x軸）に平均寿命を使うことを支持しています。\n\n次に、Pythonでmatplotlibを使ってヒストグラムを作ります。\n\n\n\nPython (matplotlib)\n\nplt.hist(x=df_gap[\"lifeExp\"])\n\n\n\n\n\n\n\n\n\n\nplt.hist()でヒストグラムを作図することを宣言し、その中に平均寿命の変数を入れます。\n\nseabornの場合はhistplot()を使って書きます。少しggplot2に近い書き方です。\n\n\n\nPython (seaborn)\n\nsns.histplot(df_gap, x=\"lifeExp\")\n\n\n\n\n\n\n\n\n\n\n6.2.1 pandasのメソッド\nなお、pandasのデータフレームには作図属性plot()があります。その中のメソッドでヒストグラムを作成できます。\n\n\n\nPython (pandas)\n\ndf_gap.plot.hist(column=\"lifeExp\")\n\n\n\n\n\n\n\n\n\n\n\n6.2.2 ビンの幅\nところで、この3つのグラフを見ると、少しずつ異なることが分かります。そもそもヒストグラムとはどのようなグラフなのでしょうか。ヒストグラムでは、まず変数を等間隔のグループに分けていきます。そして、各グループ内で観察の数を数えて、それをy軸に取ります。そうすることで、どのような値を取る観察が多いのかを可視化します。\nヒストグラムではグループを決める幅のことをビンと呼びます。例えば、ggplot2で作図した時に出てくるメッセージを見ると、30個のビンを作っていることが分かります。つまり、平均寿命の値を30等分して、ビンを作っています。\nそれでは、Pythonでもビンを30個にするとどうなるでしょうか。それぞれのパッケージのreferenceなどを読んでみましょう。\n\n\n\nPython (matplotlib)\n\nplt.hist(x=df_gap[\"lifeExp\"], bins=30)\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.histplot(df_gap, x=\"lifeExp\", bins=30)\n\n\n\n\n\n\n\n\n\n仕様のため、厳密には異なりますが、近いグラフが出力されました。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>分布のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_distribution.html#カーネル密度プロット",
    "href": "plot_distribution.html#カーネル密度プロット",
    "title": "6  分布のグラフ",
    "section": "6.3 カーネル密度プロット",
    "text": "6.3 カーネル密度プロット\nヒストグラムと同じ目的のグラフとしてカーネル密度 (kernel density) プロットというものがあります。直観的に言って、ヒストグラムを「なめらかに」したものです。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_density(aes(x = lifeExp))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.kdeplot(df_gap, x=\"lifeExp\")\n\n\n\n\n\n\n\n\n\n\nggplot2のgeom_density()やseabornのdisplot()を使います。\nseabornではkdeplot()を使います。\n\nmtplotlibでは簡単にカーネル密度を作図することはできませんが、pandasのメソッドでは可能です。\n\nあらかじめscipyというパッケージをインストールしておきます。\n\n\n\n\nPython (pandas)\n\ndf_gap[\"lifeExp\"].plot.kde()",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>分布のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_distribution.html#可視化と要約統計",
    "href": "plot_distribution.html#可視化と要約統計",
    "title": "6  分布のグラフ",
    "section": "6.4 可視化と要約統計",
    "text": "6.4 可視化と要約統計\n平均寿命のヒストグラムやカーネル密度プロットを見ていると、要約統計では不十分であることが分かるかと思います。例えば、45歳付近と75歳付近に2つのピークがありますが、平均値や中央値を使っても、このことは分かりません。\nついでに、平均値と中央値の関係について言及しておきます。以下のグラフは各国の一人あたりGDPの分布のグラフに平均値（実線）と中央値（破線）を縦線で表したものです。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_histogram(aes(x = gdpPercap)) + \n    geom_vline(aes(xintercept = mean(gdpPercap))) + \n    geom_vline(aes(xintercept = median(gdpPercap)), linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\ngeom_vline()で垂直な線を作図します。aes()内ではxではなく、xinterceptである点に注意してください。\nlinetypeで線の種類を指定します。\n\n\n\n\nPython (matplotlib)\n\nplt.hist(df_gap[\"gdpPercap\"])\nplt.axvline(x = df_gap[\"gdpPercap\"].mean(), color=\"black\")\nplt.axvline(x = df_gap[\"gdpPercap\"].median(), color=\"black\", linestyle=\"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.histplot(df_gap, x=\"gdpPercap\")\nplt.axvline(x = df_gap[\"gdpPercap\"].mean(), color=\"black\")\nplt.axvline(x = df_gap[\"gdpPercap\"].median(), color=\"black\", linestyle=\"dashed\")\n\n\n\n\n\n\n\n\n\n\nmatplotlibではplt.axvline()で垂線を描きます（seabornもmatplotlibの一種なので併用できます）。\nlinestyleで線の種類を指定します。\n\nところで、一人あたりGDPのように極端に大きな（あるいは小さな）値をとる観察がある分布をロングテールと呼んだりします。また、「右（左）裾が長い」とか「右（左）に歪んだ」(right[left]-skewed) 分布と呼ぶこともあります。\nこのように歪んだ分布の場合、平均値と中央値は一致しません。平均値は大きな（あるいは小さな）値に左右されるので、例えば億万長者がいれば、平均値は大きくなります。一方で、中央値はあくまで50%という位置を表しているので、億万長者がいくら稼いでいても中央値は変わりません。分布が歪んでいる場合（すなわち平均値と中央値が乖離している場合）、どちらに関心があるのかを明確にする必要があるでしょう。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>分布のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_distribution.html#棒グラフ",
    "href": "plot_distribution.html#棒グラフ",
    "title": "6  分布のグラフ",
    "section": "6.5 棒グラフ",
    "text": "6.5 棒グラフ\nヒストグラムもカーネル密度プロットも連続変数の分布を見るグラフでした。それでは、離散変数の分布も見てみたいと思います（それを分布と呼んでいいのかは分かりませんが）。その場合は棒グラフ (bar chart) を使います。\n試しに、大陸ごとの観察数を可視化したいと思います。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_bar(aes(x = continent))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.countplot(df_gap, x=\"continent\")\n\n\n\n\n\n\n\n\n\n\nggplot2のgeom_bar()やseabornのcountplot()を使います。\n\nmatplotlibでは、まず集計してから、bar()で作図します。\n\n\n\nPython (matplotlib)\n\ndf_continent=df_gap.value_counts(\"continent\")\n\nplt.bar(df_continent.index, df_continent.values)\n\n\n\n\n\n\n\n\n\nただ、集計したデータフレームのメソッドで作図もできます。\n\n\n\nPython (pandas)\n\ndf_continent=df_gap.value_counts(\"continent\")\n\ndf_continent.plot.bar()",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>分布のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_distribution.html#グループごとの分布",
    "href": "plot_distribution.html#グループごとの分布",
    "title": "6  分布のグラフ",
    "section": "6.6 グループごとの分布",
    "text": "6.6 グループごとの分布\nところで、なぜ平均寿命の分布はフタコブラクダのようになっているのでしょうか。ここでは、地域ごとに異なるという仮説を検討したいと思います。そのために、地域ごとに平均寿命の分布を可視化します。\n一つのやり方は地域ごとに色を塗り分けるというものです。もう一つのやり方は地域ごとにグラフを作成するというものですが、これはいずれ扱います。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_histogram(aes(x = lifeExp, fill = continent))\n\n\n\n\n\n\n\n\n\n\nfillで色分けに使う変数を指定します。\n\n\n\n\nPython (seaborn)\n\nsns.histplot(df_gap, x=\"lifeExp\", hue=\"continent\")\n\n\n\n\n\n\n\n\n\n\nhueで色分けに使う変数を指定します。\n\nここから分かることはアフリカの国が左側のコブを作っていて、ヨーロッパやアメリカの国が右側のコブを作っているということでしょう。\nところで、上と下のグラフは少し異なります。上のggplot2のグラフではそれぞれの大陸のデータが積み重なっています。一方で、下のseabornのグラフではそれぞれの大陸のデータが別個に重ねて描かれています。\nggplot2で下のように描くには次のようにします。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_histogram(aes(x = lifeExp, fill = continent), position = \"identity\", alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nposition = \"identity\"によって、そのままの値で作図します。\n重ね塗りされるので、alpha = 0.5で少し透過させます。\n\n逆に、seabornで上のように描くには次のようにします。\n\n\n\nPython (seaborn)\n\nsns.histplot(df_gap, x=\"lifeExp\", hue=\"continent\", multiple=\"stack\")\n\n\n\n\n\n\n\n\n\n\nstacked=Trueあるいはmultiple=\"stack\"で積み重ねて作図します。\n\nあるいは、ggplot2でもseabornでも次のようなグラフを描くこともできます。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_histogram(aes(x = lifeExp, fill = continent), position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.histplot(df_gap, x=\"lifeExp\", hue=\"continent\", multiple=\"dodge\")",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>分布のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_correlation.html",
    "href": "plot_correlation.html",
    "title": "7  相関のグラフ",
    "section": "",
    "text": "7.1 散布図\n連続変数同士の関係を可視化するグラフを散布図 (scatter plot) と呼びます。ヒストグラムなどを作図するときとほとんど同じようにできることが分かるかと思います。\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_point(aes(x = gdpPercap, y = lifeExp))\nPython (matplotlib)\n\nplt.scatter(x=df_gap[\"gdpPercap\"], y=df_gap[\"lifeExp\"])\nPython (pandas)\n\ndf_gap.plot.scatter(x=\"gdpPercap\", y=\"lifeExp\")\nPython (seaborn)\n\nsns.scatterplot(df_gap, x=\"gdpPercap\", y=\"lifeExp\")\n一人あたりGDPと平均寿命の関係が直線的ではないことが分かります。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_correlation.html#散布図",
    "href": "plot_correlation.html#散布図",
    "title": "7  相関のグラフ",
    "section": "",
    "text": "geom_point()で散布図を作成し、aes()の中でx軸とy軸に使う変数を指定します。\n\n\n\n\n\nmatplotlibのsctter()やseabornのscatterplot()を使います。\n同じように、適当な関数を使って、x軸とy軸を指定します。\n\n\n\n7.1.1 周辺密度付き散布図\n散布図と各変数の分布（周辺密度 [marginal density]）を同時に表示することもできます。seanbornのjointplot()を使ってみます。\n\n\n\nPython (seaborn)\n\nsns.jointplot(df_gap, x=\"gdpPercap\", y=\"lifeExp\")\n\n\n&lt;seaborn.axisgrid.JointGrid object at 0x7ff4bc566810&gt;\n\n\n\n\n\n\n\n\n\nggplot2の場合は、拡張パッケージであるggExtraを使います。\n\n\n\nR (ggplot2)\n\nlibrary(ggExtra)\n\np &lt;- ggplot(df_gap) + \n    geom_point(aes(x = gdpPercap, y = lifeExp))\nggMarginal(p)\n\n\n\n\n\n\n\n\n\n\n一度、画像をオブジェクトとして保存して、ggMarginal()に入れます。\n\n\n\n7.1.2 グループごとの散布図\n分布のときと同様に、散布図でもグループごとに色分けすることができます。以下に見るグラフも同様です。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_point(aes(x = gdpPercap, y = lifeExp, color = continent))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.scatterplot(df_gap, x=\"gdpPercap\", y=\"lifeExp\", hue=\"continent\")",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_correlation.html#同時分布",
    "href": "plot_correlation.html#同時分布",
    "title": "7  相関のグラフ",
    "section": "7.2 同時分布",
    "text": "7.2 同時分布\nカーネル密度プロットを二次元に拡張したグラフを作成することもできます。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_density_2d(aes(x = gdpPercap, y = lifeExp))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.kdeplot(df_gap, x=\"gdpPercap\", y=\"lifeExp\")\n\n\n\n\n\n\n\n\n\n\nseabornだとなんかうまくいかないです。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_correlation.html#ジッター",
    "href": "plot_correlation.html#ジッター",
    "title": "7  相関のグラフ",
    "section": "7.3 ジッター",
    "text": "7.3 ジッター\n連続変数と離散変数の関係を見るとき、散布図を作成するとよく分からないグラフができます。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_point(aes(x = continent, y = lifeExp))\n\n\n\n\n\n\n\n\n\n\nこの例では、同じ大陸にある国の平均寿命は同じ直線上に描かれるので、どのような値が多いのかは分かりにくいです。\n\nこのような場合、ジッター（ゆらぎ）を与えることで見えやすくなります。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_jitter(aes(x = continent, y = lifeExp))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.stripplot(df_gap, x=\"continent\", y=\"lifeExp\")\n\n\n\n\n\n\n\n\n\n\ngeom_jitter()やstripplot()を使います。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_correlation.html#複数の変数の分布と散布図",
    "href": "plot_correlation.html#複数の変数の分布と散布図",
    "title": "7  相関のグラフ",
    "section": "7.4 複数の変数の分布と散布図",
    "text": "7.4 複数の変数の分布と散布図\nここまで一変数の分布や二変数間の相関を可視化してきました。論文にする際には重要な変数のグラフを作成すればよいですが、データ分析を始める段階でひとまずデータの特徴を把握したい場合には、いちいちそれぞれのグラフを作るのは面倒です。\nここではデータに含まれる変数の分布や相関をひと目で可視化したいと思います。seabornのpairplot()を使います。\n\n\n\nPython (seaborn)\n\nsns.pairplot(df_gap.loc[:, [\"lifeExp\", \"pop\", \"gdpPercap\"]]);\n\n\n\n\n\n\n\n\n\nggplot2ではGGallyというパッケージのggpairs()を使います。\n\n\n\nR (ggplot2)\n\nlibrary(GGally)\n\ndf_gap |&gt; \n    select(lifeExp, pop, gdpPercap) |&gt; \n    ggpairs()",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_correlation.html#棒グラフ",
    "href": "plot_correlation.html#棒グラフ",
    "title": "7  相関のグラフ",
    "section": "7.5 棒グラフ",
    "text": "7.5 棒グラフ\nあるいはグループごとに平均値（や中央値）を計算し、その棒グラフを描くということも、よくやられます。\n\n\n\nR (ggplot2)\n\ndf_cont_life &lt;- df_gap |&gt; \n    group_by(continent) |&gt; \n    summarise(mean_lifeExp = mean(lifeExp))\n\nggplot(df_cont_life) + \n    geom_col(aes(x = continent, y = mean_lifeExp))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (matplotlib)\n\ndf_cont_life = df_gap.groupby(\"continent\", as_index=False)[\"lifeExp\"].mean()\n\nplt.bar(x=df_cont_life[\"continent\"], height=df_cont_life[\"lifeExp\"])\n\n\n\n\n\n\n\n\n\n\n\n\nPython (pandas)\n\ndf_cont_life.plot.bar(x=\"continent\", y=\"lifeExp\")\n\n\n\n\n\n\n\n\n\n\nまずはグループごとの平均寿命の平均値を求めたデータフレームを作成し、それに基づいてグラフを描きます。\n\nseabornの場合はbarplotが自動で集計してくれます。\n\n\n\nPython (seaborn)\n\nsns.barplot(df_gap, x=\"continent\", y=\"lifeExp\", errorbar=None)\n\n\n\n\n\n\n\n\n\n\nエラーバー（後述）は表示しないように設定しておきます。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_correlation.html#箱ひげ図",
    "href": "plot_correlation.html#箱ひげ図",
    "title": "7  相関のグラフ",
    "section": "7.6 箱ひげ図",
    "text": "7.6 箱ひげ図\n平均値の棒グラフはよく使われますが、平均値しか分からないという欠点があります。そこで、箱ひげ図 (boxplot) を使うことで平均値以外の情報も可視化できます。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_boxplot(aes(x = continent, y = lifeExp))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (matplotlib)\n\ndf_gap.boxplot(column=\"lifeExp\", by=\"continent\")\n\n\n\n\n\n\n\n\n\n\n\n\nPython (pandas)\n\ndf_gap.plot.box(column=\"lifeExp\", by=\"continent\")\n\n\nlifeExp    Axes(0.125,0.11;0.775x0.77)\ndtype: object\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.boxplot(df_gap, x=\"continent\", y=\"lifeExp\")\n\n\n\n\n\n\n\n\n\n\n箱ひげ図の定義はパッケージ等によって異なるので、確認してください。例えば、wikipediaによると次のような定義となっています。\n\n\n\n\n箱ひげ図の定義（一例）\n\n\n\ngeom_boxplot()やboxplot()を使います。\n\n例えば、ヨーロッパとオセアニアは平均値は近いですが、散らばり具合は異なることが分かります。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_correlation.html#バイオリンプロット",
    "href": "plot_correlation.html#バイオリンプロット",
    "title": "7  相関のグラフ",
    "section": "7.7 バイオリンプロット",
    "text": "7.7 バイオリンプロット\nグループごとにカーネル密度プロットを描くグラフをバイオリンプロットと呼びます。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_violin(aes(x = continent, y = lifeExp))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.violinplot(df_gap, x=\"continent\", y=\"lifeExp\")\n\n\n\n\n\n\n\n\n\n\ngeom_violinplot()やviolinplot()を使います。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_correlation.html#ヒートマップ",
    "href": "plot_correlation.html#ヒートマップ",
    "title": "7  相関のグラフ",
    "section": "7.8 ヒートマップ",
    "text": "7.8 ヒートマップ\n離散変数同士の関係を見る場合はヒートマップを使います。gapminderには離散変数は大陸しか含まれていないので、無駄ではありますが、平均寿命を離散変数にしたいと思います。具体的には、平均寿命を四捨五入して10年ごとの変数を作成します（例えば58歳なら60歳）。\n\n7.8.1 変数の追加\nデータフレームに変数を追加する場合は、新しい変数名を使って列を指定して、変数の内容を代入します。\n\n\n\nR (ggplot2)\n\ndf_gap[,\"lifeExp10\"] &lt;- round(df_gap[,\"lifeExp\"], digits=-1)\n\nhead(df_gap)\n\n\n# A tibble: 6 × 7\n  country     continent  year lifeExp      pop gdpPercap lifeExp10\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.        30\n2 Afghanistan Asia       1957    30.3  9240934      821.        30\n3 Afghanistan Asia       1962    32.0 10267083      853.        30\n4 Afghanistan Asia       1967    34.0 11537966      836.        30\n5 Afghanistan Asia       1972    36.1 13079460      740.        40\n6 Afghanistan Asia       1977    38.4 14880372      786.        40\n\n\n\n\n\nPython\n\ndf_gap[\"lifeExp10\"] = df_gap[\"lifeExp\"].round(decimals=-1)\n\ndf_gap.head()\n\n\n       country continent  year  lifeExp       pop   gdpPercap  lifeExp10\n0  Afghanistan      Asia  1952   28.801   8425333  779.445314       30.0\n1  Afghanistan      Asia  1957   30.332   9240934  820.853030       30.0\n2  Afghanistan      Asia  1962   31.997  10267083  853.100710       30.0\n3  Afghanistan      Asia  1967   34.020  11537966  836.197138       30.0\n4  Afghanistan      Asia  1972   36.088  13079460  739.981106       40.0\n\n\n\nround()という関数・メソッドで四捨五入をします。digits/decimalsでは小数点第何位で四捨五入をするのかを決めています。例えば、digits/decimals=1であれば、結果が小数点第1位になるように四捨五入をします。すなわち、小数点第2位に基づいて四捨五入をします。したがって、digits/decimals=-1であれば小数点第-1位（そんなものはありませんが）、すなわち1の位で四捨五入をします。\n\n\n\n7.8.2 ヒートマップの作図\nそれでは、ヒートマップを作図します。そのために、大陸ごとに10歳ごとの平均寿命が同じ国の数を計算します。\n\n\n\nR (ggplot2)\n\ndf_cont_life10 &lt;- df_gap |&gt; \n    count(continent, lifeExp10)\n\nggplot(df_cont_life10) + \n    geom_tile(aes(x = continent, y = lifeExp10, fill = n))\n\n\n\n\n\n\n\n\n\n\ncount()によって変数の値（ここでは大陸及び四捨五入済み平均寿命）ごとに観察数を計算します。\ngeom_tile()でヒートマップを作成しますが、fillによってどの変数によって色を塗るか決めます。ここでは観察数であるn（count()によって作成された変数）を指定します。\n\nPythonでヒートマップを作図するには、ひと手間かかります。いずれ改めて触れたいと思います。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_line.html",
    "href": "plot_line.html",
    "title": "8  時系列のグラフ",
    "section": "",
    "text": "8.1 折れ線グラフ",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>時系列のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_line.html#折れ線グラフ",
    "href": "plot_line.html#折れ線グラフ",
    "title": "8  時系列のグラフ",
    "section": "",
    "text": "8.1.1 単体の折れ線グラフ\n例えば、前章で見た棒グラフや箱ひげ図を使っても構いませんが、折れ線グラフ (line plot) を使うことが多いと思います。ここでは、各年の平均寿命の平均値の折れ線グラフを描きたいと思います。\n\n\n\nR (ggplot2)\n\ndf_year_life &lt;- df_gap |&gt; \n    group_by(year) |&gt; \n    summarise(mean_lifeExp = mean(lifeExp))\n\nggplot(df_year_life) + \n    geom_line(aes(x = year, y = mean_lifeExp))\n\n\n\n\n\n\n\n\n\n\ngeom_line()\n\n\n\n\nPython (matplotlib)\n\ndf_year_life = df_gap.groupby(\"year\", as_index=False)[\"lifeExp\"].mean()\n\nplt.plot(df_year_life[\"year\"], df_year_life[\"lifeExp\"])\n\n\n\n\n\n\n\n\n\n\nplot()\n\n\n\n\nPython (pandas)\n\ndf_year_life.plot(x=\"year\", y=\"lifeExp\")\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.lineplot(df_gap, x=\"year\", y=\"lifeExp\", errorbar=None)\n\n\n\n\n\n\n\n\n\n\nlineplot()\nerrorbar=Noneはおまじないです。\n\n\n\n8.1.2 複数の折れ線グラフ\n折れ線グラフは必ずしも一本である必要はありません。例えば全ての国の平均寿命の変化を折れ線グラフにすることも可能です。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_line(aes(x = year, y = lifeExp))\n\n\n\n\n\n\n\n\n\nただ、素朴にデータからそのまま折れ線グラフを作図すると、不可思議なグラフが出来上がります。なぜなら、R/Pythonは全てのデータを「一筆書き」で繋げようとしているからです。したがって、ここでは国ごとに折れ線グラフを描くように指示する必要があります。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_line(aes(x = year, y = lifeExp, group = country))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.lineplot(df_gap, x=\"year\", y=\"lifeExp\", units=\"country\", estimator=None)\n\n\n\n\n\n\n\n\n\n\nそれぞれgroupやunitsによって、どの変数ごとに折れ線グラフを描くかを指定します。\nseabornの場合、おまじないとしてestimator=Noneも追記します。\nmatplotlibでの作図は面倒なので割愛します。\n\n全ての国の折れ線グラフを作図することで散らばりや、逸脱例などが分かります。\n\n\n8.1.3 線の太さ・透過度\n一方で、線が多いと見にくい気もします。この場合、線を少し細くしたり、透明にすると見やすくなるかもしれません。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_line(aes(x = year, y = lifeExp, group = country), linewidth = 0.25, alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nlinewidthで線の太さ、alphaで透過度を指定します。\nところで、aes()の中と外のどっちで指定するんや、と疑問に思うかもしれません。データの変数を使う場合はaes()の中、特定の値を指定する場合は外になります。\nseabornでのやり方は分かりませんでした。\n\n\n\n8.1.4 グループごとの折れ線グラフ\nこれまでと同様に、折れ線グラフもグループごとに作図できます。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_line(aes(x = year, y = lifeExp, group = country, color = continent))\n\n\n\n\n\n\n\n\n\n\n\n\nPython (seaborn)\n\nsns.lineplot(df_gap, x=\"year\", y=\"lifeExp\", units=\"country\", hue=\"continent\", estimator=None)",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>時系列のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_line.html#ヒートマップ再訪",
    "href": "plot_line.html#ヒートマップ再訪",
    "title": "8  時系列のグラフ",
    "section": "8.2 ヒートマップ（再訪）",
    "text": "8.2 ヒートマップ（再訪）\n前章で触れたヒートマップを使って時系列の変化を見ることもできます。\n\n\n\nR (ggplot2)\n\nggplot(df_gap) + \n    geom_tile(aes(x = year, y = country, fill = lifeExp))",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>時系列のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_line.html#二変数の折れ線グラフ",
    "href": "plot_line.html#二変数の折れ線グラフ",
    "title": "8  時系列のグラフ",
    "section": "8.3 二変数の折れ線グラフ",
    "text": "8.3 二変数の折れ線グラフ\nこれまで、ある1つの変数が時系列でどのように変化するかを可視化してきました。次は、ある2つの変数の時系列変化を可視化したいと思います。試しに、各年の平均寿命の平均値と一人あたりGDPの平均値の変動を見たいと思います。\n\n\n\nR (ggplot2)\n\ndf_gap_sum &lt;- df_gap |&gt; \n    group_by(year) |&gt; \n    summarise(mean_lifeExp = mean(lifeExp), \n              mean_gdpPercap = mean(gdpPercap))\n\nggplot(df_gap_sum) + \n    geom_path(aes(x = mean_gdpPercap, y = mean_lifeExp))\n\n\n\n\n\n\n\n\n\n\ngeom_path()によって、データの上から順に線を繋げます。\n\n\n\n\nPython (seaborn)\n\ndf_gap_sum = df_gap.groupby(\"year\")[[\"lifeExp\", \"gdpPercap\"]].mean()\n\nsns.lineplot(df_gap_sum, x=\"gdpPercap\", y=\"lifeExp\", sort=False)\n\n\n\n\n\n\n\n\n\n\nsort=Falseとすることで、データの上から順に線を繋げます。\n\nただし、このままでは時間の順序が分かりにくいので、年で色分けします。\n\n\n\nR (ggplot2)\n\nggplot(df_gap_sum) + \n    geom_line(aes(x = mean_gdpPercap, y = mean_lifeExp, color = year))\n\n\n\n\n\n\n\n\n\n\nseabornではやり方が分からなかったです。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>時系列のグラフ</span>"
    ]
  },
  {
    "objectID": "plot_professional.html",
    "href": "plot_professional.html",
    "title": "9  プロっぽいグラフ",
    "section": "",
    "text": "9.1 テーマ\nキレイな見た目のグラフを見るとテンションが上がる気がします。ggplot2ではいくつかのテーマがあります。次のようにしてテーマを変更することができます。\nR\n\ntheme_set(theme_light())\n\nggplot(df_year_cont_life) + \n    geom_line(aes(x = year, y = mean_lifeExp, color = continent))\nmatplotlibでもテーマを変更することができます。\nPython\n\nplt.style.use(\"ggplot\")\n\nsns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", errorbar=None)\nseabornでもテーマを設定できます。\nPython\n\nsns.set_theme()\n\nsns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", errorbar=None)",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>プロっぽいグラフ</span>"
    ]
  },
  {
    "objectID": "plot_professional.html#色",
    "href": "plot_professional.html#色",
    "title": "9  プロっぽいグラフ",
    "section": "9.2 色",
    "text": "9.2 色\nテーマと同様に色もいい感じにしたいと思います。ggplot2ではscale_color_...()（あるいはscale_fill_...()）を使って色を指定します。\n\nこちらのサイトが直観的で分かりやすいと思います。\n\n\n\n\nR\n\nggplot(df_year_cont_life) + \n    geom_line(aes(x = year, y = mean_lifeExp, color = continent)) + \n    scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\nseabornではcolor_palette()で色を指定します。\n\n\n\nPython\n\nsns.set_palette(\"Set2\")\nsns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", errorbar=None)",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>プロっぽいグラフ</span>"
    ]
  },
  {
    "objectID": "plot_professional.html#線や点のスタイル",
    "href": "plot_professional.html#線や点のスタイル",
    "title": "9  プロっぽいグラフ",
    "section": "9.3 線や点のスタイル",
    "text": "9.3 線や点のスタイル\n色が付いているグラフはキレイですが、色を正確に区別できない人には不親切でしょう。できる限り、color blind friendlyな、あるいはカラーユニバーサルデザインに準拠したカラーパレットを使用するか、色以外で区別するようにしましょう。\n例えば、折れ線グラフにおいて線の種類で区別する場合は、次のようにします。\n\n\n\nR\n\nggplot(df_year_cont_life) + \n    geom_line(aes(x = year, y = mean_lifeExp, color = continent, linetype = continent)) + \n    scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\nlinetypeを使います。\n\n\n\n\nPython\n\nsns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", style=\"continent\", errorbar=None)\n\n\n\n\n\n\n\n\n\n\nstyleを使います。\n\n点線は見にくいこともあるので、線を太くすると、より効果的かもしれません。\n\n\n\nR\n\nggplot(df_year_cont_life) + \n    geom_line(aes(x = year, y = mean_lifeExp, color = continent, linetype = continent), linewidth = 1) + \n    scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n散布図の場合も同様に点の外見を変えることが重要です。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>プロっぽいグラフ</span>"
    ]
  },
  {
    "objectID": "plot_professional.html#ラベル",
    "href": "plot_professional.html#ラベル",
    "title": "9  プロっぽいグラフ",
    "section": "9.4 ラベル",
    "text": "9.4 ラベル\n論文に載せるときは、x軸やy軸のラベル、凡例の内容などをキレイに整えたいと思います。まずは軸のラベルから取り掛かります。\n\n\n\nR\n\nggplot(df_year_cont_life) + \n    geom_line(aes(x = year, y = mean_lifeExp, color = continent, linetype = continent), linewidth = 1) + \n    scale_color_brewer(palette = \"Set2\") + \n    labs(x = \"年\", y = \"平均寿命の平均値\")\n\n\n\n\n\n\n\n\n\n\nlabs()の中でラベルを上書きします。\n\nmatplotlib/seabornの場合、まずfig, ax = plt.subplots()とおまじないを書きます。\n\nplt.subplots()は2つのオブジェクトを作成するので、fig, ax =とします。\n\n\n\n\nPython\n\nfig, ax = plt.subplots()\n\nsns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", errorbar=None)\nax.set_xlabel(\"年\")\nax.set_ylabel(\"平均寿命の平均値\")\n\n\n\n\n\n\n\n\n\n\nax.set_xlabel/ylabel(...)で軸ラベルを調整します。\n\nただし、そのままだと文字化けする場合があります。その場合はフォントを指定する必要があります。\n\n\n\nPython\n\nsns.set(font=\"Noto Sans CJK JP\")\n\nfig, ax = plt.subplots()\n\nsns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", errorbar=None)\nax.set_xlabel(\"年\")\nax.set_ylabel(\"平均寿命の平均値\")\n\n\n\n\n\n\n\n\n\n\nsns.set(font=\"Noto Sans CJK JP\")とフォントを指定します。\n\nMacユーザーであればHiraKakuProN-W3などでしょうか。\n\n\nなお、ggplot2でフォントを指定する場合は、次のようにします。\n\n\n\nR\n\ntheme_set(theme_light(base_family = \"Noto Sans CJK JP\"))\n\nggplot(df_year_cont_life) + \n    geom_line(aes(x = year, y = mean_lifeExp, color = continent, linetype = continent), linewidth = 1) + \n    scale_color_brewer(palette = \"Set2\") + \n    labs(x = \"年\", y = \"平均寿命の平均値\")\n\n\n\n\n\n\n\n\n\n\nggplot2もseabornも一度フォントを設定すると、全ての画像に反映されるので、スクリプトの冒頭で設定しておきましょう。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>プロっぽいグラフ</span>"
    ]
  },
  {
    "objectID": "plot_professional.html#凡例",
    "href": "plot_professional.html#凡例",
    "title": "9  プロっぽいグラフ",
    "section": "9.5 凡例",
    "text": "9.5 凡例\n\n9.5.1 内容\n次に凡例 (legend) も日本語にしようと思います。\n\n\n\nR\n\nname_continent &lt;- c(\"アフリカ\", \"アメリカ\", \"アジア\", \"ヨーロッパ\", \"オセアニア\")\n\nggplot(df_year_cont_life) + \n    geom_line(aes(x = year, y = mean_lifeExp, color = continent, linetype = continent), linewidth = 1) + \n    scale_color_brewer(palette = \"Set2\", labels = name_continent) + \n    scale_linetype(labels = name_continent) + \n    labs(x = \"年\", y = \"平均寿命の平均値\", color = \"大陸\", linetype = \"大陸\")\n\n\n\n\n\n\n\n\n\n\nまず、日本語の大陸名をc()でまとめたものをオブジェクトname_continentとして保存します。\nscale_color_brewer/scale_linetype()内のlabelsで日本語の大陸名で上書きします。\nlabs()内のcolor/linetypeで凡例のタイトルを変更します。\n\nseabornの場合は少々ややこしいです。おまじないだと思って鵜呑みにしてください。\n\n\n\nPython\n\nname_continent = [\"アフリカ\", \"アメリカ\", \"アジア\", \"ヨーロッパ\", \"オセアニア\"]\n\nfig, ax = plt.subplots()\n\nax = sns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", errorbar=None)\nax.set_xlabel(\"年\")\nax.set_ylabel(\"平均寿命の平均値\")\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles, name_continent, title=\"大陸\")\n\n\n\n\n\n\n\n\n\n\nまず、日本語の大陸名を[]でまとめたものをオブジェクトname_continentとして保存します。\nax.get_legend_handles_labels()で凡例の位置情報とラベルをhandles, labelsとして保存します。\n新しい凡例をax.legend()として作り直します。\n\n1つ目に位置情報handlesを入れます。\n2つ目に凡例のラベル（ここではname_continent）を入れます。\ntitleで凡例のタイトルを変更します。\n\n\n\n\n9.5.2 位置\nmatplotlib/seabornでは凡例がグラフ上に現れるので、（それが嫌な場合は）変更します。\n\nfig, ax = plt.subplots()\n\nax = sns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", errorbar=None)\nax.set_xlabel(\"年\")\nax.set_ylabel(\"平均寿命の平均値\")\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles, name_continent, title=\"大陸\", bbox_to_anchor=(1, 0.5), loc=\"center left\", frameon=False)\n\n\n\n\n\n\n\n\n\nax.legend()内のbbox_to_anchorで大まかな位置を設定します。\n\n左下が(0,0)、右上が(1,1)となります。\n\nlocで凡例のどの部分が、上記で指定した座標に対応するかを決めます。\n\n今回の例では、凡例の真ん中の左が(1,0.5)に一致するようになります。\n\nframeon=Falseで凡例の枠を消します。\n\n凡例が見切れていますが、保存する際には見きれないようにするので安心してください。\n個人的には凡例は下につけるのが好みです。\n\nfig, ax = plt.subplots()\n\nax = sns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", errorbar=None)\nax.set_xlabel(\"年\")\nax.set_ylabel(\"平均寿命の平均値\")\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles, name_continent, title=\"大陸\", bbox_to_anchor=(0.5, -0.15), loc=\"upper center\", ncols=3, frameon=False)\n\n\n\n\n\n\n\n\nggplot2の場合はtheme()の中で指定します。\n\n\n\nR\n\nggplot(df_year_cont_life) + \n    geom_line(aes(x = year, y = mean_lifeExp, color = continent, linetype = continent), linewidth = 1) + \n    scale_color_brewer(palette = \"Set2\", labels = name_continent) + \n    scale_linetype(labels = name_continent) + \n    labs(x = \"年\", y = \"平均寿命の平均値\", color = \"大陸\", linetype = \"大陸\") + \n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nここまでのように、色やスタイル、軸のラベルと凡例を整えれば、論文などで載せられる（最低限の）クオリティのグラフになると思っています。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>プロっぽいグラフ</span>"
    ]
  },
  {
    "objectID": "plot_professional.html#保存",
    "href": "plot_professional.html#保存",
    "title": "9  プロっぽいグラフ",
    "section": "9.6 保存",
    "text": "9.6 保存\n最後に、作成したグラフを保存したいと思います。まずは、画像の保存先として作業ディレクトリ内にfiguresフォルダを作成します。\n\nこれまでの復習も兼ねてグラフの作成に必要なコードを全て書いておきます。\n\nggplot2の場合、ggsave()という関数で、最後に作成したグラフを保存します。\n\n\n\nR\n\ntheme_set(theme_light(base_family = \"Noto Sans CJK JP\"))\n\nname_continent &lt;- c(\"アフリカ\", \"アメリカ\", \"アジア\", \"ヨーロッパ\", \"オセアニア\")\n\nggplot(df_year_cont_life) + \n    geom_line(aes(x = year, y = mean_lifeExp, color = continent, linetype = continent), linewidth = 1) + \n    scale_color_brewer(palette = \"Set2\", labels = name_continent) + \n    scale_linetype(labels = name_continent) + \n    labs(x = \"年\", y = \"平均寿命の平均値\", color = \"大陸\", linetype = \"大陸\") + \n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nggsave(\"figures/lifeExp_year_cont_R.png\", width = 6, height = 4)\n\n\nheight/widthでサイズを指定します。\n\nmatplotlib/seabornでは、fig.savefig()で画像を保存します。\n\n\n\nPython\n\nsns.set_theme(font=\"Noto Sans CJK JP\")\nsns.set_palette(\"Set2\")\n\nname_continent = [\"アフリカ\", \"アメリカ\", \"アジア\", \"ヨーロッパ\", \"オセアニア\"]\n\nfig, ax = plt.subplots(figsize=(6,4))\n\nax = sns.lineplot(df_year_cont_life, x=\"year\", y=\"lifeExp\", hue=\"continent\", errorbar=None)\nax.set_xlabel(\"年\")\nax.set_ylabel(\"平均寿命の平均値\")\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles, name_continent, title=\"大陸\", bbox_to_anchor=(0.5, -0.15), loc=\"upper center\", ncols=3, frameon=False)\nplt.savefig(\"figures/lifeExp_year_cont_py.png\", bbox_inches=\"tight\")\n\n\n\n\n\n\n\n\n\n\np.fig.set_size_inches((w, h))でサイズを調整します。\n\nwが幅、hが高さです。\n\nbbox_inches=\"tight\"で凡例などが見きれないように保存します。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>プロっぽいグラフ</span>"
    ]
  },
  {
    "objectID": "plot_advanced.html",
    "href": "plot_advanced.html",
    "title": "10  発展的なグラフ",
    "section": "",
    "text": "10.1 グループごとの複数のグラフ\nグループごとに色分けをすることで、グループごとの分布や散布図を可視化する方法は確認してきました。しかし、それぞれ別のグラフとして作図するほうが見やすい場合もあるかもしれません。\nR\n\nggplot(df_gap) + \n    geom_histogram(aes(x = lifeExp)) + \n    facet_wrap(~ continent) + \n    labs(x = \"平均寿命\", y = \"頻度\")\nPython\n\ngrid = sns.FacetGrid(df_gap, col=\"continent\", col_wrap=3)\np = grid.map(sns.histplot, \"lifeExp\")\np.set(xlabel=\"平均寿命\", ylabel=\"頻度\");\nなお、seabornでは次のような関数を使うことで、簡便にグリッドを作成し、グラフを作図できます。\nPython\n\np = sns.displot(df_gap, x=\"lifeExp\", col=\"continent\", col_wrap=3)\np.set(xlabel=\"平均寿命\", ylabel=\"頻度\");",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>発展的なグラフ</span>"
    ]
  },
  {
    "objectID": "plot_advanced.html#グループごとの複数のグラフ",
    "href": "plot_advanced.html#グループごとの複数のグラフ",
    "title": "10  発展的なグラフ",
    "section": "",
    "text": "facet_wrap(~ ...)でグループの変数を指定して、グループごとにグラフを作ります。\nラベル名の変更は面倒なので、後ほど触れます。\n\n\n\nsns.FacetGrid()でグリッドgridを作成します。\n\n使用するデータフレームとグループの変数を指定します。\nまた、col_warp=で何枚のグラフごとに改行するかを決めます。\n\nmap()メソッドでグラフpを作成します。\n\n最初に、グラフを作る関数を指定します（()を付けないことに注意）。\n次に、作図に使う変数名を指定します。\n\nset()メソッドで軸ラベルを指定します。\n\n\n\n\n\n\n\n\nseabornの2通りの書き方\n\n\n\nseabornでは異なるグラフを同じ関数で作図していたところがあります。この図のように、いくつかの関数をまとめた関数があり、それを使っていました。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>発展的なグラフ</span>"
    ]
  },
  {
    "objectID": "plot_advanced.html#異なる種類のグラフ",
    "href": "plot_advanced.html#異なる種類のグラフ",
    "title": "10  発展的なグラフ",
    "section": "10.2 異なる種類のグラフ",
    "text": "10.2 異なる種類のグラフ\nそもそも異なる種類のグラフを一つにまとめたいこともあります。例えば、平均寿命、人口、一人あたりGDPの分布のグラフを一つにまとめます。\nggplot2の場合、gridExtraを使う方法とpatchworkを使う方法を紹介しますが、いずれの場合も複数のグラフを作成して、最後に一つにまとめます。\n\n\n\nR\n\np1 &lt;- ggplot(df_gap) + \n    geom_histogram(aes(x = lifeExp)) + \n    labs(x = \"平均寿命\", y = \"頻度\")\n\np2 &lt;- ggplot(df_gap) + \n    geom_histogram(aes(x = pop)) + \n    labs(x = \"人口\", y = \"頻度\")\n\np3 &lt;- ggplot(df_gap) + \n    geom_histogram(aes(x = gdpPercap)) + \n    labs(x = \"一人あたりGDP\", y = \"頻度\")\n\nlibrary(gridExtra)\n\ngrid.arrange(p1, p2, p3, ncol = 2) \n\n\n\n\n\n\n\n\n\n\n\n\nR\n\nlibrary(patchwork)\n\np1 + p2 + p3 + plot_layout(ncol = 2)\n\n\n\n\n\n\n\n\n\npatchworkの方が、より簡単に柔軟なレイアウトができるように思います。\n\n\n\nR\n\nlibrary(patchwork)\n\np1 / (p2 + p3)\n\n\n\n\n\n\n\n\n\nseabornの場合はmaplotlibのsubplots()を使います。\n\n\n\nPython\n\nfig, axs = plt.subplots(2, 2)\nplt.subplots_adjust(wspace=0.3, hspace=0.4)\n\nsns.histplot(df_gap, x =\"lifeExp\", ax=axs[0,0])\naxs[0,0].set_xlabel(\"平均寿命\")\naxs[0,0].set_ylabel(\"頻度\")\n\nsns.histplot(df_gap, x =\"pop\", ax=axs[0,1])\naxs[0,1].set_xlabel(\"人口\")\naxs[0,1].set_ylabel(\"頻度\")\n\nsns.histplot(df_gap, x =\"gdpPercap\", ax=axs[1,0])\naxs[1,0].set_xlabel(\"一人あたりGDP\")\naxs[1,0].set_ylabel(\"頻度\")\n\naxs[1,1].remove()\n\n\n\n\n\n\n\n\n\n\nplt.subplots(n, m)でグリッドを作ります。\n\nnが行の数、mが列の数になります。つまり、m個ごとに改行し、n段のグリッドを作ります。\n\naxs[i,j]はi+1行j+1列のグリッドになり、これを作図する関数の中でax=と指定することで、そのグリッドにグラフを作成します。\n\nプログラミングでは0から始まるのでaxs[0,0]は1行1列目（左上）のグリッドを意味しています。\n\n右下のグリッド（2行2列目）はいらないのでremove()メソッドで削除します。\n\n\n\n\nサブプロットのイメージ",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>発展的なグラフ</span>"
    ]
  },
  {
    "objectID": "plot_advanced.html#対数目盛り",
    "href": "plot_advanced.html#対数目盛り",
    "title": "10  発展的なグラフ",
    "section": "10.3 対数目盛り",
    "text": "10.3 対数目盛り\nところで、以前、一人あたりGDPの分布が歪んでいるという話をしました。つまり、多くの観察では小さい値を取り、ごく一部の観察は異様に大きな値を取るような変数でした。\nこの場合、対数化することで見やすいグラフになることがあります。\n\n\n\nR\n\nggplot(df_gap) + \n    geom_histogram(aes(x = gdpPercap)) + \n    scale_x_log10()\n\n\n\n\n\n\n\n\n\n\n\n\nPython\n\nsns.histplot(df_gap, x=\"gdpPercap\", log_scale=True)\n\n\n\n\n\n\n\n\n\nまた、散布図で対数化することで直線的関係が見えることもあります（すなわち、実際の数において対数の関係にあったということ）。\n\n\n\nR\n\nggplot(df_gap) + \n    geom_point(aes(x = gdpPercap, y = lifeExp)) + \n    scale_x_log10()\n\n\n\n\n\n\n\n\n\n\n\n\nPython\n\nfig, ax = plt.subplots()\n\nsns.scatterplot(df_gap, x=\"gdpPercap\", y=\"lifeExp\")\nax.set_xscale(\"log\")",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>発展的なグラフ</span>"
    ]
  },
  {
    "objectID": "plot_advanced.html#強調",
    "href": "plot_advanced.html#強調",
    "title": "10  発展的なグラフ",
    "section": "10.4 強調",
    "text": "10.4 強調",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>発展的なグラフ</span>"
    ]
  },
  {
    "objectID": "data_download.html",
    "href": "data_download.html",
    "title": "11  データのダウンロード",
    "section": "",
    "text": "11.1 Google Trend\nGoogle Trendsというサービスがあります。グーグルの検索トレンドを表示してくれます（検索”数”ではない点に注意）。\nRやPythonではGoogle TrendsのデータをダウンロードするパッケージgtrendsRとpytrendsがあります。\nR\n\nlibrary(gtrendsR)\nPython\n\nfrom pytrends.request import TrendReq\n例えば、“ウクライナ”と”ガザ”のトレンドを取得します。\nR\n\nout_gtrends &lt;- gtrends(c(\"ウクライナ\", \"ガザ\"), hl = \"ja-JP\", time = \"today 12-m\", tz = 540)\nPython\n\npytrends = TrendReq(hl='ja-JP', tz=540)\npytrends.build_payload(kw_list=[\"ウクライナ\", \"ガザ\"], timeframe='today 12-m')\nそれぞれのオブジェクトの中のinterest_over_timeにデータが含まれています。\nR\n\nhead(out_gtrends$interest_over_time)\n\n\n        date hits    keyword   geo       time gprop category\n1 2023-05-07   73 ウクライナ world today 12-m   web        0\n2 2023-05-14   96 ウクライナ world today 12-m   web        0\n3 2023-05-21   97 ウクライナ world today 12-m   web        0\n4 2023-05-28   75 ウクライナ world today 12-m   web        0\n5 2023-06-04   98 ウクライナ world today 12-m   web        0\n6 2023-06-11   98 ウクライナ world today 12-m   web        0\nPython\n\npytrends.interest_over_time\n\n\n&lt;bound method TrendReq.interest_over_time of &lt;pytrends.request.TrendReq object at 0x7fcd445f2250&gt;&gt;\n他にも地域別の傾向なども分かるので、調べてみてください。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>データのダウンロード</span>"
    ]
  },
  {
    "objectID": "data_download.html#google-trend",
    "href": "data_download.html#google-trend",
    "title": "11  データのダウンロード",
    "section": "",
    "text": "hlで言語、tzでタイムゾーン、time[frame]で期間を指定します。\n\n\n\n\nRではオブジェクトの中に別のオブジェクトが入れ子になっている場合、$で取り出せます。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>データのダウンロード</span>"
    ]
  },
  {
    "objectID": "data_download.html#google-ngram",
    "href": "data_download.html#google-ngram",
    "title": "11  データのダウンロード",
    "section": "11.2 Google Ngram",
    "text": "11.2 Google Ngram\nGoogle Ngram Viewerというサービスがあります。グーグルが電子化した書籍に単語が各年にどれくらいの割合で出現するかが分かります。\n\nちなみに、国会図書館もNDL Ngram Viewerという日本語向けの同様のサービスを提供しています。\n\nRではGoogle Trendsのデータをダウンロードするパッケージngramrがあります。\n\n\n\nR\n\nlibrary(ngramr)\n\n\n試しに”Japan”と”China”の出現割合をダウンロードしてみます。\n\n\n\nR\n\nout_ngram &lt;- ngram(c(\"Japan\", \"China\"), year_start = 1950)\n\nhead(out_ngram)\n\n\n# Ngram data table\n# Phrases:      China, Japan\n# Case-sensitive:   TRUE\n# Corpuses:     en-2019\n# Smoothing:        3\n# Years:        1950-1955\n\n  Year Phrase    Frequency  Corpus\n1 1950  Japan 6.193348e-05 en-2019\n2 1951  Japan 6.231487e-05 en-2019\n3 1952  Japan 6.328589e-05 en-2019\n4 1953  Japan 6.391569e-05 en-2019\n5 1954  Japan 6.455746e-05 en-2019\n6 1955  Japan 6.454950e-05 en-2019",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>データのダウンロード</span>"
    ]
  },
  {
    "objectID": "data_download.html#wikipedia",
    "href": "data_download.html#wikipedia",
    "title": "11  データのダウンロード",
    "section": "11.3 Wikipedia",
    "text": "11.3 Wikipedia\n作成中です。もしかすると旧バージョンになにかあるかもしれません。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>データのダウンロード</span>"
    ]
  },
  {
    "objectID": "data_import.html",
    "href": "data_import.html",
    "title": "12  データの読み込み",
    "section": "",
    "text": "12.1 使用するパッケージ\nRでデータを読み込む場合、標準関数を用いるか、tidyverseに含まれるパッケージreadrを使うことが多いです。\nR\n\nlibrary(tidyverse)\nPythonの場合、pandasがデファクト・スタンダードですが、最近はpolarsも人気ではないかと思います。\nPython\n\nimport pandas as pd\nimport polars as pl",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの読み込み</span>"
    ]
  },
  {
    "objectID": "data_import.html#データの形式と読み込み",
    "href": "data_import.html#データの形式と読み込み",
    "title": "12  データの読み込み",
    "section": "12.2 データの形式と読み込み",
    "text": "12.2 データの形式と読み込み\nしかし、本命はネット上で公開されているデータなどを読み込むことではないかと思います。データには形式があり、それに応じてデータを読み込む必要があります。データの形式はファイルの拡張子を見れば分かります。\n\n例えば、sample.csvというファイルであれば、sampleがファイル名で、.以降のcsvが拡張子です。このファイルはcsvファイルであることが分かります。\nもしPCで拡張子が表示されていない設定であれば、表示するように設定することを勧めます。\n\n以下では、dataフォルダに入っているxxxというファイルを読み込み、df_sampleというオブジェクトにするコードを紹介します。\n\n12.2.1 csvファイル\nここでは、代表的なデータの形式と読み込み方法を紹介します。表形式のデータと言われると、エクセルファイルを思い浮かべると思いますが、研究の世界ではcsvファイルやtsvファイルが多いように思います。\ncsvとは”comma-separated values”の略で、その名の通り「コンマ,」で区切られたファイルです。\n\n\n\nR (base)\n\ndf_sample &lt;- read.csv(\"data/xxx.csv\")\n\n\n\n\n\nR (tidyverse)\n\ndf_sample &lt;- read_csv(\"data/xxx.csv\")\n\n\n\n\n\nPython (pandas)\n\ndf_sample = pd.read_csv(\"data/xxx.csv\")\n\n\n\n\n\nPython (polars)\n\ndf_sample = pl.read_csv(\"data/xxx.csv\")\n\n\n\n12.2.1.1 Qualtrics\n政治学ではサーベイ（実験）を行う際にはQualtricsというサービスを使うことが多いです。RではqualtRicsというパッケージを使うことで、サーベイ結果のcsvファイルを読み込めます。\n\n\n\nR (qualtRics)\n\nlibrary(qualtRics)\n\ndf_sample &lt;- read_survey(\"data/xxx.csv\")\n\n\n\n\n\n12.2.2 tsvファイル\n一方で、tsvは「タブ」で区切られています。\n\n\n\nR (base)\n\ndf_sample &lt;- read.csv(\"data/xxx.csv\", sep=\"\\t\")\n\n\n\n\n\nR (tidyverse)\n\ndf_sample &lt;- read_tsv(\"data/xxx.tsv\")\n\n\n\n\n\nPython (pandas)\n\ndf_sample = pd.read_csv(\"data/xxx.csv\", sep=\"\\t\")\n\n\n\n\n\nPython (polars)\n\ndf_sample = pl.read_csv(\"data/xxx.csv\", separator=\"\\t\")\n\n\ntidyverseには専用の関数がありますが、それ以外ではタブ区切りであることを指定する必要があります。\n\n\\tはタブの正規表現 (regular expression) です。\n\n\n\n12.2.3 xls[x]ファイル：Excel\nExcelファイルを読み込む場合、Rではreadrというパッケージを使います。\n\nExcelファイルの拡張子はxlsまたはxlsxです。\n\n\n\n\nR (readxl)\n\nlibrary(readxl)\n\ndf_sample &lt;- read_excel(\"data/xxx.xlsx\")\n\n\n\n\n\nPython (pandas)\n\ndf_sample = pd.read_excel(\"data/xxx.xlsx\")\n\n\n\nopenpyxlとxlrdをインストールしておく必要があります。\n\n\n\n\nPython (polars)\n\ndf_sample = pl.read_excel(\"data/xxx.xlsx\")\n\n\n\nfastexcelとxlsx2csvをインストールしておく必要があります。\n\n\n\n12.2.4 dtaファイル：Stata\n政治学や経済学などではStataという統計分析ソフトを使うこともあります。Stata専用のデータ形式はdtaファイルと呼びます。\n\n\n\nR (tidyverse)\n\nlibrary(haven)\n\ndf_sample &lt;- read_dta(\"data/xxx.dta\")\n\n\n\n\n\nPython (pandas)\n\ndf_sample = pd.read_stata(\"data/xxx.dta\")\n\n\n政治学だとめったに遭遇しませんが、おそらく心理学や医学ではSASという統計ソフトを使うことがあり、専用のファイルを読み込む関数もあります。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの読み込み</span>"
    ]
  },
  {
    "objectID": "data_import.html#データの読み込み実践",
    "href": "data_import.html#データの読み込み実践",
    "title": "12  データの読み込み",
    "section": "12.3 データの読み込み実践",
    "text": "12.3 データの読み込み実践\nまずは、キレイなデータを読み込みたいと思います。政治学において民主主義は避けて通ることのできない概念であり、様々なデータセットがあります。その代表的なものとしてPolityというものがあります。\n\n“Polity5 Annual Time-Series, 1946-2018”のエクセルデータを作業ディレクトリ内のdataフォルダに保存します。\n\nそれでは、エクセルデータを読み込みます。\n\n\n\nR (readxl)\n\nlibrary(readxl)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\")\n\nhead(df_polity)\n\n\n# A tibble: 6 × 37\n     p5   cyear ccode scode country      year  flag fragment democ autoc polity\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0 7001800   700 AFG   Afghanistan  1800     0       NA     1     7     -6\n2     0 7001801   700 AFG   Afghanistan  1801     0       NA     1     7     -6\n3     0 7001802   700 AFG   Afghanistan  1802     0       NA     1     7     -6\n4     0 7001803   700 AFG   Afghanistan  1803     0       NA     1     7     -6\n5     0 7001804   700 AFG   Afghanistan  1804     0       NA     1     7     -6\n6     0 7001805   700 AFG   Afghanistan  1805     0       NA     1     7     -6\n# ℹ 26 more variables: polity2 &lt;dbl&gt;, durable &lt;dbl&gt;, xrreg &lt;dbl&gt;, xrcomp &lt;dbl&gt;,\n#   xropen &lt;dbl&gt;, xconst &lt;dbl&gt;, parreg &lt;dbl&gt;, parcomp &lt;dbl&gt;, exrec &lt;dbl&gt;,\n#   exconst &lt;dbl&gt;, polcomp &lt;dbl&gt;, prior &lt;dbl&gt;, emonth &lt;dbl&gt;, eday &lt;dbl&gt;,\n#   eyear &lt;dbl&gt;, eprec &lt;dbl&gt;, interim &lt;dbl&gt;, bmonth &lt;dbl&gt;, bday &lt;dbl&gt;,\n#   byear &lt;dbl&gt;, bprec &lt;dbl&gt;, post &lt;dbl&gt;, change &lt;dbl&gt;, d5 &lt;dbl&gt;, sf &lt;dbl&gt;,\n#   regtrans &lt;dbl&gt;\n\n\n\n\n\nPython (pandas)\n\ndf_polity = pd.read_excel(\"data/p5v2018.xls\")\n\ndf_polity.head()\n\n\n   p5    cyear  ccode scode      country  ...  post  change   d5  sf  regtrans\n0   0  7001800    700   AFG  Afghanistan  ...  -6.0    88.0  1.0 NaN       NaN\n1   0  7001801    700   AFG  Afghanistan  ...   NaN     NaN  NaN NaN       NaN\n2   0  7001802    700   AFG  Afghanistan  ...   NaN     NaN  NaN NaN       NaN\n3   0  7001803    700   AFG  Afghanistan  ...   NaN     NaN  NaN NaN       NaN\n4   0  7001804    700   AFG  Afghanistan  ...   NaN     NaN  NaN NaN       NaN\n\n[5 rows x 37 columns]\n\n\n\n\n\nPython (polars)\n\ndf_polity = pl.read_excel(\"data/p5v2018.xls\")\n\ndf_polity.head()\n\n\n\n\nshape: (5, 37)\n\n\n\np5\ncyear\nccode\nscode\ncountry\nyear\nflag\nfragment\ndemoc\nautoc\npolity\npolity2\ndurable\nxrreg\nxrcomp\nxropen\nxconst\nparreg\nparcomp\nexrec\nexconst\npolcomp\nprior\nemonth\neday\neyear\neprec\ninterim\nbmonth\nbday\nbyear\nbprec\npost\nchange\nd5\nsf\nregtrans\n\n\ni64\ni64\ni64\nstr\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n0\n7001800\n700\n\"AFG\"\n\"Afghanistan\"\n1800\n0\nnull\n1\n7\n-6\n-6\nnull\n3\n1\n1\n1\n3\n3\n1\n1\n6\nnull\nnull\nnull\nnull\nnull\nnull\n1\n1\n1800\n1\n-6\n88\n1\nnull\nnull\n\n\n0\n7001801\n700\n\"AFG\"\n\"Afghanistan\"\n1801\n0\nnull\n1\n7\n-6\n-6\nnull\n3\n1\n1\n1\n3\n3\n1\n1\n6\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7001802\n700\n\"AFG\"\n\"Afghanistan\"\n1802\n0\nnull\n1\n7\n-6\n-6\nnull\n3\n1\n1\n1\n3\n3\n1\n1\n6\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7001803\n700\n\"AFG\"\n\"Afghanistan\"\n1803\n0\nnull\n1\n7\n-6\n-6\nnull\n3\n1\n1\n1\n3\n3\n1\n1\n6\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7001804\n700\n\"AFG\"\n\"Afghanistan\"\n1804\n0\nnull\n1\n7\n-6\n-6\nnull\n3\n1\n1\n1\n3\n3\n1\n1\n6\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\n\n\n\n\n\nGoogle Colaboratoryを使っている場合はパスの先頭にdrive/MyDrive/を付けます。つまり、\"drive/MyDrive/data/p5v2018.xls\"とします。\n\nところで、それぞれNAやNaN、nullとありますが、これらは欠損値 (missing value) を意味しています。欠損値とは何かしらの理由で変数の値が測定されていないことを意味します。\n\n例えば、その年にその国が独立していない場合などは民主主義を測定できません。\n\n\n12.3.1 行のスキップ\n政治学で使用するデータの多くは上記のようなコードで読み込みが可能だと思います。しかし、実際には様々な理由から、単にデータを読み込むだけでは分析できないことがあります。以下では、実際のデータを用いつつ、どのような問題に遭遇しうるのか、その際にどのように対処すれば良いかを学びます。\nまずは、World Bank Open Dataのデータを読み込んでみましょう。\n\n例えば、女性人口 (Population, female) で検索をし、右側にあるDownloadのCSVをクリックします。\nxipファイルがダウンロードされるので、それを適当なフォルダ（例えばダウンロードフォルダ）に保存し、解凍します。\nその中に、長いファイル名のファイルが3つありますが、APIから始まるファイルが目当てのファイルです。\nこのファイルを作業ディレクトリ内のdataフォルダにコピーをします。\nファイル名が分かりにくいので、分かりやすい名前（例えば、wb_pop_fem.csv）に変えておきます。\n\nそれでは、データを読み込んでみます。\n\n\n\nR (tidyverse)\n\ndf_pop_fem &lt;- read_csv(\"data/wb_pop_fem.csv\")\n\nhead(df_pop_fem)\n\n\n# A tibble: 6 × 3\n  `Data Source`               `World Development Indicators` ...3               \n  &lt;chr&gt;                       &lt;chr&gt;                          &lt;chr&gt;              \n1 Last Updated Date           2024-03-28                      &lt;NA&gt;              \n2 Country Name                Country Code                   \"Indicator Name,In…\n3 Aruba                       ABW                            \"Population, femal…\n4 Africa Eastern and Southern AFE                            \"Population, femal…\n5 Afghanistan                 AFG                            \"Population, femal…\n6 Africa Western and Central  AFW                            \"Population, femal…\n\n\n\n\n\nPython (pandas)\n\ndf_pop_fem = pd.read_csv(\"data/wb_pop_fem.csv\")\n\n\npandas.errors.ParserError: Error tokenizing data. C error: Expected 3 fields in line 5, saw 69\n\n\n\n\n\nPython (polars)\n\ndf_pop_fem = pl.read_csv(\"data/wb_pop_fem.csv\")\n\n\npolars.exceptions.ComputeError: found more fields than defined in 'Schema'\n\nConsider setting 'truncate_ragged_lines=True'.\n\n\nさて、Pythonではエラーが生じました。また、Rでも肝心の女性の人口データが含まれていません。\nなぜこのようなことになってしまったのか、元のcsvファイルをエクセルなどの表計算ソフトで見てみます。すると、最初の4行ほどはデータソースや更新日などが書かれており、目当てのデータは5行目以降にあることが分かります。\nR/Pythonは素直なので、上から順にデータを読み込みます。Rはおそらくこのデータは2,3列しかないだろうと思って読み込んだのでしょう。Pythonは2列しかないと思っていたら5行目でそれ以上のデータと遭遇してエラーを出してしまったのでしょう。\nしたがって、このような場合は「5行目から読んでね（4行目までは無視してね）」とR/Pythonにお願いする必要があります。\n\n\n\nR (tidyverse)\n\ndf_pop_fem &lt;- read_csv(\"data/wb_pop_fem.csv\", skip = 4)\n\nhead(df_pop_fem)\n\n\n# A tibble: 6 × 69\n  `Country Name`  `Country Code` `Indicator Name` `Indicator Code` `1960` `1961`\n  &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;            &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;\n1 Aruba           ABW            Population, fem… SP.POP.TOTL.FE.… 2.78e4 2.84e4\n2 Africa Eastern… AFE            Population, fem… SP.POP.TOTL.FE.… 6.59e7 6.76e7\n3 Afghanistan     AFG            Population, fem… SP.POP.TOTL.FE.… 4.15e6 4.23e6\n4 Africa Western… AFW            Population, fem… SP.POP.TOTL.FE.… 4.88e7 4.99e7\n5 Angola          AGO            Population, fem… SP.POP.TOTL.FE.… 2.67e6 2.70e6\n6 Albania         ALB            Population, fem… SP.POP.TOTL.FE.… 7.85e5 8.09e5\n# ℹ 63 more variables: `1962` &lt;dbl&gt;, `1963` &lt;dbl&gt;, `1964` &lt;dbl&gt;, `1965` &lt;dbl&gt;,\n#   `1966` &lt;dbl&gt;, `1967` &lt;dbl&gt;, `1968` &lt;dbl&gt;, `1969` &lt;dbl&gt;, `1970` &lt;dbl&gt;,\n#   `1971` &lt;dbl&gt;, `1972` &lt;dbl&gt;, `1973` &lt;dbl&gt;, `1974` &lt;dbl&gt;, `1975` &lt;dbl&gt;,\n#   `1976` &lt;dbl&gt;, `1977` &lt;dbl&gt;, `1978` &lt;dbl&gt;, `1979` &lt;dbl&gt;, `1980` &lt;dbl&gt;,\n#   `1981` &lt;dbl&gt;, `1982` &lt;dbl&gt;, `1983` &lt;dbl&gt;, `1984` &lt;dbl&gt;, `1985` &lt;dbl&gt;,\n#   `1986` &lt;dbl&gt;, `1987` &lt;dbl&gt;, `1988` &lt;dbl&gt;, `1989` &lt;dbl&gt;, `1990` &lt;dbl&gt;,\n#   `1991` &lt;dbl&gt;, `1992` &lt;dbl&gt;, `1993` &lt;dbl&gt;, `1994` &lt;dbl&gt;, `1995` &lt;dbl&gt;, …\n\n\n\n\n\nPython (pandas)\n\ndf_pop_fem = pd.read_csv(\"data/wb_pop_fem.csv\", skiprows=4)\n\ndf_pop_fem.head()\n\n\n                  Country Name Country Code  ... 2023 Unnamed: 68\n0                        Aruba          ABW  ...  NaN         NaN\n1  Africa Eastern and Southern          AFE  ...  NaN         NaN\n2                  Afghanistan          AFG  ...  NaN         NaN\n3   Africa Western and Central          AFW  ...  NaN         NaN\n4                       Angola          AGO  ...  NaN         NaN\n\n[5 rows x 69 columns]\n\n\n\n\n\nPython (polars)\n\ndf_pop_fem = pl.read_csv(\"data/wb_pop_fem.csv\", skip_rows=4)\n\ndf_pop_fem.head()\n\n\n\n\nshape: (5, 69)\n\n\n\nCountry Name\nCountry Code\nIndicator Name\nIndicator Code\n1960\n1961\n1962\n1963\n1964\n1965\n1966\n1967\n1968\n1969\n1970\n1971\n1972\n1973\n1974\n1975\n1976\n1977\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n\n\n\nstr\nstr\nstr\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\nstr\nstr\n\n\n\n\n\"Aruba\"\n\"ABW\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n27773\n28380\n28820\n29218\n29570\n29875\n30135\n30253\n30232\n30166\n30063\n29927\n29953\n30229\n30595\n30972\n31245\n31416\n31584\n31749\n31909\n32121\n32389\n32659\n32886\n33008\n33007\n32904\n32788\n32892\n33480\n34657\n35941\n37137\n38437\n39724\n41014\n42336\n43688\n45050\n46269\n47178\n47831\n48374\n48877\n49414\n50016\n50636\n51272\n51919\n52484\n52980\n53480\n53953\n54403\n54828\n55224\n55591\n55935\n56254\n56373\n56330\n56272\n\"\"\nnull\n\n\n\"Africa Eastern…\n\"AFE\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n65853220\n67606287\n69457112\n71375643\n73386167\n75478396\n77610073\n79810945\n82111287\n84493601\n86968714\n89504801\n92051419\n94694181\n97478670\n100339888\n103289004\n106237590\n109415983\n112834021\n116060576\n119525759\n123410049\n127333314\n131344567\n135563206\n139816011\n144066893\n148288335\n152522362\n156942214\n161298074\n165609524\n170167926\n174762745\n179486372\n184468529\n189280003\n194009070\n198959676\n204048614\n209257664\n214635664\n220167814\n225898442\n231830259\n237997868\n244435307\n251105628\n257956460\n265000967\n272174714\n279546577\n287224924\n295089133\n303195897\n311387401\n319637365\n328159112\n336930970\n345889868\n354855221\n363834524\n\"\"\nnull\n\n\n\"Afghanistan\"\n\"AFG\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n4145945\n4233771\n4326881\n4424511\n4526691\n4634341\n4745981\n4861918\n4983086\n5108507\n5239568\n5372747\n5509781\n5655304\n5803603\n5948268\n6083166\n6214979\n6342838\n6373547\n6136856\n5490160\n4973968\n4916351\n5074600\n5225679\n5207273\n5152650\n5188060\n5334609\n5346409\n5372208\n6028939\n7000119\n7722096\n8199445\n8537421\n8871958\n9217591\n9595036\n9727541\n9793166\n10438055\n11247647\n11690825\n12109086\n12614497\n12835340\n13088192\n13557331\n13949295\n14468875\n15067373\n15594637\n16172321\n16682054\n17115346\n17614722\n18136922\n18679089\n19279930\n19844584\n20362329\n\"\"\nnull\n\n\n\"Africa Western…\n\"AFW\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n48802898\n49850088\n50928609\n52044907\n53196730\n54389295\n55621877\n56890201\n58204276\n59560501\n60963620\n62404746\n63900687\n65482730\n67160750\n68943269\n70786681\n72718234\n74770813\n76909670\n79104037\n81359426\n83714354\n85996392\n88238093\n90605997\n93047700\n95556172\n98139171\n100824162\n103478502\n106184462\n109071980\n111968903\n114896750\n117979287\n121143186\n124399328\n127775360\n131211380\n134795501\n138546839\n142408066\n146370538\n150463219\n154696476\n159035017\n163481052\n168058833\n172782717\n177645233\n182657978\n187755307\n192900081\n198163527\n203513873\n208980433\n214578994\n220253839\n226004857\n231877590\n237813580\n243821774\n\"\"\nnull\n\n\n\"Angola\"\n\"AGO\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n2670229\n2704394\n2742689\n2779473\n2812590\n2838939\n2856740\n2867926\n2879001\n2902120\n2953347\n3032948\n3132441\n3244749\n3362438\n3483416\n3606782\n3735823\n3872130\n4014347\n4164145\n4321167\n4485276\n4656894\n4834820\n5018620\n5206761\n5396035\n5588733\n5787505\n5991207\n6199060\n6408303\n6621767\n6845622\n7077381\n7315200\n7561436\n7813123\n8071413\n8339311\n8619083\n8912191\n9219638\n9545020\n9886765\n10244381\n10620174\n11013001\n11422969\n11853530\n12303450\n12770743\n13252938\n13746371\n14248799\n14764575\n15293335\n15828040\n16370553\n16910989\n17452283\n17998220\n\"\"\nnull\n\n\n\n\n\n\n\n無事にデータを読み込むことができました。ここから得られる教訓は、データを読み込む前に表計算ソフトでどのようなデータなのか確認すべしということでしょう。\n\n\n12.3.2 シートの選択\n続いて、ストックホルム国際平和研究所のSIPRI Military Expenditure Databaseを扱います。\n\nリンクをクリックしてデータを作業ディレクトリ内のdataフォルダに保存します。\n\n先程の教訓を活かして、まずは表計算ソフトでこのファイルを開きます。すると、英語で説明が書かれたページが表示されます。\nエクセルファイルは一つのファイルに複数のシート（データフレーム）が含まれていることがあります。したがって、その場合はどのシートを読み込むかを指定する必要があります。試しに、実質USドルで計算された5つ目のシートを読み込みます。\nまた、5つ目のシートを見てみると最初の5行は説明書きのようなので、スキップします。\n\n\n\nR (readxl)\n\nlibrary(readxl)\n\ndf_sipri &lt;- read_excel(\"data/SIPRI-Milex-data-1949-2022.xlsx\", sheet = 5, skip = 5)\n\nhead(df_sipri)\n\n\n# A tibble: 6 × 77\n  Country      ...2  Notes `1949.0` `1950.0` `1951.0` `1952.0` `1953.0` `1954.0`\n  &lt;chr&gt;        &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 &lt;NA&gt;         NA    &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n2 Africa       NA    &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n3 North Africa NA    &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;    \n4 Algeria      NA    §4    xxx      xxx      xxx      xxx      xxx      xxx     \n5 Libya        NA    ‡§¶16 xxx      xxx      ...      ...      ...      ...     \n6 Morocco      NA    §17   xxx      xxx      xxx      xxx      xxx      xxx     \n# ℹ 68 more variables: `1955.0` &lt;chr&gt;, `1956.0` &lt;chr&gt;, `1957.0` &lt;chr&gt;,\n#   `1958.0` &lt;chr&gt;, `1959.0` &lt;chr&gt;, `1960.0` &lt;chr&gt;, `1961.0` &lt;chr&gt;,\n#   `1962.0` &lt;chr&gt;, `1963.0` &lt;chr&gt;, `1964.0` &lt;chr&gt;, `1965.0` &lt;chr&gt;,\n#   `1966.0` &lt;chr&gt;, `1967.0` &lt;chr&gt;, `1968.0` &lt;chr&gt;, `1969.0` &lt;chr&gt;,\n#   `1970.0` &lt;chr&gt;, `1971.0` &lt;chr&gt;, `1972.0` &lt;chr&gt;, `1973.0` &lt;chr&gt;,\n#   `1974.0` &lt;chr&gt;, `1975.0` &lt;chr&gt;, `1976.0` &lt;chr&gt;, `1977.0` &lt;chr&gt;,\n#   `1978.0` &lt;chr&gt;, `1979.0` &lt;chr&gt;, `1980.0` &lt;chr&gt;, `1981.0` &lt;chr&gt;, …\n\n\n\n\n\nPython (pandas)\n\ndf_sipri = pd.read_excel(\"data/SIPRI-Milex-data-1949-2022.xlsx\", sheet_name=5, skiprows=5)\n\ndf_sipri.head()\n\n\n        Country  Notes 1949  ...        2020         2021         2022\n0           NaN    NaN  NaN  ...         NaN          NaN          NaN\n1        Africa    NaN  NaN  ...         NaN          NaN          NaN\n2  North Africa    NaN  NaN  ...         NaN          NaN          NaN\n3       Algeria     §4  xxx  ...  9708.27744  9112.461105  9145.810174\n4         Libya  ‡§¶16  xxx  ...         ...          ...          ...\n\n[5 rows x 76 columns]\n\n\n\n\n\nPython (polars)\n\ndf_sipri = pl.read_excel(\"data/SIPRI-Milex-data-1949-2022.xlsx\", sheet_id=5, read_options={\"skip_rows\": 5})\n\ndf_sipri.head()\n\n\n\n\nshape: (5, 76)\n\n\n\nCountry\nNotes\n1949\n1950\n1951\n1952\n1953\n1954\n1955\n1956\n1957\n1958\n1959\n1960\n1961\n1962\n1963\n1964\n1965\n1966\n1967\n1968\n1969\n1970\n1971\n1972\n1973\n1974\n1975\n1976\n1977\n1978\n1979\n1980\n1981\n1982\n1983\n…\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\n…\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\"Africa\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"North Africa\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"Algeria\"\n\"§4\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"234.875985\"\n\"219.434678\"\n\"215.133118\"\n\"208.220940\"\n\"215.742463\"\n\"413.599801\"\n\"461.022683\"\n\"642.532765\"\n\"560.729351\"\n\"607.406682\"\n\"600.773471\"\n\"683.327939\"\n\"607.328128\"\n\"701.198007\"\n\"704.831389\"\n…\n\"610.182410\"\n\"622.034094\"\n\"615.542127\"\n\"601.651385\"\n\"642.721150\"\n\"657.986141\"\n\"1101.032432\"\n\"1183.864801\"\n\"1440.243493\"\n\"1395.429481\"\n\"1588.840569\"\n\"1910.994943\"\n\"2021.120506\"\n\"2133.027701\"\n\"2475.100274\"\n\"2709.025608\"\n\"2768.307740\"\n\"2708.645105\"\n\"3080.937162\"\n\"3225.387723\"\n\"3306.186349\"\n\"3879.058547\"\n\"4519.638056\"\n\"4908.797561\"\n\"5194.999271\"\n\"7434.910242\"\n\"7823.704814\"\n\"8450.873651\"\n\"9732.621963\"\n\"10182.147187\"\n\"10212.538248\"\n\"9671.777933\"\n\"9275.706188\"\n\"10006.914126\"\n\"9773.554762\"\n\"9112.461105\"\n\"8776.364725\"\n\n\n\"Libya\"\n\"‡§¶16\"\n\"xxx\"\n\"xxx\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"62.239411\"\n\"75.739505\"\n\"135.605176\"\n\"171.736926\"\n\"205.401564\"\n\"280.364831\"\n\"501.713486\"\n\"517.782969\"\n\"399.804189\"\n\"496.864250\"\n\"660.244648\"\n\"403.379454\"\n\"433.595285\"\n\"599.712512\"\n\"705.411019\"\n\"877.901730\"\n\"1006.758017\"\n\"469.762633\"\n\"542.251381\"\n\"...\"\n…\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"528.148467\"\n\"595.753213\"\n\"460.005767\"\n\"492.339926\"\n\"481.663213\"\n\"619.030119\"\n\"770.484367\"\n\"1006.128971\"\n\"991.116581\"\n\"872.043438\"\n\"820.739134\"\n\"1240.400997\"\n\"...\"\n\"...\"\n\"...\"\n\"2691.266837\"\n\"3509.174752\"\n\"3246.886855\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\"...\"\n\n\n\"Morocco\"\n\"§17\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"xxx\"\n\"119.561947\"\n\"174.296160\"\n\"231.988959\"\n\"270.419973\"\n\"269.797363\"\n\"307.693292\"\n\"326.567713\"\n\"429.706446\"\n\"386.061343\"\n\"336.729958\"\n\"365.821285\"\n\"381.660589\"\n\"491.011780\"\n\"445.838272\"\n\"460.681190\"\n\"552.386269\"\n\"610.999174\"\n\"694.413605\"\n\"818.316780\"\n\"1201.617167\"\n\"1686.646799\"\n\"1934.233958\"\n\"1722.805411\"\n\"1726.670724\"\n\"1987.294925\"\n\"2025.512311\"\n\"2098.786842\"\n\"1527.477606\"\n…\n\"1721.964873\"\n\"1722.974496\"\n\"1859.410193\"\n\"2010.669934\"\n\"1974.552450\"\n\"2073.654577\"\n\"2057.185887\"\n\"2170.432946\"\n\"2228.159258\"\n\"2052.130321\"\n\"2046.648979\"\n\"2143.497749\"\n\"2169.058500\"\n\"1837.788653\"\n\"1390.760784\"\n\"2516.231872\"\n\"2394.040085\"\n\"2535.872578\"\n\"2464.704546\"\n\"2557.771063\"\n\"2582.189542\"\n\"2659.230192\"\n\"2966.110340\"\n\"3168.016273\"\n\"3390.448538\"\n\"3415.165311\"\n\"3660.789360\"\n\"4182.250761\"\n\"4146.897151\"\n\"3828.729050\"\n\"3852.059058\"\n\"3965.368975\"\n\"3993.067756\"\n\"4076.773137\"\n\"5225.571603\"\n\"5378.366535\"\n\"5368.334058\"\n\n\n\n\n\n\n\n\npl.read_csv()のときとスキップの仕方が異なる点に注意してください。\n\nややツッコミどころはありますが、一応、それなりにデータが読み込みめているようです。\n\n\n12.3.3 欠損値の指定\n残念ながら、まだこれだけでは分析に耐えるデータではありません。１つ目の問題は、謎のxxxや...です。改めて元のデータを見てみると、4行目に”“. .” = data unavailable. “xxx” = country did not exist or was not independent during all or part of the year in question.”と書いてあります。すなわち、これらは欠損値を示していると考えられます。\nしたがって、データを読み込む際にはこれらを欠損値であることをR/Pythonに教えてあげる必要があります。\n\n\n\nR (readxl)\n\nlibrary(readxl)\n\ndf_sipri &lt;- read_excel(\"data/SIPRI-Milex-data-1949-2022.xlsx\", sheet = 5, skip = 5, na = c(\"xxx\", \"...\"))\n\nhead(df_sipri)\n\n\n# A tibble: 6 × 77\n  Country      ...2  Notes `1949.0` `1950.0` `1951.0` `1952.0` `1953.0` `1954.0`\n  &lt;chr&gt;        &lt;lgl&gt; &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 &lt;NA&gt;         NA    &lt;NA&gt;        NA       NA       NA       NA       NA       NA\n2 Africa       NA    &lt;NA&gt;        NA       NA       NA       NA       NA       NA\n3 North Africa NA    &lt;NA&gt;        NA       NA       NA       NA       NA       NA\n4 Algeria      NA    §4          NA       NA       NA       NA       NA       NA\n5 Libya        NA    ‡§¶16       NA       NA       NA       NA       NA       NA\n6 Morocco      NA    §17         NA       NA       NA       NA       NA       NA\n# ℹ 68 more variables: `1955.0` &lt;dbl&gt;, `1956.0` &lt;dbl&gt;, `1957.0` &lt;dbl&gt;,\n#   `1958.0` &lt;dbl&gt;, `1959.0` &lt;dbl&gt;, `1960.0` &lt;dbl&gt;, `1961.0` &lt;dbl&gt;,\n#   `1962.0` &lt;dbl&gt;, `1963.0` &lt;dbl&gt;, `1964.0` &lt;dbl&gt;, `1965.0` &lt;dbl&gt;,\n#   `1966.0` &lt;dbl&gt;, `1967.0` &lt;dbl&gt;, `1968.0` &lt;dbl&gt;, `1969.0` &lt;dbl&gt;,\n#   `1970.0` &lt;dbl&gt;, `1971.0` &lt;dbl&gt;, `1972.0` &lt;dbl&gt;, `1973.0` &lt;dbl&gt;,\n#   `1974.0` &lt;dbl&gt;, `1975.0` &lt;dbl&gt;, `1976.0` &lt;dbl&gt;, `1977.0` &lt;dbl&gt;,\n#   `1978.0` &lt;dbl&gt;, `1979.0` &lt;dbl&gt;, `1980.0` &lt;dbl&gt;, `1981.0` &lt;dbl&gt;, …\n\n\n\n\n\nPython (pandas)\n\ndf_sipri = pd.read_excel(\"data/SIPRI-Milex-data-1949-2022.xlsx\", sheet_name=5, skiprows=5, na_values=[\"xxx\", \"...\"])\n\ndf_sipri.head()\n\n\n        Country  Notes  1949  ...        2020         2021         2022\n0           NaN    NaN   NaN  ...         NaN          NaN          NaN\n1        Africa    NaN   NaN  ...         NaN          NaN          NaN\n2  North Africa    NaN   NaN  ...         NaN          NaN          NaN\n3       Algeria     §4   NaN  ...  9708.27744  9112.461105  9145.810174\n4         Libya  ‡§¶16   NaN  ...         NaN          NaN          NaN\n\n[5 rows x 76 columns]\n\n\n\n\n\nPython (polars)\n\ndf_sipri = pl.read_excel(\"data/SIPRI-Milex-data-1949-2022.xlsx\", sheet_id=5, read_options={\"skip_rows\": 5, \"null_values\": [\"xxx\", \"...\"]})\n\ndf_sipri.head()\n\n\n\n\nshape: (5, 76)\n\n\n\nCountry\nNotes\n1949\n1950\n1951\n1952\n1953\n1954\n1955\n1956\n1957\n1958\n1959\n1960\n1961\n1962\n1963\n1964\n1965\n1966\n1967\n1968\n1969\n1970\n1971\n1972\n1973\n1974\n1975\n1976\n1977\n1978\n1979\n1980\n1981\n1982\n1983\n…\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\n…\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"Africa\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"North Africa\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"Algeria\"\n\"§4\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n234.875985\n219.434678\n215.133118\n208.22094\n215.742463\n413.599801\n461.022683\n642.532765\n560.729351\n607.406682\n600.773471\n683.327939\n607.328128\n701.198007\n704.831389\n…\n610.18241\n622.034094\n615.542127\n601.651385\n642.72115\n657.986141\n1101.032432\n1183.864801\n1440.243493\n1395.429481\n1588.840569\n1910.994943\n2021.120506\n2133.027701\n2475.100274\n2709.025608\n2768.30774\n2708.645105\n3080.937162\n3225.387723\n3306.186349\n3879.058547\n4519.638056\n4908.797561\n5194.999271\n7434.910242\n7823.704814\n8450.873651\n9732.621963\n10182.147187\n10212.538248\n9671.777933\n9275.706188\n10006.914126\n9773.554762\n9112.461105\n8776.364725\n\n\n\"Libya\"\n\"‡§¶16\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n62.239411\n75.739505\n135.605176\n171.736926\n205.401564\n280.364831\n501.713486\n517.782969\n399.804189\n496.86425\n660.244648\n403.379454\n433.595285\n599.712512\n705.411019\n877.90173\n1006.758017\n469.762633\n542.251381\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n528.148467\n595.753213\n460.005767\n492.339926\n481.663213\n619.030119\n770.484367\n1006.128971\n991.116581\n872.043438\n820.739134\n1240.400997\nnull\nnull\nnull\n2691.266837\n3509.174752\n3246.886855\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"Morocco\"\n\"§17\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n119.561947\n174.29616\n231.988959\n270.419973\n269.797363\n307.693292\n326.567713\n429.706446\n386.061343\n336.729958\n365.821285\n381.660589\n491.01178\n445.838272\n460.68119\n552.386269\n610.999174\n694.413605\n818.31678\n1201.617167\n1686.646799\n1934.233958\n1722.805411\n1726.670724\n1987.294925\n2025.512311\n2098.786842\n1527.477606\n…\n1721.964873\n1722.974496\n1859.410193\n2010.669934\n1974.55245\n2073.654577\n2057.185887\n2170.432946\n2228.159258\n2052.130321\n2046.648979\n2143.497749\n2169.0585\n1837.788653\n1390.760784\n2516.231872\n2394.040085\n2535.872578\n2464.704546\n2557.771063\n2582.189542\n2659.230192\n2966.11034\n3168.016273\n3390.448538\n3415.165311\n3660.78936\n4182.250761\n4146.897151\n3828.72905\n3852.059058\n3965.368975\n3993.067756\n4076.773137\n5225.571603\n5378.366535\n5368.334058\n\n\n\n\n\n\n\n先程までxxxや...であったところが欠損値になっていることが分かります。必ずしもエラーが出なかったとしても問題がないというわけではない、というのがもう一つの教訓でしょうか。\nこれでもまだ直すべき点はあるのですが、それはデータの加工として扱いたいと思います。\n\n\n12.3.4 文字化けの対処\n最後に、日本語を含むデータを用いて文字化けに対処したいと思います。まずは、東京大学谷口研究室・朝日新聞社共同調査の2017年衆院選の有権者調査のデータをダウンロードします。\n表計算ソフトで開くと、おそらくMac/Linuxユーザは都道府県などが文字化けしているのではないでしょうか。大雑把に言ってしまうとWindowsで作ったファイルはMac/Linuxで文字化けを起こし、その逆もまた然りです。\nその場合、文字データの処理方法（エンコード）を適切に設定することで、文字化けを回避することができます。Windowsで作成された日本語データはShift-JIS（あるいはCP932）という形式でエンコードされるので、そのように指定します。\n\nついでに99が無回答なので欠損値としておきます。\n\n\n\n\nR (tidyverse)\n\ndf_voter2017 &lt;- read_csv(\"data/2017UTASV20200326.csv\", locale = locale(encoding = \"Shift-JIS\"), na = \"99\")\n\nhead(df_voter2017)\n\n\n# A tibble: 6 × 137\n     ID PREFNAME CITY    PREFEC HRDIST    Q1    Q2    Q3    Q4  Q5_1  Q5_2  Q5_3\n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     4 北海道   札幌市…      1      1     2     1     4     1     6     2     5\n2     6 北海道   札幌市…      1      1     2     4     1     4     6     2     7\n3     7 北海道   札幌市…      1      1     1    66    66    66    66    66    66\n4    10 北海道   札幌市…      1      1     1    66    66    66    66    66    66\n5    11 北海道   札幌市…      1      3     2     1     2     1     6     5     1\n6    12 北海道   札幌市…      1      3     2     6     2     6    10     5    11\n# ℹ 125 more variables: Q6_1 &lt;dbl&gt;, Q6_2 &lt;dbl&gt;, Q6_3 &lt;dbl&gt;, Q7_1 &lt;dbl&gt;,\n#   Q7_2 &lt;dbl&gt;, Q7_3 &lt;dbl&gt;, Q7_4 &lt;dbl&gt;, Q7_5 &lt;dbl&gt;, Q7_6 &lt;dbl&gt;, Q8 &lt;dbl&gt;,\n#   Q9_1 &lt;dbl&gt;, Q9_2 &lt;dbl&gt;, Q9_3 &lt;dbl&gt;, Q9_4 &lt;dbl&gt;, Q9_5 &lt;dbl&gt;, Q9_6 &lt;dbl&gt;,\n#   Q9_7 &lt;dbl&gt;, Q9_8 &lt;dbl&gt;, Q9_9 &lt;dbl&gt;, Q10 &lt;dbl&gt;, Q11_1 &lt;dbl&gt;, Q11_2 &lt;dbl&gt;,\n#   Q12 &lt;dbl&gt;, Q13_1 &lt;dbl&gt;, Q13_2 &lt;dbl&gt;, Q13_3 &lt;dbl&gt;, Q13_4 &lt;dbl&gt;, Q13_5 &lt;dbl&gt;,\n#   Q13_6 &lt;dbl&gt;, Q13_7 &lt;dbl&gt;, Q13_8 &lt;dbl&gt;, Q13_9 &lt;dbl&gt;, Q13_10 &lt;dbl&gt;,\n#   Q14 &lt;dbl&gt;, Q15_1 &lt;dbl&gt;, Q15_2 &lt;dbl&gt;, Q16 &lt;dbl&gt;, Q17_1 &lt;dbl&gt;, Q17_2 &lt;dbl&gt;, …\n\n\n\n\n\nPython (pandas)\n\ndf_voter2017 = pd.read_csv(\"data/2017UTASV20200326.csv\", encoding=\"Shift-JIS\", na_values=\"99\")\n\ndf_voter2017.head()\n\n\n   ID PREFNAME    CITY  PREFEC  HRDIST  ...  Q19FA  Q26_2FA  Q26_3FA  F3FA  F4FA\n0   4      北海道  札幌市中央区       1       1  ...    NaN      NaN      NaN   NaN   NaN\n1   6      北海道  札幌市中央区       1       1  ...    NaN      NaN      NaN   NaN   NaN\n2   7      北海道  札幌市中央区       1       1  ...    NaN      NaN      NaN   NaN   NaN\n3  10      北海道  札幌市中央区       1       1  ...    NaN      NaN      NaN   NaN   NaN\n4  11      北海道  札幌市豊平区       1       3  ...    NaN      NaN      NaN  大学中退   NaN\n\n[5 rows x 137 columns]\n\n\n\n\n\nPython (polars)\n\ndf_voter2017 = pl.read_csv(\"data/2017UTASV20200326.csv\", encoding=\"Shift-JIS\", null_values=\"99\")\n\ndf_voter2017.head()\n\n\n\n\nshape: (5, 137)\n\n\n\nID\nPREFNAME\nCITY\nPREFEC\nHRDIST\nQ1\nQ2\nQ3\nQ4\nQ5_1\nQ5_2\nQ5_3\nQ6_1\nQ6_2\nQ6_3\nQ7_1\nQ7_2\nQ7_3\nQ7_4\nQ7_5\nQ7_6\nQ8\nQ9_1\nQ9_2\nQ9_3\nQ9_4\nQ9_5\nQ9_6\nQ9_7\nQ9_8\nQ9_9\nQ10\nQ11_1\nQ11_2\nQ12\nQ13_1\nQ13_2\n…\nQ23_17\nQ24_1\nQ24_2\nQ24_3\nQ24_4\nQ24_5\nQ24_6\nQ24_7\nQ25_1\nQ25_2\nQ25_3\nQ25_4\nQ25_5\nQ26_1\nQ26_2_1\nQ26_2_2\nQ26_2_3\nQ26_3_1\nQ26_3_2\nQ26_3_3\nQ27\nF1\nF2\nF3\nF4\nQ2FA\nQ4FA\nQ5FA\nQ6FA\nQ8FA\nQ13FA\nQ18FA\nQ19FA\nQ26_2FA\nQ26_3FA\nF3FA\nF4FA\n\n\ni64\nstr\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n…\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n4\n\"北海道\"\n\"札幌市中央区\"\n1\n1\n2\n1\n4\n1\n6\n2\n5\n1\n6\n4\n1\n2\n2\n2\n3\n3\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n3\n3\n3\n4\n0\n0\n…\n4\n2\n5\n3\n4\n4\n4\n2\n4\n3\n4\n2\n3\n3\n66\n66\n66\n2\n6\n7\n3\n2\n4\n3\n1\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\n\n6\n\"北海道\"\n\"札幌市中央区\"\n1\n1\n2\n4\n1\n4\n6\n2\n7\n1\n6\n5\n5\n2\n2\n5\n5\n5\n4\n1\n0\n0\n0\n0\n0\n0\n0\n0\n2\n3\n4\n2\n0\n0\n…\n4\n3\n2\n2\n2\n2\n3\n2\n2\n2\n4\n2\n3\n1\n2\n1\n9\n66\n66\n66\n2\n1\n5\n2\n2\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\n\n7\n\"北海道\"\n\"札幌市中央区\"\n1\n1\n1\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n3\n2\n3\n4\n0\n0\n…\n3\n3\n4\n4\n3\n3\n2\n2\n3\n4\n2\n3\n3\n3\n66\n66\n66\n1\n2\n3\n2\n2\n3\n4\n6\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\n\n10\n\"北海道\"\n\"札幌市中央区\"\n1\n1\n1\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n66\n0\n0\n0\n0\n0\n0\n0\n0\n1\n3\n2\n2\n4\n0\n0\n…\n3\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n5\n4\n4\n4\n4\n3\n66\n66\n66\nnull\nnull\nnull\nnull\n2\n7\n2\n6\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\n\n11\n\"北海道\"\n\"札幌市豊平区\"\n1\n3\n2\n1\n2\n1\n6\n5\n1\n1\n3\n2\nnull\n2\n2\n3\n3\n4\n1\n1\n1\n1\n0\n0\n0\n0\n0\n0\n2\n3\n4\n2\n0\n1\n…\n3\n2\n3\n4\n4\n3\n3\n3\n4\n4\n4\n3\n3\n3\n66\n66\n66\n1\n2\nnull\n3\n2\n7\n7\n6\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"大学中退\"\n\"NA\"\n\n\n\n\n\n\n\n逆に、Windowsで開いたファイルが文字化けする場合はMac/Linuxで作成された可能性が高いです。Mac/LinuxではUTF8というエンコーディングを使っているので、そのように指定すれば文字化けせずに読み込めるはずです。\n\nただし、最近のWindowsではUTF8が使われて、文字化けが起こらないことがあります。\n\n\n\n\n\n\n\nLibreOffice\n\n\n\nところで、エクセルで読み込む際の文字化けを解決することはできません。その場合は無料のオフィスソフトであるLibreOfficeを使うことをおすすめします。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの読み込み</span>"
    ]
  },
  {
    "objectID": "data_import.html#データの在り処",
    "href": "data_import.html#データの在り処",
    "title": "12  データの読み込み",
    "section": "12.4 データの在り処",
    "text": "12.4 データの在り処\n政治学や周辺領域で利用可能なデータが集まっているサイトを紹介します。\n\nWorld Bank Open Data\nVarieties of Democracy\nA dataset with political datasets\n大阪大学大学院国際公共政策研究科EBPM研究センター\nKaggle Datasets\n\nKaggleとは世界最大規模のデータ分析コンペです。\n\nHarvard Dataverse\n\n政治学でレプリケーションデータを公開するデファクトスタンダードになっています。\n\nGitHub\n\nGitHubはコードの公開・共有サイトですが、適当な単語で検索するとデータが引っかかるときがあります。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの読み込み</span>"
    ]
  },
  {
    "objectID": "data_select.html",
    "href": "data_select.html",
    "title": "13  データの選択",
    "section": "",
    "text": "13.1 変数の選択",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの選択</span>"
    ]
  },
  {
    "objectID": "data_select.html#変数の選択",
    "href": "data_select.html#変数の選択",
    "title": "13  データの選択",
    "section": "",
    "text": "13.1.1 変数名による選択\nまずは、特定の変数だけを使う場合を考えます。例えば、以前読み込んだPolityのデータから特定の変数だけを取り出します。具体的には、ccodeとcountry、year、polity2だけを取り出します。\n\n\n\nR (base)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\")\n\ndf_polity &lt;- df_polity[,c(\"ccode\", \"country\", \"year\", \"polity2\")]\n\nhead(df_polity)\n\n\n# A tibble: 6 × 4\n  ccode country      year polity2\n  &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1   700 Afghanistan  1800      -6\n2   700 Afghanistan  1801      -6\n3   700 Afghanistan  1802      -6\n4   700 Afghanistan  1803      -6\n5   700 Afghanistan  1804      -6\n6   700 Afghanistan  1805      -6\n\n\n\n\n\nR (tidyverse)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\") |&gt; \n    select(ccode, country, year, polity2)\n\nhead(df_polity)\n\n\n# A tibble: 6 × 4\n  ccode country      year polity2\n  &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1   700 Afghanistan  1800      -6\n2   700 Afghanistan  1801      -6\n3   700 Afghanistan  1802      -6\n4   700 Afghanistan  1803      -6\n5   700 Afghanistan  1804      -6\n6   700 Afghanistan  1805      -6\n\n\n\n\n\nPython (pandas)\n\ndf_polity = pd.read_excel(\"data/p5v2018.xls\")\n\ndf_polity = df_polity.loc[:,[\"ccode\", \"country\", \"year\", \"polity2\"]]\n# df_polity = df_polity[[\"ccode\", \"country\", \"year\", \"polity2\"]]でも可\n\ndf_polity.head()\n\n\n   ccode      country  year  polity2\n0    700  Afghanistan  1800     -6.0\n1    700  Afghanistan  1801     -6.0\n2    700  Afghanistan  1802     -6.0\n3    700  Afghanistan  1803     -6.0\n4    700  Afghanistan  1804     -6.0\n\n\n\n\n\nPython (polars)\n\ndf_polity = (\n    pl.read_excel(\"data/p5v2018.xls\")\n    .select([\"ccode\", \"country\", \"year\", \"polity2\"])\n)\n\ndf_polity.head()\n\n\n\n\nshape: (5, 4)\n\n\n\nccode\ncountry\nyear\npolity2\n\n\ni64\nstr\ni64\ni64\n\n\n\n\n700\n\"Afghanistan\"\n1800\n-6\n\n\n700\n\"Afghanistan\"\n1801\n-6\n\n\n700\n\"Afghanistan\"\n1802\n-6\n\n\n700\n\"Afghanistan\"\n1803\n-6\n\n\n700\n\"Afghanistan\"\n1804\n-6\n\n\n\n\n\n\n\nいずれも期待通りの結果が出ています。ところで、上の4つのコードを見比べていると共通性があることが分かります。\n\nRの標準関数およびPythonのpandasでは,の右側で変数名を入力することで変数を選択しています。\n\npandasの場合はloc属性を使っていること、,の左に「全て」を意味する:が入っている点に注意。\n\n一方、RのtidyverseとPythonのpolarsではselect()を使って変数名を選択しています。\n\n\n\n13.1.2 番号による選択\nあまり使う機会はありませんが、変数の番号を指定して選択することもできます。それぞれ、3, 5, 6, 12番目の変数です。\n\n\n\nR (base)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\")\n\ndf_polity &lt;- df_polity[,c(3, 5, 6, 12)]\n\nhead(df_polity)\n\n\n# A tibble: 6 × 4\n  ccode country      year polity2\n  &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1   700 Afghanistan  1800      -6\n2   700 Afghanistan  1801      -6\n3   700 Afghanistan  1802      -6\n4   700 Afghanistan  1803      -6\n5   700 Afghanistan  1804      -6\n6   700 Afghanistan  1805      -6\n\n\n\n\n\nPython (pandas)\n\ndf_polity = pd.read_excel(\"data/p5v2018.xls\")\n\ndf_polity = df_polity.iloc[:,[2, 4, 5, 11]]\n\ndf_polity.head()\n\n\n   ccode      country  year  polity2\n0    700  Afghanistan  1800     -6.0\n1    700  Afghanistan  1801     -6.0\n2    700  Afghanistan  1802     -6.0\n3    700  Afghanistan  1803     -6.0\n4    700  Afghanistan  1804     -6.0\n\n\n\nlocの代わりにilocを使います。\n\nRは1から始まるので番号をそのまま入力すればいいですが、Pythonは0から始まるので1引いた数を入力します。\n\n直観的にはRの方が自然ですが、プログラミングでは0から始まるのが標準的です。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの選択</span>"
    ]
  },
  {
    "objectID": "data_select.html#変数名の変更",
    "href": "data_select.html#変数名の変更",
    "title": "13  データの選択",
    "section": "13.2 変数名の変更",
    "text": "13.2 変数名の変更\n変数の選択ではないですが、ついでに変数名を変更する方法を説明します。例えば、世銀のデータではCountry Nameのように空白が変数名に入っていましたが、変数名に空白が入ることは（特にtidyverseを使う上で）不都合があります。変数名を変更したいと思います。\n\n\n\nR (tidyverse)\n\ndf_pop_fem &lt;- read_csv(\"data/wb_pop_fem.csv\", skip = 4) |&gt; \n    rename(country_name = \"Country Name\", coutnry_code = \"Country Code\", indicator_name = \"Indicator Name\", indicator_code = \"Indicator Code\")\n\nhead(df_pop_fem)\n\n\n# A tibble: 6 × 69\n  country_name   coutnry_code indicator_name indicator_code `1960` `1961` `1962`\n  &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Aruba          ABW          Population, f… SP.POP.TOTL.F… 2.78e4 2.84e4 2.88e4\n2 Africa Easter… AFE          Population, f… SP.POP.TOTL.F… 6.59e7 6.76e7 6.95e7\n3 Afghanistan    AFG          Population, f… SP.POP.TOTL.F… 4.15e6 4.23e6 4.33e6\n4 Africa Wester… AFW          Population, f… SP.POP.TOTL.F… 4.88e7 4.99e7 5.09e7\n5 Angola         AGO          Population, f… SP.POP.TOTL.F… 2.67e6 2.70e6 2.74e6\n6 Albania        ALB          Population, f… SP.POP.TOTL.F… 7.85e5 8.09e5 8.34e5\n# ℹ 62 more variables: `1963` &lt;dbl&gt;, `1964` &lt;dbl&gt;, `1965` &lt;dbl&gt;, `1966` &lt;dbl&gt;,\n#   `1967` &lt;dbl&gt;, `1968` &lt;dbl&gt;, `1969` &lt;dbl&gt;, `1970` &lt;dbl&gt;, `1971` &lt;dbl&gt;,\n#   `1972` &lt;dbl&gt;, `1973` &lt;dbl&gt;, `1974` &lt;dbl&gt;, `1975` &lt;dbl&gt;, `1976` &lt;dbl&gt;,\n#   `1977` &lt;dbl&gt;, `1978` &lt;dbl&gt;, `1979` &lt;dbl&gt;, `1980` &lt;dbl&gt;, `1981` &lt;dbl&gt;,\n#   `1982` &lt;dbl&gt;, `1983` &lt;dbl&gt;, `1984` &lt;dbl&gt;, `1985` &lt;dbl&gt;, `1986` &lt;dbl&gt;,\n#   `1987` &lt;dbl&gt;, `1988` &lt;dbl&gt;, `1989` &lt;dbl&gt;, `1990` &lt;dbl&gt;, `1991` &lt;dbl&gt;,\n#   `1992` &lt;dbl&gt;, `1993` &lt;dbl&gt;, `1994` &lt;dbl&gt;, `1995` &lt;dbl&gt;, `1996` &lt;dbl&gt;, …\n\n\n\n\n\nPython (pandas)\n\ndf_pop_fem = (\n    pd.read_csv(\"data/wb_pop_fem.csv\", skiprows=4)\n    .rename(columns={\"Country Name\": \"country_name\", \"Country Code\": \"coutnry_code\", \"Indicator Name\": \"indicator_name\", \"Indicator Code\": \"indicator_code\"})\n)\n\ndf_pop_fem.head()\n\n\n                  country_name coutnry_code  ... 2023 Unnamed: 68\n0                        Aruba          ABW  ...  NaN         NaN\n1  Africa Eastern and Southern          AFE  ...  NaN         NaN\n2                  Afghanistan          AFG  ...  NaN         NaN\n3   Africa Western and Central          AFW  ...  NaN         NaN\n4                       Angola          AGO  ...  NaN         NaN\n\n[5 rows x 69 columns]\n\n\n\n\n\nPython (polars)\n\ndf_pop_fem = (\n    pl.read_csv(\"data/wb_pop_fem.csv\", skip_rows=4)\n    .rename({\"Country Name\": \"country_name\", \"Country Code\": \"coutnry_code\", \"Indicator Name\": \"indicator_name\", \"Indicator Code\": \"indicator_code\"})\n)\n\ndf_pop_fem.head()\n\n\n\n\nshape: (5, 69)\n\n\n\ncountry_name\ncoutnry_code\nindicator_name\nindicator_code\n1960\n1961\n1962\n1963\n1964\n1965\n1966\n1967\n1968\n1969\n1970\n1971\n1972\n1973\n1974\n1975\n1976\n1977\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n\n\n\nstr\nstr\nstr\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\nstr\nstr\n\n\n\n\n\"Aruba\"\n\"ABW\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n27773\n28380\n28820\n29218\n29570\n29875\n30135\n30253\n30232\n30166\n30063\n29927\n29953\n30229\n30595\n30972\n31245\n31416\n31584\n31749\n31909\n32121\n32389\n32659\n32886\n33008\n33007\n32904\n32788\n32892\n33480\n34657\n35941\n37137\n38437\n39724\n41014\n42336\n43688\n45050\n46269\n47178\n47831\n48374\n48877\n49414\n50016\n50636\n51272\n51919\n52484\n52980\n53480\n53953\n54403\n54828\n55224\n55591\n55935\n56254\n56373\n56330\n56272\n\"\"\nnull\n\n\n\"Africa Eastern…\n\"AFE\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n65853220\n67606287\n69457112\n71375643\n73386167\n75478396\n77610073\n79810945\n82111287\n84493601\n86968714\n89504801\n92051419\n94694181\n97478670\n100339888\n103289004\n106237590\n109415983\n112834021\n116060576\n119525759\n123410049\n127333314\n131344567\n135563206\n139816011\n144066893\n148288335\n152522362\n156942214\n161298074\n165609524\n170167926\n174762745\n179486372\n184468529\n189280003\n194009070\n198959676\n204048614\n209257664\n214635664\n220167814\n225898442\n231830259\n237997868\n244435307\n251105628\n257956460\n265000967\n272174714\n279546577\n287224924\n295089133\n303195897\n311387401\n319637365\n328159112\n336930970\n345889868\n354855221\n363834524\n\"\"\nnull\n\n\n\"Afghanistan\"\n\"AFG\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n4145945\n4233771\n4326881\n4424511\n4526691\n4634341\n4745981\n4861918\n4983086\n5108507\n5239568\n5372747\n5509781\n5655304\n5803603\n5948268\n6083166\n6214979\n6342838\n6373547\n6136856\n5490160\n4973968\n4916351\n5074600\n5225679\n5207273\n5152650\n5188060\n5334609\n5346409\n5372208\n6028939\n7000119\n7722096\n8199445\n8537421\n8871958\n9217591\n9595036\n9727541\n9793166\n10438055\n11247647\n11690825\n12109086\n12614497\n12835340\n13088192\n13557331\n13949295\n14468875\n15067373\n15594637\n16172321\n16682054\n17115346\n17614722\n18136922\n18679089\n19279930\n19844584\n20362329\n\"\"\nnull\n\n\n\"Africa Western…\n\"AFW\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n48802898\n49850088\n50928609\n52044907\n53196730\n54389295\n55621877\n56890201\n58204276\n59560501\n60963620\n62404746\n63900687\n65482730\n67160750\n68943269\n70786681\n72718234\n74770813\n76909670\n79104037\n81359426\n83714354\n85996392\n88238093\n90605997\n93047700\n95556172\n98139171\n100824162\n103478502\n106184462\n109071980\n111968903\n114896750\n117979287\n121143186\n124399328\n127775360\n131211380\n134795501\n138546839\n142408066\n146370538\n150463219\n154696476\n159035017\n163481052\n168058833\n172782717\n177645233\n182657978\n187755307\n192900081\n198163527\n203513873\n208980433\n214578994\n220253839\n226004857\n231877590\n237813580\n243821774\n\"\"\nnull\n\n\n\"Angola\"\n\"AGO\"\n\"Population, fe…\n\"SP.POP.TOTL.FE…\n2670229\n2704394\n2742689\n2779473\n2812590\n2838939\n2856740\n2867926\n2879001\n2902120\n2953347\n3032948\n3132441\n3244749\n3362438\n3483416\n3606782\n3735823\n3872130\n4014347\n4164145\n4321167\n4485276\n4656894\n4834820\n5018620\n5206761\n5396035\n5588733\n5787505\n5991207\n6199060\n6408303\n6621767\n6845622\n7077381\n7315200\n7561436\n7813123\n8071413\n8339311\n8619083\n8912191\n9219638\n9545020\n9886765\n10244381\n10620174\n11013001\n11422969\n11853530\n12303450\n12770743\n13252938\n13746371\n14248799\n14764575\n15293335\n15828040\n16370553\n16910989\n17452283\n17998220\n\"\"\nnull\n\n\n\n\n\n\n\nいずれもrename()を使って元の変数名と新しい変数名の対応関係を入力します。\n\ntidyverseの場合は新変数名 = 旧変数名ですが、pandas/polarsの場合は旧変数名: 新変数名です。\ntidyverseのselect()の中でも変数名を変更することができます。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの選択</span>"
    ]
  },
  {
    "objectID": "data_select.html#変数の除外",
    "href": "data_select.html#変数の除外",
    "title": "13  データの選択",
    "section": "13.3 変数の除外",
    "text": "13.3 変数の除外\n特定の変数を選択するのではなく、除外したいときがあるかもしれません。例えば、SIPRIの軍事費データのNotesは不要な気がします。\ntidyverseではselect()の際に!を付けると変数を除外します。\n\n\n\nR (readxl)\n\nlibrary(readxl)\n\ndf_sipri &lt;- read_excel(\"data/SIPRI-Milex-data-1949-2022.xlsx\", sheet = 5, skip = 5, na = c(\"xxx\", \"...\")) |&gt; \n    select(!Notes)\n\nhead(df_sipri)\n\n\n# A tibble: 6 × 76\n  Country   ...2  `1949.0` `1950.0` `1951.0` `1952.0` `1953.0` `1954.0` `1955.0`\n  &lt;chr&gt;     &lt;lgl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 &lt;NA&gt;      NA          NA       NA       NA       NA       NA       NA       NA\n2 Africa    NA          NA       NA       NA       NA       NA       NA       NA\n3 North Af… NA          NA       NA       NA       NA       NA       NA       NA\n4 Algeria   NA          NA       NA       NA       NA       NA       NA       NA\n5 Libya     NA          NA       NA       NA       NA       NA       NA       NA\n6 Morocco   NA          NA       NA       NA       NA       NA       NA       NA\n# ℹ 67 more variables: `1956.0` &lt;dbl&gt;, `1957.0` &lt;dbl&gt;, `1958.0` &lt;dbl&gt;,\n#   `1959.0` &lt;dbl&gt;, `1960.0` &lt;dbl&gt;, `1961.0` &lt;dbl&gt;, `1962.0` &lt;dbl&gt;,\n#   `1963.0` &lt;dbl&gt;, `1964.0` &lt;dbl&gt;, `1965.0` &lt;dbl&gt;, `1966.0` &lt;dbl&gt;,\n#   `1967.0` &lt;dbl&gt;, `1968.0` &lt;dbl&gt;, `1969.0` &lt;dbl&gt;, `1970.0` &lt;dbl&gt;,\n#   `1971.0` &lt;dbl&gt;, `1972.0` &lt;dbl&gt;, `1973.0` &lt;dbl&gt;, `1974.0` &lt;dbl&gt;,\n#   `1975.0` &lt;dbl&gt;, `1976.0` &lt;dbl&gt;, `1977.0` &lt;dbl&gt;, `1978.0` &lt;dbl&gt;,\n#   `1979.0` &lt;dbl&gt;, `1980.0` &lt;dbl&gt;, `1981.0` &lt;dbl&gt;, `1982.0` &lt;dbl&gt;, …\n\n\npandasとpolarsはdrop()メソッドで変数を除外します。\n\n\n\nPython (pandas)\n\ndf_sipri = (\n    pd.read_excel(\"data/SIPRI-Milex-data-1949-2022.xlsx\", sheet_name=5, skiprows=5, na_values=[\"xxx\", \"...\"])\n    .drop(columns=[\"Notes\"])\n)\n\ndf_sipri.head()\n\n\n        Country  1949  1950  ...        2020         2021         2022\n0           NaN   NaN   NaN  ...         NaN          NaN          NaN\n1        Africa   NaN   NaN  ...         NaN          NaN          NaN\n2  North Africa   NaN   NaN  ...         NaN          NaN          NaN\n3       Algeria   NaN   NaN  ...  9708.27744  9112.461105  9145.810174\n4         Libya   NaN   NaN  ...         NaN          NaN          NaN\n\n[5 rows x 75 columns]\n\n\n\n\n\nPython (polars)\n\ndf_sipri = (\n    pl.read_excel(\"data/SIPRI-Milex-data-1949-2022.xlsx\", sheet_id=5, read_options={\"skip_rows\": 5, \"null_values\": [\"xxx\", \"...\"]})\n    .drop([\"Notes\"])\n)\n\ndf_sipri.head()\n\n\n\n\nshape: (5, 75)\n\n\n\nCountry\n1949\n1950\n1951\n1952\n1953\n1954\n1955\n1956\n1957\n1958\n1959\n1960\n1961\n1962\n1963\n1964\n1965\n1966\n1967\n1968\n1969\n1970\n1971\n1972\n1973\n1974\n1975\n1976\n1977\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n\n\nstr\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"Africa\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"North Africa\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"Algeria\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n234.875985\n219.434678\n215.133118\n208.22094\n215.742463\n413.599801\n461.022683\n642.532765\n560.729351\n607.406682\n600.773471\n683.327939\n607.328128\n701.198007\n704.831389\n661.921863\n620.079659\n610.18241\n622.034094\n615.542127\n601.651385\n642.72115\n657.986141\n1101.032432\n1183.864801\n1440.243493\n1395.429481\n1588.840569\n1910.994943\n2021.120506\n2133.027701\n2475.100274\n2709.025608\n2768.30774\n2708.645105\n3080.937162\n3225.387723\n3306.186349\n3879.058547\n4519.638056\n4908.797561\n5194.999271\n7434.910242\n7823.704814\n8450.873651\n9732.621963\n10182.147187\n10212.538248\n9671.777933\n9275.706188\n10006.914126\n9773.554762\n9112.461105\n8776.364725\n\n\n\"Libya\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n62.239411\n75.739505\n135.605176\n171.736926\n205.401564\n280.364831\n501.713486\n517.782969\n399.804189\n496.86425\n660.244648\n403.379454\n433.595285\n599.712512\n705.411019\n877.90173\n1006.758017\n469.762633\n542.251381\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n528.148467\n595.753213\n460.005767\n492.339926\n481.663213\n619.030119\n770.484367\n1006.128971\n991.116581\n872.043438\n820.739134\n1240.400997\nnull\nnull\nnull\n2691.266837\n3509.174752\n3246.886855\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"Morocco\"\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n119.561947\n174.29616\n231.988959\n270.419973\n269.797363\n307.693292\n326.567713\n429.706446\n386.061343\n336.729958\n365.821285\n381.660589\n491.01178\n445.838272\n460.68119\n552.386269\n610.999174\n694.413605\n818.31678\n1201.617167\n1686.646799\n1934.233958\n1722.805411\n1726.670724\n1987.294925\n2025.512311\n2098.786842\n1527.477606\n1372.987541\n1966.91535\n1721.964873\n1722.974496\n1859.410193\n2010.669934\n1974.55245\n2073.654577\n2057.185887\n2170.432946\n2228.159258\n2052.130321\n2046.648979\n2143.497749\n2169.0585\n1837.788653\n1390.760784\n2516.231872\n2394.040085\n2535.872578\n2464.704546\n2557.771063\n2582.189542\n2659.230192\n2966.11034\n3168.016273\n3390.448538\n3415.165311\n3660.78936\n4182.250761\n4146.897151\n3828.72905\n3852.059058\n3965.368975\n3993.067756\n4076.773137\n5225.571603\n5378.366535\n5368.334058",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの選択</span>"
    ]
  },
  {
    "objectID": "data_select.html#観察の選択",
    "href": "data_select.html#観察の選択",
    "title": "13  データの選択",
    "section": "13.4 観察の選択",
    "text": "13.4 観察の選択\nこれまでは変数の操作について見てきましたが、次は観察の選択を学びます。つまり、データに含まれる観察の一部だけを取り出して分析する状況を考えます。\n\n13.4.1 不等号による選択\n例えば、Polityのデータのうち、第2次世界大戦後のデータを取り出したいとします。\n\n\n\nR (base)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\")\n\ndf_polity[df_polity$year &gt; 1945,]\n\n\n# A tibble: 9,952 × 37\n      p5   cyear ccode scode country      year  flag fragment democ autoc polity\n   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     0 7001946   700 AFG   Afghanistan  1946     0       NA     0    10    -10\n 2     0 7001947   700 AFG   Afghanistan  1947     0       NA     0    10    -10\n 3     0 7001948   700 AFG   Afghanistan  1948     0       NA     0    10    -10\n 4     0 7001949   700 AFG   Afghanistan  1949     0       NA     0    10    -10\n 5     0 7001950   700 AFG   Afghanistan  1950     0       NA     0    10    -10\n 6     0 7001951   700 AFG   Afghanistan  1951     0       NA     0    10    -10\n 7     0 7001952   700 AFG   Afghanistan  1952     0       NA     0    10    -10\n 8     0 7001953   700 AFG   Afghanistan  1953     0       NA     0    10    -10\n 9     0 7001954   700 AFG   Afghanistan  1954     0       NA     0    10    -10\n10     0 7001955   700 AFG   Afghanistan  1955     0       NA     0    10    -10\n# ℹ 9,942 more rows\n# ℹ 26 more variables: polity2 &lt;dbl&gt;, durable &lt;dbl&gt;, xrreg &lt;dbl&gt;, xrcomp &lt;dbl&gt;,\n#   xropen &lt;dbl&gt;, xconst &lt;dbl&gt;, parreg &lt;dbl&gt;, parcomp &lt;dbl&gt;, exrec &lt;dbl&gt;,\n#   exconst &lt;dbl&gt;, polcomp &lt;dbl&gt;, prior &lt;dbl&gt;, emonth &lt;dbl&gt;, eday &lt;dbl&gt;,\n#   eyear &lt;dbl&gt;, eprec &lt;dbl&gt;, interim &lt;dbl&gt;, bmonth &lt;dbl&gt;, bday &lt;dbl&gt;,\n#   byear &lt;dbl&gt;, bprec &lt;dbl&gt;, post &lt;dbl&gt;, change &lt;dbl&gt;, d5 &lt;dbl&gt;, sf &lt;dbl&gt;,\n#   regtrans &lt;dbl&gt;\n\nhead(df_polity)\n\n# A tibble: 6 × 37\n     p5   cyear ccode scode country      year  flag fragment democ autoc polity\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0 7001800   700 AFG   Afghanistan  1800     0       NA     1     7     -6\n2     0 7001801   700 AFG   Afghanistan  1801     0       NA     1     7     -6\n3     0 7001802   700 AFG   Afghanistan  1802     0       NA     1     7     -6\n4     0 7001803   700 AFG   Afghanistan  1803     0       NA     1     7     -6\n5     0 7001804   700 AFG   Afghanistan  1804     0       NA     1     7     -6\n6     0 7001805   700 AFG   Afghanistan  1805     0       NA     1     7     -6\n# ℹ 26 more variables: polity2 &lt;dbl&gt;, durable &lt;dbl&gt;, xrreg &lt;dbl&gt;, xrcomp &lt;dbl&gt;,\n#   xropen &lt;dbl&gt;, xconst &lt;dbl&gt;, parreg &lt;dbl&gt;, parcomp &lt;dbl&gt;, exrec &lt;dbl&gt;,\n#   exconst &lt;dbl&gt;, polcomp &lt;dbl&gt;, prior &lt;dbl&gt;, emonth &lt;dbl&gt;, eday &lt;dbl&gt;,\n#   eyear &lt;dbl&gt;, eprec &lt;dbl&gt;, interim &lt;dbl&gt;, bmonth &lt;dbl&gt;, bday &lt;dbl&gt;,\n#   byear &lt;dbl&gt;, bprec &lt;dbl&gt;, post &lt;dbl&gt;, change &lt;dbl&gt;, d5 &lt;dbl&gt;, sf &lt;dbl&gt;,\n#   regtrans &lt;dbl&gt;\n\n\n\n\n\nR (tidyverse)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\") |&gt; \n    filter(year &gt; 1945)\n\nhead(df_polity)\n\n\n# A tibble: 6 × 37\n     p5   cyear ccode scode country      year  flag fragment democ autoc polity\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0 7001946   700 AFG   Afghanistan  1946     0       NA     0    10    -10\n2     0 7001947   700 AFG   Afghanistan  1947     0       NA     0    10    -10\n3     0 7001948   700 AFG   Afghanistan  1948     0       NA     0    10    -10\n4     0 7001949   700 AFG   Afghanistan  1949     0       NA     0    10    -10\n5     0 7001950   700 AFG   Afghanistan  1950     0       NA     0    10    -10\n6     0 7001951   700 AFG   Afghanistan  1951     0       NA     0    10    -10\n# ℹ 26 more variables: polity2 &lt;dbl&gt;, durable &lt;dbl&gt;, xrreg &lt;dbl&gt;, xrcomp &lt;dbl&gt;,\n#   xropen &lt;dbl&gt;, xconst &lt;dbl&gt;, parreg &lt;dbl&gt;, parcomp &lt;dbl&gt;, exrec &lt;dbl&gt;,\n#   exconst &lt;dbl&gt;, polcomp &lt;dbl&gt;, prior &lt;dbl&gt;, emonth &lt;dbl&gt;, eday &lt;dbl&gt;,\n#   eyear &lt;dbl&gt;, eprec &lt;dbl&gt;, interim &lt;dbl&gt;, bmonth &lt;dbl&gt;, bday &lt;dbl&gt;,\n#   byear &lt;dbl&gt;, bprec &lt;dbl&gt;, post &lt;dbl&gt;, change &lt;dbl&gt;, d5 &lt;dbl&gt;, sf &lt;dbl&gt;,\n#   regtrans &lt;dbl&gt;\n\n\n\n\n\nPython (pandas)\n\ndf_polity = pd.read_excel(\"data/p5v2018.xls\")\n\ndf_polity = df_polity.loc[df_polity[\"year\"] &gt; 1945,:]\n# df_polity = df_polity[df_polity[\"year\"] &gt; 1945]でも可\n\ndf_polity.head()\n\n\n     p5    cyear  ccode scode      country  ...  post  change  d5  sf  regtrans\n146   0  7001946    700   AFG  Afghanistan  ...   NaN     NaN NaN NaN       NaN\n147   0  7001947    700   AFG  Afghanistan  ...   NaN     NaN NaN NaN       NaN\n148   0  7001948    700   AFG  Afghanistan  ...   NaN     NaN NaN NaN       NaN\n149   0  7001949    700   AFG  Afghanistan  ...   NaN     NaN NaN NaN       NaN\n150   0  7001950    700   AFG  Afghanistan  ...   NaN     NaN NaN NaN       NaN\n\n[5 rows x 37 columns]\n\n\n\n\n\nPython (polars)\n\ndf_polity = (\n    pl.read_excel(\"data/p5v2018.xls\")\n    .filter(pl.col(\"year\") &gt; 1945)\n)\n\ndf_polity.head()\n\n\n\n\nshape: (5, 37)\n\n\n\np5\ncyear\nccode\nscode\ncountry\nyear\nflag\nfragment\ndemoc\nautoc\npolity\npolity2\ndurable\nxrreg\nxrcomp\nxropen\nxconst\nparreg\nparcomp\nexrec\nexconst\npolcomp\nprior\nemonth\neday\neyear\neprec\ninterim\nbmonth\nbday\nbyear\nbprec\npost\nchange\nd5\nsf\nregtrans\n\n\ni64\ni64\ni64\nstr\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n0\n7001946\n700\n\"AFG\"\n\"Afghanistan\"\n1946\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7001947\n700\n\"AFG\"\n\"Afghanistan\"\n1947\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7001948\n700\n\"AFG\"\n\"Afghanistan\"\n1948\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7001949\n700\n\"AFG\"\n\"Afghanistan\"\n1949\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7001950\n700\n\"AFG\"\n\"Afghanistan\"\n1950\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\n\n\n\n\nここでも共通点が見えてきます。tidyverseとpolarsではfilter()の中に条件式を入れます。一方、Rの標準関数とpandasでは,の左側に条件式を入れます。\n\n&lt;や&gt;は通常の意味通り、使うことができます。\n等号も含む場合は&lt;=や&gt;=とします。\n\n\n\n13.4.2 等号による選択\n次に、日本だけのデータを取り出したいと思います。=ではなく==（=が2つ）である点に注意してください。\n\n\n\nR (base)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\")\n\ndf_polity[df_polity$country == \"Japan\",]\n\n\n# A tibble: 219 × 37\n      p5   cyear ccode scode country  year  flag fragment democ autoc polity\n   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     0 7401800   740 JPN   Japan    1800     0       NA     0    10    -10\n 2     0 7401801   740 JPN   Japan    1801     0       NA     0    10    -10\n 3     0 7401802   740 JPN   Japan    1802     0       NA     0    10    -10\n 4     0 7401803   740 JPN   Japan    1803     0       NA     0    10    -10\n 5     0 7401804   740 JPN   Japan    1804     0       NA     0    10    -10\n 6     0 7401805   740 JPN   Japan    1805     0       NA     0    10    -10\n 7     0 7401806   740 JPN   Japan    1806     0       NA     0    10    -10\n 8     0 7401807   740 JPN   Japan    1807     0       NA     0    10    -10\n 9     0 7401808   740 JPN   Japan    1808     0       NA     0    10    -10\n10     0 7401809   740 JPN   Japan    1809     0       NA     0    10    -10\n# ℹ 209 more rows\n# ℹ 26 more variables: polity2 &lt;dbl&gt;, durable &lt;dbl&gt;, xrreg &lt;dbl&gt;, xrcomp &lt;dbl&gt;,\n#   xropen &lt;dbl&gt;, xconst &lt;dbl&gt;, parreg &lt;dbl&gt;, parcomp &lt;dbl&gt;, exrec &lt;dbl&gt;,\n#   exconst &lt;dbl&gt;, polcomp &lt;dbl&gt;, prior &lt;dbl&gt;, emonth &lt;dbl&gt;, eday &lt;dbl&gt;,\n#   eyear &lt;dbl&gt;, eprec &lt;dbl&gt;, interim &lt;dbl&gt;, bmonth &lt;dbl&gt;, bday &lt;dbl&gt;,\n#   byear &lt;dbl&gt;, bprec &lt;dbl&gt;, post &lt;dbl&gt;, change &lt;dbl&gt;, d5 &lt;dbl&gt;, sf &lt;dbl&gt;,\n#   regtrans &lt;dbl&gt;\n\nhead(df_polity)\n\n# A tibble: 6 × 37\n     p5   cyear ccode scode country      year  flag fragment democ autoc polity\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0 7001800   700 AFG   Afghanistan  1800     0       NA     1     7     -6\n2     0 7001801   700 AFG   Afghanistan  1801     0       NA     1     7     -6\n3     0 7001802   700 AFG   Afghanistan  1802     0       NA     1     7     -6\n4     0 7001803   700 AFG   Afghanistan  1803     0       NA     1     7     -6\n5     0 7001804   700 AFG   Afghanistan  1804     0       NA     1     7     -6\n6     0 7001805   700 AFG   Afghanistan  1805     0       NA     1     7     -6\n# ℹ 26 more variables: polity2 &lt;dbl&gt;, durable &lt;dbl&gt;, xrreg &lt;dbl&gt;, xrcomp &lt;dbl&gt;,\n#   xropen &lt;dbl&gt;, xconst &lt;dbl&gt;, parreg &lt;dbl&gt;, parcomp &lt;dbl&gt;, exrec &lt;dbl&gt;,\n#   exconst &lt;dbl&gt;, polcomp &lt;dbl&gt;, prior &lt;dbl&gt;, emonth &lt;dbl&gt;, eday &lt;dbl&gt;,\n#   eyear &lt;dbl&gt;, eprec &lt;dbl&gt;, interim &lt;dbl&gt;, bmonth &lt;dbl&gt;, bday &lt;dbl&gt;,\n#   byear &lt;dbl&gt;, bprec &lt;dbl&gt;, post &lt;dbl&gt;, change &lt;dbl&gt;, d5 &lt;dbl&gt;, sf &lt;dbl&gt;,\n#   regtrans &lt;dbl&gt;\n\n\n\n\n\nR (tidyverse)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\") |&gt; \n    filter(country == \"Japan\")\n\nhead(df_polity)\n\n\n# A tibble: 6 × 37\n     p5   cyear ccode scode country  year  flag fragment democ autoc polity\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0 7401800   740 JPN   Japan    1800     0       NA     0    10    -10\n2     0 7401801   740 JPN   Japan    1801     0       NA     0    10    -10\n3     0 7401802   740 JPN   Japan    1802     0       NA     0    10    -10\n4     0 7401803   740 JPN   Japan    1803     0       NA     0    10    -10\n5     0 7401804   740 JPN   Japan    1804     0       NA     0    10    -10\n6     0 7401805   740 JPN   Japan    1805     0       NA     0    10    -10\n# ℹ 26 more variables: polity2 &lt;dbl&gt;, durable &lt;dbl&gt;, xrreg &lt;dbl&gt;, xrcomp &lt;dbl&gt;,\n#   xropen &lt;dbl&gt;, xconst &lt;dbl&gt;, parreg &lt;dbl&gt;, parcomp &lt;dbl&gt;, exrec &lt;dbl&gt;,\n#   exconst &lt;dbl&gt;, polcomp &lt;dbl&gt;, prior &lt;dbl&gt;, emonth &lt;dbl&gt;, eday &lt;dbl&gt;,\n#   eyear &lt;dbl&gt;, eprec &lt;dbl&gt;, interim &lt;dbl&gt;, bmonth &lt;dbl&gt;, bday &lt;dbl&gt;,\n#   byear &lt;dbl&gt;, bprec &lt;dbl&gt;, post &lt;dbl&gt;, change &lt;dbl&gt;, d5 &lt;dbl&gt;, sf &lt;dbl&gt;,\n#   regtrans &lt;dbl&gt;\n\n\n\n\n\nPython (pandas)\n\ndf_polity = pd.read_excel(\"data/p5v2018.xls\")\n\ndf_polity = df_polity.loc[df_polity[\"country\"] == \"Japan\",:]\n\ndf_polity.head()\n\n\n      p5    cyear  ccode scode country  ...  post  change   d5  sf  regtrans\n7921   0  7401800    740   JPN   Japan  ... -10.0    88.0  1.0 NaN       NaN\n7922   0  7401801    740   JPN   Japan  ...   NaN     NaN  NaN NaN       NaN\n7923   0  7401802    740   JPN   Japan  ...   NaN     NaN  NaN NaN       NaN\n7924   0  7401803    740   JPN   Japan  ...   NaN     NaN  NaN NaN       NaN\n7925   0  7401804    740   JPN   Japan  ...   NaN     NaN  NaN NaN       NaN\n\n[5 rows x 37 columns]\n\n\n\n\n\nPython (polars)\n\ndf_polity = (\n    pl.read_excel(\"data/p5v2018.xls\")\n    .filter(pl.col(\"country\") == \"Japan\")\n)\n\ndf_polity.head()\n\n\n\n\nshape: (5, 37)\n\n\n\np5\ncyear\nccode\nscode\ncountry\nyear\nflag\nfragment\ndemoc\nautoc\npolity\npolity2\ndurable\nxrreg\nxrcomp\nxropen\nxconst\nparreg\nparcomp\nexrec\nexconst\npolcomp\nprior\nemonth\neday\neyear\neprec\ninterim\nbmonth\nbday\nbyear\nbprec\npost\nchange\nd5\nsf\nregtrans\n\n\ni64\ni64\ni64\nstr\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n0\n7401800\n740\n\"JPN\"\n\"Japan\"\n1800\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\n1\n1\n1800\n1\n-10\n88\n1\nnull\nnull\n\n\n0\n7401801\n740\n\"JPN\"\n\"Japan\"\n1801\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7401802\n740\n\"JPN\"\n\"Japan\"\n1802\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7401803\n740\n\"JPN\"\n\"Japan\"\n1803\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n0\n7401804\n740\n\"JPN\"\n\"Japan\"\n1804\n0\nnull\n0\n10\n-10\n-10\nnull\n3\n1\n1\n1\n4\n1\n1\n1\n1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\n\n\n\n\n\n\n13.4.3 部分集合による選択\n第2次世界大戦後から冷戦終結までのデータを取り出したい場合は、「かつ (and)」を意味する&を使います。\n\n\n\nR (base)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\")\n\ndf_polity &lt;- df_polity[df_polity$year &gt; 1945 & df_polity$year &lt;= 1991,]\n\n\n\n\n\nR (tidyverse)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\") |&gt; \n    filter(year &gt; 1945 & year &lt;= 1991)\n\n\n\n\n\nPython (pandas)\n\ndf_polity = pd.read_excel(\"data/p5v2018.xls\")\n\ndf_polity = df_polity.loc[(df_polity[\"year\"] &gt; 1945) & (df_polity[\"year\"] &lt;= 1991),:]\n\n\n\n\n\nPython (polars)\n\ndf_polity = (\n    pl.read_excel(\"data/p5v2018.xls\")\n    .filter((pl.col(\"year\") &gt; 1945) & (pl.col(\"year\") &lt; 1991))\n)\n\n\n\nPythonではそれぞれの条件部分を()でくくる必要があります。\n\nなお、次のように範囲を指定することもできます。\n\n\n\nR (tidyverse)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\") |&gt; \n    filter(between(year, 1946, 1991))\n\n\n\n\n\nPython (pandas)\n\ndf_polity = pd.read_excel(\"data/p5v2018.xls\")\n\ndf_polity = df_polity.loc[df_polity[\"year\"].between(1946, 1991),:]\n\n\n\n\n\nPython (polars)\n\ndf_polity = (\n    pl.read_excel(\"data/p5v2018.xls\")\n    .filter(pl.col(\"year\").is_between(1946, 1991))\n)\n\n\n\n\n13.4.4 和集合による選択\n日本と中国のデータを取り出す場合は、「または (or)」を意味する|を使います。\n\n\n\nR (base)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\")\n\ndf_polity &lt;- df_polity[df_polity$country == \"Japan\" | df_polity$country == \"China\",]\n\n\n\n\n\nR (tidyverse)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\") |&gt; \n    filter(country == \"Japan\" | country == \"China\")\n\n\n\n\n\nPython (pandas)\n\ndf_polity = pd.read_excel(\"data/p5v2018.xls\")\n\ndf_polity = df_polity.loc[(df_polity[\"country\"] == \"Japan\") | (df_polity[\"country\"] == \"China\"),:]\n\n\n\n\n\nPython (polars)\n\ndf_polity = (\n    pl.read_excel(\"data/p5v2018.xls\")\n    .filter((pl.col(\"country\") == \"Japan\") | (pl.col(\"country\") == \"China\"))\n)\n\n\n次のように簡単に書くこともできます。\n\n\n\nR (base)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\")\n\ndf_polity &lt;- df_polity[df_polity$country %in% c(\"Japan\", \"China\"),]\n\n\n\n\n\nR (tidyverse)\n\ndf_polity &lt;- read_excel(\"data/p5v2018.xls\") |&gt; \n    filter(country %in% c(\"Japan\", \"China\"))\n\n\n\n\n\nPython (pandas)\n\ndf_polity = pd.read_excel(\"data/p5v2018.xls\")\n\ndf_polity = df_polity.loc[df_polity[\"country\"].isin([\"Japan\", \"China\"]),:]\n\n\n\n\n\nPython (polars)\n\ndf_polity = (\n    pl.read_excel(\"data/p5v2018.xls\")\n    .filter(pl.col(\"country\").is_in([\"Japan\", \"China\"]))\n)\n\n\nなお、否定を表す場合はRの場合は!を、Pythonの場合は~を条件式の冒頭に付けます。\n\nRでもPythonでも==の否定は!=でも構いません。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの選択</span>"
    ]
  },
  {
    "objectID": "data_create.html",
    "href": "data_create.html",
    "title": "14  データの追加",
    "section": "",
    "text": "14.1 変数の作成\nデータフレームを拡張する方法の一つは変数を増やすことです。変数を増やすためには、\nの2通りの方法があります。まずは、前者について学びます。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの追加</span>"
    ]
  },
  {
    "objectID": "data_create.html#変数の作成",
    "href": "data_create.html#変数の作成",
    "title": "14  データの追加",
    "section": "",
    "text": "既存のデータフレームの変数を用いて新しい変数を作成するか、\n別のデータフレームと結合する\n\n\n\n14.1.1 四則演算\n一般的な四則演算が実行可能です。例えば、東大朝日の2017年衆議院選挙の有権者調査のコードブックを見てみると、問23で政策に対する賛否を聞いています（質問文は間違っていますが）。特に、(1)から(4)は外交政策についてタカ派かハト派かを表しています。\nそこで、これらの変数を足し合わせることでハト派度合いを表す変数を作りたいと思います。\n\nただし、(4)については点数が高いほうがタカ派を意味するので、引き算します。\nついでに不要な変数も除去しておきます。\n\n\n\n\nR (base)\n\ndf_voter2017 &lt;- read_csv(\"data/2017UTASV20200326.csv\", locale = locale(encoding = \"Shift-JIS\"), na = \"99\")\n\ndf_voter2017 &lt;- df_voter2017[,c(\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\")]\ndf_voter2017$dovish &lt;- df_voter2017$Q23_1 + df_voter2017$Q23_2 + df_voter2017$Q23_3 - df_voter2017$Q23_4\n\nhead(df_voter2017)\n\n\n# A tibble: 6 × 5\n  Q23_1 Q23_2 Q23_3 Q23_4 dovish\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     2     3     2     2      5\n2     2     3     2     4      3\n3     3     4     2     2      7\n4     2     1     2     1      4\n5     4     3     2     2      7\n6     3     4     5     1     11\n\n\n\n\n\nR (tidyverse)\n\ndf_voter2017 &lt;- read_csv(\"data/2017UTASV20200326.csv\", locale = locale(encoding = \"Shift-JIS\"), na = \"99\") |&gt; \n    select(Q23_1, Q23_2, Q23_3, Q23_4) |&gt; \n    mutate(dovish = Q23_1 + Q23_2 + Q23_3 - Q23_4)\n\nhead(df_voter2017)\n\n\n# A tibble: 6 × 5\n  Q23_1 Q23_2 Q23_3 Q23_4 dovish\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     2     3     2     2      5\n2     2     3     2     4      3\n3     3     4     2     2      7\n4     2     1     2     1      4\n5     4     3     2     2      7\n6     3     4     5     1     11\n\n\n\n\n\nPython (pandas)\n\ndf_voter2017 = pd.read_csv(\"data/2017UTASV20200326.csv\", encoding=\"Shift-JIS\", na_values=\"99\")\n\ndf_voter2017 = df_voter2017.loc[:,[\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\"]]\ndf_voter2017[\"dovish\"] = df_voter2017[\"Q23_1\"] + df_voter2017[\"Q23_2\"] + df_voter2017[\"Q23_3\"] - df_voter2017[\"Q23_4\"]\n\ndf_voter2017.head()\n\n\n   Q23_1  Q23_2  Q23_3  Q23_4  dovish\n0    2.0    3.0    2.0    2.0     5.0\n1    2.0    3.0    2.0    4.0     3.0\n2    3.0    4.0    2.0    2.0     7.0\n3    2.0    1.0    2.0    1.0     4.0\n4    4.0    3.0    2.0    2.0     7.0\n\n\n\n\n\nPython (polars)\n\ndf_voter2017 = (\n    pl.read_csv(\"data/2017UTASV20200326.csv\", encoding=\"Shift-JIS\", null_values=\"99\")\n    .select([\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\"])\n    .with_columns(dovish = pl.col(\"Q23_1\") + pl.col(\"Q23_2\") + pl.col(\"Q23_3\") - pl.col(\"Q23_4\"))\n)\n\ndf_voter2017.head()\n\n\n\n\nshape: (5, 5)\n\n\n\nQ23_1\nQ23_2\nQ23_3\nQ23_4\ndovish\n\n\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n2\n3\n2\n2\n5\n\n\n2\n3\n2\n4\n3\n\n\n3\n4\n2\n2\n7\n\n\n2\n1\n2\n1\n4\n\n\n4\n3\n2\n2\n7\n\n\n\n\n\n\n\nここでもtidyverseとpolars、R標準関数とpandasの共通性が見て取れます。つまり、前者ではmutate()ないしwith_columns()内で新しい変数を定義しています。一方で後者は存在しない変数を参照して、そこに代入することで新しい変数を作成しています。\nなお、+や-以外にも四則演算は可能です。\n\n\n\n計算\nR\nPython\n\n\n\n\n足し算\n+\n+\n\n\n引き算\n-\n-\n\n\n掛け算\n*\n*\n\n\n割り算\n/\n/\n\n\n累乗\n^\n**\n\n\n割り算の余り\n%%\n%\n\n\n割り算の商\n%/%\n//\n\n\n\n\n\n14.1.2 尺度の反転\nところで、先程の4つの設問では賛成が1、反対が5となる変数でした。そして、(1)から(3)は賛成のほうがタカ派であり、(4)は反対の方がタカ派と言えそうでした。\nそうすると、(4)でも反対が1、賛成が5となるように尺度を反転させたくなるのが人情です。このような場合、「最大値から元の変数を引いて最小値を足す」ことで反転させることができます。そのような反転させた(4)の回答をQ23_4newとして作ってみます。\n\n\n\nR (base)\n\ndf_voter2017 &lt;- read_csv(\"data/2017UTASV20200326.csv\", locale = locale(encoding = \"Shift-JIS\"), na = \"99\")\n\ndf_voter2017 &lt;- df_voter2017[,c(\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\")]\ndf_voter2017$Q23_4new &lt;- max(df_voter2017$Q23_4) - df_voter2017$Q23_4 + min(df_voter2017$Q23_4)\ndf_voter2017$dovish &lt;- df_voter2017$Q23_1 + df_voter2017$Q23_2 + df_voter2017$Q23_3 + df_voter2017$Q23_4new\n\nhead(df_voter2017)\n\n\n# A tibble: 6 × 6\n  Q23_1 Q23_2 Q23_3 Q23_4 Q23_4new dovish\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1     2     3     2     2       NA     NA\n2     2     3     2     4       NA     NA\n3     3     4     2     2       NA     NA\n4     2     1     2     1       NA     NA\n5     4     3     2     2       NA     NA\n6     3     4     5     1       NA     NA\n\n\nQ23_4newが全てNAとなっています。なぜなら、Q23_4に欠損値が含まれており、この場合は最大値も最小値も欠損値になってしまうからです。したがって、na.rm = TRUEとすることで欠損値を除外して最大値と最小値を求めます。\n\n\n\nR (base)\n\ndf_voter2017 &lt;- read_csv(\"data/2017UTASV20200326.csv\", locale = locale(encoding = \"Shift-JIS\"), na = \"99\")\n\ndf_voter2017 &lt;- df_voter2017[,c(\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\")]\ndf_voter2017$Q23_4new &lt;- max(df_voter2017$Q23_4, na.rm = TRUE) - df_voter2017$Q23_4 + min(df_voter2017$Q23_4, na.rm = TRUE)\ndf_voter2017$dovish &lt;- df_voter2017$Q23_1 + df_voter2017$Q23_2 + df_voter2017$Q23_3 + df_voter2017$Q23_4new\n\nhead(df_voter2017)\n\n\n# A tibble: 6 × 6\n  Q23_1 Q23_2 Q23_3 Q23_4 Q23_4new dovish\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1     2     3     2     2        4     11\n2     2     3     2     4        2      9\n3     3     4     2     2        4     13\n4     2     1     2     1        5     10\n5     4     3     2     2        4     13\n6     3     4     5     1        5     17\n\n\n\n\n\nR (tidyverse)\n\ndf_voter2017 &lt;- read_csv(\"data/2017UTASV20200326.csv\", locale = locale(encoding = \"Shift-JIS\"), na = \"99\") |&gt; \n    select(Q23_1, Q23_2, Q23_3, Q23_4) |&gt; \n    mutate(Q23_4new = max(Q23_4, na.rm = TRUE) - Q23_4 + min(Q23_4, na.rm = TRUE), \n           dovish = Q23_1 + Q23_2 + Q23_3 + Q23_4new)\n\nhead(df_voter2017)\n\n\n# A tibble: 6 × 6\n  Q23_1 Q23_2 Q23_3 Q23_4 Q23_4new dovish\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1     2     3     2     2        4     11\n2     2     3     2     4        2      9\n3     3     4     2     2        4     13\n4     2     1     2     1        5     10\n5     4     3     2     2        4     13\n6     3     4     5     1        5     17\n\n\n\n\n\nPython (pandas)\n\ndf_voter2017 = pd.read_csv(\"data/2017UTASV20200326.csv\", encoding=\"Shift-JIS\", na_values=\"99\")\n\ndf_voter2017 = df_voter2017.loc[:,[\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\"]]\ndf_voter2017[\"Q23_4new\"] = df_voter2017[\"Q23_4\"].max() - df_voter2017[\"Q23_4\"] + df_voter2017[\"Q23_4\"].min()\ndf_voter2017[\"dovish\"] = df_voter2017[\"Q23_1\"] + df_voter2017[\"Q23_2\"] + df_voter2017[\"Q23_3\"] + df_voter2017[\"Q23_4new\"]\n\ndf_voter2017.head()\n\n\n   Q23_1  Q23_2  Q23_3  Q23_4  Q23_4new  dovish\n0    2.0    3.0    2.0    2.0       4.0    11.0\n1    2.0    3.0    2.0    4.0       2.0     9.0\n2    3.0    4.0    2.0    2.0       4.0    13.0\n3    2.0    1.0    2.0    1.0       5.0    10.0\n4    4.0    3.0    2.0    2.0       4.0    13.0\n\n\n\n\n\nPython (polars)\n\ndf_voter2017 = (\n    pl.read_csv(\"data/2017UTASV20200326.csv\", encoding=\"Shift-JIS\", null_values=\"99\")\n    .select([\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\"])\n    .with_columns(Q23_4new = pl.col(\"Q23_4\").max() - pl.col(\"Q23_4\") + pl.col(\"Q23_4\").min())\n    .with_columns(dovish = pl.col(\"Q23_1\") + pl.col(\"Q23_2\") + pl.col(\"Q23_3\") + pl.col(\"Q23_4new\"))\n)\n\ndf_voter2017.head()\n\n\n\n\nshape: (5, 6)\n\n\n\nQ23_1\nQ23_2\nQ23_3\nQ23_4\nQ23_4new\ndovish\n\n\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n2\n3\n2\n2\n4\n11\n\n\n2\n3\n2\n4\n2\n9\n\n\n3\n4\n2\n2\n4\n13\n\n\n2\n1\n2\n1\n5\n10\n\n\n4\n3\n2\n2\n4\n13\n\n\n\n\n\n\n\n\n\n14.1.3 条件に基づく変数\n\n14.1.3.1 条件が一つの場合\n四則演算以外にも条件に基づいて新しい変数を作成することもできます。例えば、先ほど作ったハト派変数について、「平均値よりも大きければハト派、そうでなければタカ派」とする変数を作ってみます。\n\n\n\nR (base)\n\ndf_voter2017 &lt;- read_csv(\"data/2017UTASV20200326.csv\", locale = locale(encoding = \"Shift-JIS\"), na = \"99\")\n\ndf_voter2017 &lt;- df_voter2017[,c(\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\")]\ndf_voter2017$Q23_4new &lt;- max(df_voter2017$Q23_4, na.rm = TRUE) - df_voter2017$Q23_4 + min(df_voter2017$Q23_4, na.rm = TRUE)\ndf_voter2017$dovish &lt;- df_voter2017$Q23_1 + df_voter2017$Q23_2 + df_voter2017$Q23_3 + df_voter2017$Q23_4new\ndf_voter2017$dov_bin &lt;- ifelse(df_voter2017$dovish &gt; mean(df_voter2017$dovish, na.rm = TRUE), \"dove\", \"hawk\")\n\nhead(df_voter2017)\n\n\n# A tibble: 6 × 7\n  Q23_1 Q23_2 Q23_3 Q23_4 Q23_4new dovish dov_bin\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  \n1     2     3     2     2        4     11 hawk   \n2     2     3     2     4        2      9 hawk   \n3     3     4     2     2        4     13 dove   \n4     2     1     2     1        5     10 hawk   \n5     4     3     2     2        4     13 dove   \n6     3     4     5     1        5     17 dove   \n\n\n\n\n\nR (tidyverse)\n\ndf_voter2017 &lt;- read_csv(\"data/2017UTASV20200326.csv\", locale = locale(encoding = \"Shift-JIS\"), na = \"99\") |&gt; \n    select(Q23_1, Q23_2, Q23_3, Q23_4) |&gt; \n    mutate(Q23_4new = max(Q23_4, na.rm = TRUE) - Q23_4 + min(Q23_4, na.rm = TRUE), \n           dovish = Q23_1 + Q23_2 + Q23_3 + Q23_4new, \n           dov_bin = if_else(dovish &gt; mean(dovish, na.rm = TRUE), \"dove\", \"hawk\"))\n\nhead(df_voter2017)\n\n\n# A tibble: 6 × 7\n  Q23_1 Q23_2 Q23_3 Q23_4 Q23_4new dovish dov_bin\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  \n1     2     3     2     2        4     11 hawk   \n2     2     3     2     4        2      9 hawk   \n3     3     4     2     2        4     13 dove   \n4     2     1     2     1        5     10 hawk   \n5     4     3     2     2        4     13 dove   \n6     3     4     5     1        5     17 dove   \n\n\n\n\n\nPython (pandas)\n\nimport numpy as np\n\ndf_voter2017 = pd.read_csv(\"data/2017UTASV20200326.csv\", encoding=\"Shift-JIS\", na_values=\"99\")\n\ndf_voter2017 = df_voter2017.loc[:,[\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\"]]\ndf_voter2017[\"Q23_4new\"] = df_voter2017[\"Q23_4\"].max() - df_voter2017[\"Q23_4\"] + df_voter2017[\"Q23_4\"].min()\ndf_voter2017[\"dovish\"] = df_voter2017[\"Q23_1\"] + df_voter2017[\"Q23_2\"] + df_voter2017[\"Q23_3\"] + df_voter2017[\"Q23_4new\"]\ndf_voter2017[\"dov_bin\"] = np.where(df_voter2017[\"dovish\"] &gt; df_voter2017[\"dovish\"].mean(), \"dove\", \"hawk\")\n\ndf_voter2017.head()\n\n\n   Q23_1  Q23_2  Q23_3  Q23_4  Q23_4new  dovish dov_bin\n0    2.0    3.0    2.0    2.0       4.0    11.0    hawk\n1    2.0    3.0    2.0    4.0       2.0     9.0    hawk\n2    3.0    4.0    2.0    2.0       4.0    13.0    dove\n3    2.0    1.0    2.0    1.0       5.0    10.0    hawk\n4    4.0    3.0    2.0    2.0       4.0    13.0    dove\n\n\n\nnumpyというパッケージを使います。\n\n\n\n\nPython (polars)\n\ndf_voter2017 = (\n    pl.read_csv(\"data/2017UTASV20200326.csv\", encoding=\"Shift-JIS\", null_values=\"99\")\n    .select([\"Q23_1\", \"Q23_2\", \"Q23_3\", \"Q23_4\"])\n    .with_columns(Q23_4new = pl.col(\"Q23_4\").max() - pl.col(\"Q23_4\") + pl.col(\"Q23_4\").min())\n    .with_columns(dovish = pl.col(\"Q23_1\") + pl.col(\"Q23_2\") + pl.col(\"Q23_3\") + pl.col(\"Q23_4new\"))\n    .with_columns(dov_bin = pl.when(pl.col(\"dovish\") &gt; pl.col(\"dovish\").mean()).then(pl.lit(\"dove\")).otherwise(pl.lit(\"hawk\")))\n)\n\ndf_voter2017.head()\n\n\n\n\nshape: (5, 7)\n\n\n\nQ23_1\nQ23_2\nQ23_3\nQ23_4\nQ23_4new\ndovish\ndov_bin\n\n\ni64\ni64\ni64\ni64\ni64\ni64\nstr\n\n\n\n\n2\n3\n2\n2\n4\n11\n\"hawk\"\n\n\n2\n3\n2\n4\n2\n9\n\"hawk\"\n\n\n3\n4\n2\n2\n4\n13\n\"dove\"\n\n\n2\n1\n2\n1\n5\n10\n\"hawk\"\n\n\n4\n3\n2\n2\n4\n13\n\"dove\"\n\n\n\n\n\n\n\n\n変数に文字列を代入するためにはpl.lit()を使います。\n\n長くて分かりにくいですが、基本的な構造はいずれも同じです。Rの標準関数の場合はifelse()、tidyverseの場合はif_else()、pandasではnumpyのnp.where()、polarsではwhen().then().otherwise()を使います。\nまず最初に条件式を入力し（ハト派度合いが平均値以上）、それに合致する場合は最初の値doveを代入し、合致しない場合は次の値hawkを代入しています。\n\n\n14.1.3.2 条件が複数の場合\n条件が複数ある場合、つまり条件1に当てはまる場合はA、条件2に当てはまる場合はB、条件3に当てはまる場合はC……というような変数を作る場合は、次のように書くのが便利です。例えば、F2という変数は年代を表していますが、10代・20代を若者、30代から50代を中高年、60代以上を高齢者とするような変数を作ってみます。\ntidyverseではcase_when()を使います。条件式 ~ 変数の値とします。条件に合致しないものに対しては条件式をTRUEとします。\n\n\n\nR (tidyverse)\n\ndf_voter2017 &lt;- read_csv(\"data/2017UTASV20200326.csv\", locale = locale(encoding = \"Shift-JIS\"), na = \"99\") |&gt; \n    select(F2) |&gt; \n    mutate(generation = case_when(F2 &lt;= 2 ~ \"youth\", \n                                  3 &lt;= F2 & F2 &lt;= 5 ~ \"middle\", \n                                  TRUE ~ \"senior\"))\n\nhead(df_voter2017)\n\n\n# A tibble: 6 × 2\n     F2 generation\n  &lt;dbl&gt; &lt;chr&gt;     \n1     4 middle    \n2     5 middle    \n3     3 middle    \n4     7 senior    \n5     7 senior    \n6     7 senior    \n\n\npolarsではwhen().then()を繰り返し、最後にotherwise()で条件に合致しないものの値を決めます。\n\n\n\nPython (polars)\n\ndf_voter2017 = (\n    pl.read_csv(\"data/2017UTASV20200326.csv\", encoding=\"Shift-JIS\", null_values=\"99\")\n    .select([\"F2\"])\n    .with_columns(generation = pl.when(pl.col(\"F2\") &lt;= 2)\n                               .then(pl.lit(\"youth\"))\n                               .when((3 &lt;= pl.col(\"F2\")) & (pl.col(\"F2\") &lt;= 5))\n                               .then(pl.lit(\"middle\"))\n                               .otherwise(pl.lit(\"senior\")))\n)\n\ndf_voter2017.head()\n\n\n\n\nshape: (5, 2)\n\n\n\nF2\ngeneration\n\n\ni64\nstr\n\n\n\n\n4\n\"middle\"\n\n\n5\n\"middle\"\n\n\n3\n\"middle\"\n\n\n7\n\"senior\"\n\n\n7\n\"senior\"\n\n\n\n\n\n\n\n\n\n\n14.1.4 ラグ変数\n\n\n14.1.5 日付",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの追加</span>"
    ]
  },
  {
    "objectID": "data_create.html#データの結合変数の追加",
    "href": "data_create.html#データの結合変数の追加",
    "title": "14  データの追加",
    "section": "14.2 データの結合（変数の追加）",
    "text": "14.2 データの結合（変数の追加）\n\n14.2.1 左結合・右結合\n\n\n14.2.2 全結合・共通部分結合\n\n\n14.2.3 countrycode",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの追加</span>"
    ]
  },
  {
    "objectID": "data_create.html#データの結合観察の追加",
    "href": "data_create.html#データの結合観察の追加",
    "title": "14  データの追加",
    "section": "14.3 データの結合（観察の追加）",
    "text": "14.3 データの結合（観察の追加）\n作成中です。もしかすると旧バージョンになにかあるかもしれません。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの追加</span>"
    ]
  },
  {
    "objectID": "data_pivot.html",
    "href": "data_pivot.html",
    "title": "15  ロングとワイドの変換",
    "section": "",
    "text": "作成中です。もしかすると旧バージョンになにかあるかもしれません。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>ロングとワイドの変換</span>"
    ]
  },
  {
    "objectID": "data_missing_values.html",
    "href": "data_missing_values.html",
    "title": "16  欠損値の対応",
    "section": "",
    "text": "作成中です。もしかすると旧バージョンになにかあるかもしれません。",
    "crumbs": [
      "データの処理",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>欠損値の対応</span>"
    ]
  },
  {
    "objectID": "plot_map.html",
    "href": "plot_map.html",
    "title": "17  地図のグラフ",
    "section": "",
    "text": "作成中です。もしかすると旧バージョンになにかあるかもしれません。",
    "crumbs": [
      "地理空間データ",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>地図のグラフ</span>"
    ]
  },
  {
    "objectID": "encoding.html",
    "href": "encoding.html",
    "title": "付録 A — エンコーディングの問題",
    "section": "",
    "text": "A.1 文字化けが起こる理由\n簡単に言うと、エンコーディングとは人間が理解可能な自然言語から機械が理解可能な記号への「翻訳方法」です。エンコードとデコードで異なる方式を用いると、適切な文字に翻訳できず、文字化けが起こります。\nエンコーディングの方法は以下のように、使用しているOSによって変わります。\nつまり、Macなどで作成され、すなわちUTF-8でエンコードしたデータをWindowsでShift-JISなどでデコードしようとすると文字化けが起こります（その逆もしかり）。\nしたがって、対処法は次の通りになります。\nなお、UTF-8が様々な言語に対応しているものなので、データなどを保存する際はこちらを使うほうがベターです。",
    "crumbs": [
      "付録",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>エンコーディングの問題</span>"
    ]
  },
  {
    "objectID": "encoding.html#文字化けが起こる理由",
    "href": "encoding.html#文字化けが起こる理由",
    "title": "付録 A — エンコーディングの問題",
    "section": "",
    "text": "Mac, Linux: UTF-8\nWindows: Shift-JISやCP932\n\n\n\n\n\n\n\n\nWindowsでもUTF-8となる場合\n\n\n\nWindows 10以上でR 4.2以上を使っている場合はUTF-8がデフォルトのエンコーディングになります。この場合は、以下の説明のRに関する箇所においてはMax, Linuxとして読んでください。\n\n\n\n\nMac, Linuxで文字化けが起こる\\(\\leadsto\\)データはShift-JISなどでエンコードされているので、そのように指定する。\nWindowsで文字化けが起こる\\(\\leadsto\\)データはUTF-8などでエンコードされているので、そのように指定する。",
    "crumbs": [
      "付録",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>エンコーディングの問題</span>"
    ]
  },
  {
    "objectID": "encoding.html#ロケールの確認",
    "href": "encoding.html#ロケールの確認",
    "title": "付録 A — エンコーディングの問題",
    "section": "A.2 ロケールの確認",
    "text": "A.2 ロケールの確認\nロケールとは、ざっくり言うと、PCにおける言語や国・地域の設定のことです。ロケールを確認すると、デフォルトのエンコーディングも分かります。\n\n\n\nR\n\nSys.getlocale()\n\n\n[1] \"LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=ja_JP.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=ja_JP.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=ja_JP.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=ja_JP.UTF-8;LC_IDENTIFICATION=C\"\n\n\n\n\n\nPython\n\nimport sys\n\nsys.getdefaultencoding()\n\n\n'utf-8'\n\n\n僕はLinuxを使っているので、UTF-8がデフォルトのエンコーディングです。",
    "crumbs": [
      "付録",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>エンコーディングの問題</span>"
    ]
  },
  {
    "objectID": "encoding.html#データの文字化け",
    "href": "encoding.html#データの文字化け",
    "title": "付録 A — エンコーディングの問題",
    "section": "A.3 データの文字化け",
    "text": "A.3 データの文字化け\nUTF-8でエンコーディングされたデータとShift-JISでエンコーディングされたデータをダウンロードします。\n\nA.3.1 問題の確認\nまず、UTF-8のデータを読み込みます。MacやLinuxの場合は問題なく読み込めるはずです。一方で、Windowsの場合はエラーが表示されるはずです。\n\n\n\nR (base)\n\nread.csv(\"data/data_utf8.csv\")\n\n\n  桃太郎\n1   イヌ\n2   サル\n3   キジ\n\n\n\n\n\nR (tidyverse)\n\nlibrary(tidyverse)\n\nread_csv(\"data/data_utf8.csv\")\n\n\n# A tibble: 3 × 1\n  桃太郎\n  &lt;chr&gt; \n1 イヌ  \n2 サル  \n3 キジ  \n\n\n\n\n\nPython\n\nimport pandas as pd\n\npd.read_csv('data/data_utf8.csv')\n\n\n  桃太郎\n0  イヌ\n1  サル\n2  キジ\n\n\n逆に、Max, LinuxではShift-JISのデータは読み込めず、Windowsでは読み込めるはずです。\n\n\n\nR (base)\n\nread.csv(\"data/data_sjis.csv\")\n\n\nError in make.names(col.names, unique = TRUE): invalid multibyte string at '&lt;93&gt;&lt;8d&gt;&lt;91&gt;&lt;be&gt;&lt;98&gt;Y'\n\n\n\n\n\nR (tidyverse)\n\nread_csv(\"data/data_sjis.csv\")\n\n\nError in nchar(x, \"width\"): invalid multibyte string, element 1\n\n\n\n\n\nPython\n\npd.read_csv('data/data_sjis.csv')\n\n\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte\n\n\n\n\nA.3.2 対処法\nデータを読み込む時にエンコーディング方法を明示することで解決できます。\n\n\n\nR (base)\n\nread.csv(\"data/data_sjis.csv\", fileEncoding = \"Shift-JIS\")\n\n\n  桃太郎\n1   イヌ\n2   サル\n3   キジ\n\n\n\n\n\nR (tidyverse)\n\nread_csv(\"data/data_sjis.csv\", locale = locale(encoding = \"Shift-JIS\"))\n\n\n# A tibble: 3 × 1\n  桃太郎\n  &lt;chr&gt; \n1 イヌ  \n2 サル  \n3 キジ  \n\n\n\n\n\nPython\n\npd.read_csv('data/data_sjis.csv', encoding='Shift-JIS')\n\n\n  桃太郎\n0  イヌ\n1  サル\n2  キジ\n\n\n“Shift-JIS”を”UTF-8”に変更すれば、UTF-8のデータを読み込むことができます。\n\n\n\nR (base)\n\nread.csv(\"data/data_utf8.csv\", fileEncoding = \"UTF-8\")\n\n\n  桃太郎\n1   イヌ\n2   サル\n3   キジ\n\n\n\n\n\nR (tidyverse)\n\nread_csv(\"data/data_utf8.csv\", locale = locale(encoding = \"UTF-8\"))\n\n\n# A tibble: 3 × 1\n  桃太郎\n  &lt;chr&gt; \n1 イヌ  \n2 サル  \n3 キジ  \n\n\n\n\n\nPython\n\npd.read_csv('data/data_utf8.csv', encoding='UTF-8')\n\n\n  桃太郎\n0  イヌ\n1  サル\n2  キジ\n\n\n\n\n\n\n\n\n表計算ソフトで見る場合\n\n\n\n例えば、UTF-8の.csvファイルをWindowsのエクセルで開くと文字化けが起こります。Libre Officeという無料のオフィスソフトではエンコーディングを指定してファイルを開くことができるので、こちらで開くことを勧めます。",
    "crumbs": [
      "付録",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>エンコーディングの問題</span>"
    ]
  },
  {
    "objectID": "encoding.html#スクリプトの文字化け",
    "href": "encoding.html#スクリプトの文字化け",
    "title": "付録 A — エンコーディングの問題",
    "section": "A.4 スクリプトの文字化け",
    "text": "A.4 スクリプトの文字化け\nUTF-8でエンコーディングされたスクリプトとShift-JISでエンコーディングされたスクリプトをダウンロードします。\n\nA.4.1 問題の確認\nMac. LinuxでUTF-8のスクリプトを開くと正しく表示されますが、Windowsでは表示されないはずです。\n同様に、Shift-JISの方はWindowsで正しく表示され、Mac, Linuxでは文字化けが起こるはずです。\n\nRスクリプトですが、原理はPythonスクリプトと同様です。VIsual Studio Codeなどで開いてみてください。\n\n\n\nA.4.2 対処法\nRStudioの場合、メニューの中のFileにReopen with Encoding...というのがあるので、UTF-8を選択します。さらにSet as default encoding for source filesにチェックを入れることで今後はUTF-8で表示されます。\n今後、文字化けが起こる場合はShift-JISでエンコーディングしたファイルのはずなので、Reopen with Encoding...でShift-JISを選択してファイルを開きます。\nVisual Studio Codeの場合、右下にエンコーディングが書かれているので、それをクリックし、Reopen with Encodingをクリックし、適当なエンコーディングを選択します。",
    "crumbs": [
      "付録",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>エンコーディングの問題</span>"
    ]
  },
  {
    "objectID": "encoding.html#エンコーディングの確認",
    "href": "encoding.html#エンコーディングの確認",
    "title": "付録 A — エンコーディングの問題",
    "section": "A.5 エンコーディングの確認",
    "text": "A.5 エンコーディングの確認\nファイルのエンコーディングを確認することが可能です。どれくらい信頼していいのかは分かりません。\n\n\n\nR (tidyverse)\n\nguess_encoding(\"data/data_sjis.csv\")\n\n\n# A tibble: 1 × 2\n  encoding     confidence\n  &lt;chr&gt;             &lt;dbl&gt;\n1 windows-1252       0.23\n\n\n\n\n\nPython\n\nimport chardet\n\nwith open('data/data_sjis.csv', 'rb') as f:\n  c = f.read()\n  chardet.detect(c)\n\n\n{'encoding': 'SHIFT_JIS', 'confidence': 0.99, 'language': 'Japanese'}",
    "crumbs": [
      "付録",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>エンコーディングの問題</span>"
    ]
  },
  {
    "objectID": "encoding.html#文字化けしない保存",
    "href": "encoding.html#文字化けしない保存",
    "title": "付録 A — エンコーディングの問題",
    "section": "A.6 文字化けしない保存",
    "text": "A.6 文字化けしない保存\n\nA.6.1 データの保存\nデータを保存する際は（そもそもマルチバイト文字を避けるべきですが）UTF-8で保存するほうが良いでしょう。\n\n\n\nR (base)\n\nwrite.csv(..., \"...\", fileEncoding = \"UTF-8\")\n\n\n\n\n\nR (tidyverse)\n\nwrite_excel_csv(\"...\")\n\n\n\ntidyverseではwrite_excel_csv()を使うことで、エクセルでも文字化けしないようにできます。\n\n\n\n\nPython\n\n....to_csv('...', encoding='UTF-8_sig')\n\n\n\npandasではencoding='UTF-8_sig'とすることで、エクセルでも文字化けしないようにできます。\n\n\n\nA.6.2 スクリプトの保存\nRStudioの場合、Fileの中のSave with Encoding...でUTF-8を選択してください。ここでもUTF-8がデフォルトになるようにチェックを入れておきましょう。\n\n\nA.6.3 画像の保存\nMacで画像を保存する際に、日本語が文字化けするらしいです。対処法は以下の通りです。\n\nフォント名HiraKakuProN-W3は例です。\n\n\n\n\nR (base)\n\npar(family = \"HiraKakuProN-W3\")\n\n\n\n\n\nR (tidyverse)\n\ntheme_set(theme_grey(base_family = \"HiraKakuProN-W3\"))\n\n\n\n\n\nPython (matplotlib)\n\nplt.rcParams['font.family'] = 'HiraKakuProN-W3'\n\n\n\n\n\nPython (seaborn)\n\nsns.set(font='HiraKakuProN-W3')",
    "crumbs": [
      "付録",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>エンコーディングの問題</span>"
    ]
  },
  {
    "objectID": "pipe.html",
    "href": "pipe.html",
    "title": "付録 B — パイプ演算子",
    "section": "",
    "text": "作成中です。もしかすると旧バージョンになにかあるかもしれません。",
    "crumbs": [
      "付録",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>パイプ演算子</span>"
    ]
  },
  {
    "objectID": "session_info.html",
    "href": "session_info.html",
    "title": "動作環境",
    "section": "",
    "text": "本書はRとPythonについて、それぞれ以下のような動作環境で作成しています。\n\n\n\nR\n\nsessionInfo()\n\n\nR version 4.4.0 (2024-04-24)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3;  LAPACK version 3.9.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=ja_JP.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=ja_JP.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=ja_JP.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=ja_JP.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Asia/Tokyo\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.0    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.4.0       htmltools_0.5.8.1 rmarkdown_2.26    knitr_1.46       \n [9] jsonlite_1.8.8    xfun_0.43         digest_0.6.35     rlang_1.1.3      \n[13] evaluate_0.23    \n\n\n\n\n\nPython\n\nimport session_info\nsession_info.show()\n\n\n-----\nsession_info        1.0.0\n-----\nPython 3.11.9 (main, Apr  6 2024, 17:59:24) [GCC 9.4.0]\nLinux-4.15.0-191-generic-x86_64-with-glibc2.31\n-----\nSession information updated at 2024-05-07 18:32",
    "crumbs": [
      "付録",
      "動作環境"
    ]
  }
]